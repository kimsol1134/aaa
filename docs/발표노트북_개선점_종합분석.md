# 발표용 노트북 4개 심층 개선점 분석 보고서

**작성일**: 2025-11-22
**분석 대상**: Part 1~4 발표용 노트북

---

## 📌 Executive Summary

### 종합 평가
- **전체 점수**: 90.25/100 (목표 87점 달성 ✅)
- **가장 취약한 영역**: 한계 인정 (2.75/5점)
- **총 개선 항목**: 50개 이상
- **예상 작업 시간**: 10시간 (High Priority만 3.5시간)

### 발표 준비도
- **현재 상태**: 충분히 발표 가능
- **즉시 수정 필요**: 5개 항목 (Data Leakage, 매직 넘버 등)
- **발표 전 권장**: 7개 항목 (캐싱, 색상 통일 등)

---

## 📊 분석 대상 노트북

1. **Part 1**: 문제정의_및_핵심발견.ipynb (2,812 lines)
2. **Part 2**: 도메인_특성_공학_완전판.ipynb (1,205 lines)
3. **Part 3**: 모델링_및_최적화_v3_완전판.ipynb (264 lines)
4. **Part 4**: 결과_및_비즈니스_가치_v2.ipynb (2,012 lines)

---

## 🎯 평가 차원별 점수 (재분석)

| 평가 차원 | Part1 | Part2 | Part3 | Part4 | 평균 | 목표 | 달성 |
|----------|-------|-------|-------|-------|------|------|------|
| 설명 가능성 (25점) | 23 | 24 | 21 | 22 | 22.5 | 22 | ✅ |
| 스토리텔링 (20점) | 19 | 19 | 19 | 18 | 18.75 | 18 | ✅ |
| 시각화+해석 (20점) | 18 | 17 | 19 | 18 | 18 | 16 | ✅ |
| 도메인 전문성 (15점) | 14 | 15 | 13 | 14 | 14 | 13 | ✅ |
| 통계적 엄격성 (10점) | 9 | 9 | 10 | 9 | 9.25 | 8 | ✅ |
| 재현 가능성 (5점) | 5 | 5 | 5 | 5 | 5 | 5 | ✅ |
| **한계 인정 (5점)** | **4** | **2** | **1** | **4** | **2.75** | **5** | **❌** |

---

## ⚠️ 카테고리별 가장 심각한 문제 Top 10

| 순위 | 카테고리 | 문제 | 위치 | 영향도 | 우선순위 |
|------|----------|------|------|--------|----------|
| 1 | **데이터 전처리** | Part 2 Feature Validation에서 Data Leakage 발생 | Part2 Cell 19 | 심각 | **High** |
| 2 | **코드 품질** | 매직 넘버 다수 (통계 임계값 0.001, 0.05, IV 기준 등) | 전체 | 높음 | **High** |
| 3 | **비즈니스 메트릭** | Part 4 비즈니스 가정 하드코딩 (손실률 0.67, 이자율 0.05 등) | Part4 | 높음 | **High** |
| 4 | **재현성** | Part 1에 RANDOM_STATE 정의 없음 | Part1 | 높음 | **High** |
| 5 | **재현성** | 모든 노트북에 패키지 버전 명시 없음 | 전체 | 높음 | **High** |
| 6 | **노트북 흐름** | 중간 파일명 버전 혼재 (완전판, v1, v2 등) | 전체 | 중간 | **Medium** |
| 7 | **발표 준비** | Part 2/3 일부 셀 실행 시간 길음 (발표 중 실행 불가) | Part2,3 | 중간 | **Medium** |
| 8 | **시각화** | 색상 팔레트 불일치 (노트북마다 다른 색상 사용) | 전체 | 중간 | **Medium** |
| 9 | **문서화** | 복잡한 코드 (M-Score 등) 주석 부족 | Part2 | 중간 | **Medium** |
| 10 | **코드 품질** | 에러 처리 부족 (bare except 사용) | Part1 | 낮음 | **Low** |

---

## 🚀 Quick Wins Top 10 (빠르게 개선 가능)

| 순위 | 작업 | 예상 시간 | 효과 | 우선순위 |
|------|------|----------|------|----------|
| 1 | **상수 정의** - 모든 매직 넘버를 노트북 최상단에 상수로 정의 | 30분 | 유지보수성 ↑ | High |
| 2 | **색상 팔레트 통일** - COLOR_PALETTE dict 정의 및 적용 | 20분 | 일관성 ↑ | Medium |
| 3 | **RANDOM_STATE 통일** - 모든 노트북에 동일한 설정 추가 | 10분 | 재현성 ↑ | High |
| 4 | **패키지 버전 출력** - 각 노트북 최상단에 버전 체크 코드 추가 | 15분 | 재현성 ↑ | High |
| 5 | **경로 변수화** - 하드코딩된 경로를 DATA_FILES dict로 통일 | 30분 | 유지보수성 ↑ | High |
| 6 | **한글 폰트 유틸리티** - setup_korean_font() 함수 분리 | 10분 | 코드 중복 ↓ | Low |
| 7 | **통계 검정 함수화** - run_mannwhitney_test() 등 유틸리티 함수 | 30분 | 코드 중복 ↓ | Medium |
| 8 | **핵심 결과 강조** - print_key_result() 또는 Markdown 테이블 | 20분 | 가독성 ↑ | Medium |
| 9 | **축 레이블 단위 추가** - 모든 Plotly 차트에 단위 명시 | 20분 | 명확성 ↑ | Medium |
| 10 | **VIF 캐싱** - 사전 계산된 VIF 결과 저장/로딩 | 15분 | 발표 준비 ↑ | Medium |

**총 예상 시간: 3.5시간**

---

## 📋 상세 개선 항목 (10개 카테고리)

### 1. 코드 품질 및 실행 가능성

#### 1.1 매직 넘버 제거 (High Priority)

**문제점:**
- 통계 임계값 (0.001, 0.05)
- IV 분류 기준 (0.02, 0.1, 0.3, 0.5)
- Winsorize 경계값 (0.005, 0.995)
- 데이터 분할 비율 (0.2, 0.25)

**개선 방법:**
```python
# 노트북 최상단에 추가
# ============================================================================
# 설정 및 상수 정의
# ============================================================================

# 통계 검정 임계값
ALPHA_VERY_SIGNIFICANT = 0.001
ALPHA_SIGNIFICANT = 0.05

# Information Value 분류 기준
IV_THRESHOLDS = {
    'none': 0.02,
    'weak': 0.1,
    'medium': 0.3,
    'strong': 0.5
}

# 이상치 처리
WINSORIZE_LOWER_PERCENTILE = 0.005  # 하위 0.5%
WINSORIZE_UPPER_PERCENTILE = 0.995  # 상위 0.5%

# 데이터 분할
TEST_SIZE = 0.2   # 전체의 20%
VAL_SIZE = 0.25   # Train+Val의 25%
# 결과: Train 60%, Val 20%, Test 20%

# VIF 계산
VIF_INFINITE_REPLACEMENT = 999.0
VIF_HIGH_THRESHOLD = 10.0

# Random Seed
RANDOM_STATE = 42
```

**적용 위치:**
- Part 1: Cell 12 (Mann-Whitney U test)
- Part 2: Cell 24 (IV 분류), Cell 28 (VIF)
- Part 3: Cell 5 (train_test_split), Cell 7 (Winsorizer)

#### 1.2 경로 변수화 (High Priority)

**현재 문제:**
```python
df = pd.read_csv('../data/기업신용평가정보_210801.csv', encoding='utf-8')
all_features.to_csv('../data/features/domain_based_features_완전판.csv')
```

**개선 방법:**
```python
# 노트북 최상단에 추가
import os

# 경로 설정
BASE_DIR = os.path.dirname(os.path.abspath('.'))
DATA_DIR = os.path.join(BASE_DIR, 'data')
FEATURES_DIR = os.path.join(DATA_DIR, 'features')
PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')

# 파일명 설정
DATA_FILES = {
    'raw_data': os.path.join(DATA_DIR, '기업신용평가정보_210801.csv'),
    'features': {
        'domain': os.path.join(FEATURES_DIR, 'domain_based_features_v1.csv'),
        'metadata': os.path.join(FEATURES_DIR, 'feature_metadata_v1.csv')
    },
    'processed': {
        'model': os.path.join(PROCESSED_DIR, '발표_Part3_v3_최종모델.pkl'),
        'threshold': os.path.join(PROCESSED_DIR, '발표_Part3_v3_임계값.pkl'),
        'results': os.path.join(PROCESSED_DIR, '발표_Part3_v3_결과.pkl')
    }
}

# 사용
df = pd.read_csv(DATA_FILES['raw_data'], encoding='utf-8')
all_features.to_csv(DATA_FILES['features']['domain'], encoding='utf-8-sig')
```

#### 1.3 에러 처리 개선 (Medium Priority)

**현재 문제:**
```python
try:
    data_dict = pd.read_excel('../data/기업 CB 데이터 항목설명.xlsx')
except:  # ❌ Bare except
    print("⚠️ 파일을 찾을 수 없습니다")
```

**개선 방법:**
```python
try:
    data_dict_path = os.path.join(DATA_DIR, '기업 CB 데이터 항목설명.xlsx')
    data_dict = pd.read_excel(data_dict_path)
    print("✅ 데이터 딕셔너리 로딩 완료")
except FileNotFoundError:
    print(f"⚠️ 데이터 딕셔너리 파일을 찾을 수 없습니다: {data_dict_path}")
    data_dict = None
except Exception as e:
    print(f"⚠️ 데이터 딕셔너리 로딩 중 에러: {type(e).__name__}: {e}")
    data_dict = None
```

#### 1.4 코드 중복 제거 - 통계 검정 함수화 (Medium Priority)

**현재 문제:** Part 1에서 Mann-Whitney U test 코드가 여러 셀에서 반복

**개선 방법:**
```python
def run_mannwhitney_test(normal_values, bankrupt_values, metric_name,
                         alpha_very_sig=ALPHA_VERY_SIGNIFICANT,
                         alpha_sig=ALPHA_SIGNIFICANT):
    """
    Mann-Whitney U test를 수행하고 결과를 출력

    Parameters
    ----------
    normal_values : array-like
        정상 기업의 값
    bankrupt_values : array-like
        부도 기업의 값
    metric_name : str
        지표명
    alpha_very_sig : float, default=0.001
        매우 유의한 차이 임계값
    alpha_sig : float, default=0.05
        유의한 차이 임계값

    Returns
    -------
    statistic : float
        검정 통계량
    pvalue : float
        p-value
    """
    if len(normal_values) == 0 or len(bankrupt_values) == 0:
        print(f"{metric_name}: 데이터 부족")
        return None, None

    statistic, pvalue = mannwhitneyu(normal_values, bankrupt_values,
                                     alternative='two-sided')

    print(f"\n{metric_name}:")
    print(f"  정상 기업 평균: {normal_values.mean():.4f}")
    print(f"  부도 기업 평균: {bankrupt_values.mean():.4f}")
    print(f"  p-value: {pvalue:.4e}")

    if pvalue < alpha_very_sig:
        print(f"  ✅ 결론: *** 매우 유의한 차이 (p < {alpha_very_sig}) ***")
    elif pvalue < alpha_sig:
        print(f"  ✅ 결론: 유의한 차이 (p < {alpha_sig})")
    else:
        print(f"  ❌ 결론: 유의한 차이 없음 (p ≥ {alpha_sig})")

    return statistic, pvalue

# 사용
for metric in ['유동비율', '당좌비율', '현금비율']:
    normal = df[df[target_col] == 0][metric].dropna()
    bankrupt = df[df[target_col] == 1][metric].dropna()
    run_mannwhitney_test(normal, bankrupt, metric)
```

---

### 2. 데이터 전처리 일관성

#### 2.1 Data Leakage 수정 (High Priority) ⚠️ **가장 중요**

**문제점:**
Part 2 Cell 19 - Feature Validation 시 전체 데이터의 median 사용

**현재 코드:**
```python
# Part 2 - Cell 19
for feature in all_features.columns:
    # ❌ 전체 데이터의 median 사용 → Data Leakage!
    feature_data = all_features[feature].fillna(all_features[feature].median())
    auc = roc_auc_score(df[target_col], feature_data)
```

**개선 방법:**
```python
# Train/Val/Test Split 먼저 수행
from sklearn.model_selection import train_test_split

X_all = all_features.copy()
y_all = df[target_col].copy()

# Test 분리 (20%)
X_train_val, X_test_final, y_train_val, y_test_final = train_test_split(
    X_all, y_all, test_size=TEST_SIZE, stratify=y_all, random_state=RANDOM_STATE
)

# Train+Val 데이터만으로 median 계산
train_val_median = X_train_val.median()
X_train_val_clean = X_train_val.fillna(train_val_median)

# Feature Validation (Train+Val만 사용)
validation_results = []
for feature in X_train_val_clean.columns:
    feature_data = X_train_val_clean[feature]

    if feature_data.std() > 0:  # 분산이 있는 경우만
        try:
            auc = roc_auc_score(y_train_val, feature_data)
            validation_results.append({
                'Feature': feature,
                'AUC': auc
            })
        except Exception as e:
            print(f"⚠️ {feature} AUC 계산 실패: {e}")

validation_df = pd.DataFrame(validation_results).sort_values('AUC', ascending=False)
```

#### 2.2 무한대 처리 통일 (Medium Priority)

**문제점:**
- Part 2: `.replace([np.inf, -np.inf], 0)` (0으로 대체)
- Part 3: `InfiniteHandler` (nan으로 변환 후 Imputer)

**개선 방법:** Part 3 방식으로 통일

```python
# Part 2에서도 InfiniteHandler 사용
from sklearn.base import BaseEstimator, TransformerMixin

class InfiniteHandler(BaseEstimator, TransformerMixin):
    """무한대 값을 NaN으로 변환"""
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X_copy = X.copy()
        return X_copy.replace([np.inf, -np.inf], np.nan)

# Pipeline에 포함
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

preprocessing_pipeline = Pipeline([
    ('inf_handler', InfiniteHandler()),
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', RobustScaler())
])
```

---

### 3. 통계적 가정 검증

#### 3.1 정규성 검정 추가 (Medium Priority)

**문제점:** Mann-Whitney U test를 왜 사용하는지 근거 부족

**개선 방법:**
```python
from scipy.stats import shapiro

print("\n" + "="*80)
print("📊 정규성 검정 (Shapiro-Wilk Test)")
print("="*80)

for metric in ['유동비율', '당좌비율', '현금비율']:
    normal_values = df[df[target_col] == 0][metric].dropna()
    bankrupt_values = df[df[target_col] == 1][metric].dropna()

    # 샘플 크기 제한 (Shapiro는 5000개 제한)
    normal_sample = normal_values.sample(min(5000, len(normal_values)),
                                         random_state=RANDOM_STATE)
    bankrupt_sample = bankrupt_values.sample(min(5000, len(bankrupt_values)),
                                             random_state=RANDOM_STATE)

    stat_normal, p_normal = shapiro(normal_sample)
    stat_bankrupt, p_bankrupt = shapiro(bankrupt_sample)

    print(f"\n{metric}:")
    print(f"  정상 기업: p={p_normal:.4e} "
          f"({'정규분포' if p_normal >= 0.05 else '비정규분포'})")
    print(f"  부도 기업: p={p_bankrupt:.4e} "
          f"({'정규분포' if p_bankrupt >= 0.05 else '비정규분포'})")

    if p_normal < 0.05 or p_bankrupt < 0.05:
        print(f"  → 비모수 검정(Mann-Whitney U) 사용 근거 확립 ✅")
```

#### 3.2 Chi-square Test 가정 검증 (Low Priority)

**개선 방법:**
```python
# Chi-square Test 전에 가정 검증
chi2, p_value, dof, expected = chi2_contingency(contingency_table)

print("\n📝 Chi-square Test 가정 검증:")
print("  1. 관측값 독립성: ✅ 각 기업은 독립적인 관측값")
print(f"  2. 기대빈도 ≥ 5: ", end="")

if (expected >= 5).all():
    print("✅ 모든 셀에서 충족")
    print(f"\n  χ² = {chi2:.4f}, p-value = {p_value:.4e}")
else:
    low_freq_count = (expected < 5).sum()
    print(f"⚠️ {low_freq_count}개 셀에서 미충족")
    print(f"  → Fisher's Exact Test 고려 필요")
```

---

### 4. 시각화 디테일

#### 4.1 색상 팔레트 통일 (High Priority)

**문제점:** 노트북마다 다른 색상 사용

**개선 방법:**
```python
# 모든 노트북 최상단에 추가
# ============================================================================
# 시각화 색상 팔레트
# ============================================================================

COLOR_PALETTE = {
    # 기업 분류
    'normal': '#3498db',      # 파랑 (정상 기업)
    'bankrupt': '#e74c3c',    # 빨강 (부도 기업)

    # 위험도
    'high_risk': '#e74c3c',   # 빨강 (고위험)
    'medium_risk': '#f39c12', # 주황 (중위험)
    'low_risk': '#27ae60',    # 초록 (저위험)

    # 상태
    'good': '#2ecc71',        # 초록 (양호)
    'warning': '#f39c12',     # 주황 (경고)
    'danger': '#e74c3c',      # 빨강 (위험)

    # Traffic Light System
    'red': '#e74c3c',         # 대출 거절
    'yellow': '#f39c12',      # 신중 검토
    'green': '#27ae60'        # 대출 승인
}

# Plotly에서 사용
import plotly.graph_objects as go

fig = go.Figure()
fig.add_trace(go.Bar(
    name='정상기업',
    x=['유동비율', '당좌비율'],
    y=[1.5, 1.2],
    marker_color=COLOR_PALETTE['normal']
))
fig.add_trace(go.Bar(
    name='부도기업',
    x=['유동비율', '당좌비율'],
    y=[0.8, 0.6],
    marker_color=COLOR_PALETTE['bankrupt']
))
```

#### 4.2 축 레이블 단위 추가 (Medium Priority)

**개선 방법:**
```python
fig.update_layout(
    title='정상기업 vs 부도기업: 유동성 비교',
    xaxis_title='유동성 지표',
    yaxis_title='비율 (배수)',  # ✅ 단위 명시
    height=500,
    showlegend=True
)

# 또는 더 구체적으로
fig.update_layout(
    title='정상기업 vs 부도기업: 유동비율 및 당좌비율 비교',
    xaxis_title='유동성 지표',
    yaxis_title='비율 (유동자산/유동부채)',  # ✅ 계산식 명시
)
```

#### 4.3 한글 폰트 유틸리티 분리 (Low Priority)

**개선 방법:**
```python
# utils/visualization.py 생성
import platform
import matplotlib.pyplot as plt

def setup_korean_font():
    """한글 폰트 설정 (OS별 자동 선택)"""
    if platform.system() == 'Darwin':  # macOS
        plt.rc('font', family='AppleGothic')
    elif platform.system() == 'Windows':
        plt.rc('font', family='Malgun Gothic')
    else:  # Linux
        plt.rc('font', family='NanumGothic')

    plt.rc('axes', unicode_minus=False)
    print("✅ 한글 폰트 설정 완료")

def print_key_result(title, value, unit="", color="green"):
    """핵심 결과 강조 출력"""
    colors = {
        'green': '\033[92m',
        'yellow': '\033[93m',
        'red': '\033[91m',
        'blue': '\033[94m',
        'end': '\033[0m'
    }

    print(f"\n{'='*80}")
    print(f"{colors.get(color, '')}{title}: {value}{unit}{colors['end']}")
    print(f"{'='*80}\n")

# 노트북에서 사용
from utils.visualization import setup_korean_font, print_key_result

setup_korean_font()
print_key_result("🎯 최종 PR-AUC", f"{test_pr_auc:.4f}", color="green")
```

---

### 5. 노트북 간 데이터 흐름

#### 5.1 파일명 버전 통일 (High Priority)

**문제점:**
```
data/features/
├── domain_based_features.csv              # 구버전?
├── domain_based_features_완전판.csv       # 최신?
├── feature_metadata.csv
└── feature_metadata_완전판.csv
```

**개선 방법:**
```python
# 1. 버전 명시 파일명 사용
DATA_FILES = {
    'features': {
        'domain': '../data/features/domain_based_features_v1.csv',
        'metadata': '../data/features/feature_metadata_v1.csv'
    },
    'processed': {
        'model': '../data/processed/model_part3_v3.pkl',
        'threshold': '../data/processed/threshold_part3_v3.pkl',
        'results': '../data/processed/results_part3_v3.pkl'
    }
}

# 2. 구버전 파일 정리
# - domain_based_features.csv → domain_based_features_v0_deprecated.csv
# - domain_based_features_완전판.csv → domain_based_features_v1.csv
```

#### 5.2 중간 파일 저장 시 타임스탬프 (Medium Priority)

**개선 방법:**
```python
from datetime import datetime
import joblib

# 타임스탬프 추가
TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')

# 모델 저장
model_filename = f'model_part3_v3_{TIMESTAMP}.pkl'
joblib.dump(model, os.path.join(PROCESSED_DIR, model_filename))

# 최신 버전 심볼릭 링크 (또는 복사)
latest_filename = 'model_part3_v3_latest.pkl'
joblib.dump(model, os.path.join(PROCESSED_DIR, latest_filename))

print(f"✅ 모델 저장 완료:")
print(f"  - 버전: {model_filename}")
print(f"  - 최신: {latest_filename}")
```

---

### 6. 비즈니스 메트릭 연결

#### 6.1 ROI 계산 구체화 (High Priority)

**Part 4에 추가:**
```python
# ============================================================================
# 비즈니스 임팩트 상세 분석
# ============================================================================

print("\n" + "="*80)
print("💰 비즈니스 임팩트 ROI 계산")
print("="*80)

# 가정
total_loans = 10000  # 연간 대출 건수
avg_loan_amount = 5e8  # 건당 평균 대출액 5억원
DEFAULT_RATE = 0.015  # 부도율 1.5%
DEFAULT_LOSS_RATE = 0.67  # 손실률 67%
INTEREST_RATE = 0.05  # 이자율 5%

# 1. Baseline (모델 미사용)
print("\n1️⃣ Baseline (모델 미사용 시)")
total_loan_volume = total_loans * avg_loan_amount
expected_defaults = total_loans * DEFAULT_RATE
baseline_loss = expected_defaults * avg_loan_amount * DEFAULT_LOSS_RATE

print(f"  전체 대출: {total_loans:,}건 × {avg_loan_amount/1e8:.1f}억원 = {total_loan_volume/1e8:.0f}억원")
print(f"  부도율: {DEFAULT_RATE:.2%}")
print(f"  예상 부도 건수: {expected_defaults:.0f}건")
print(f"  예상 손실: {baseline_loss/1e8:.1f}억원")

# 2. With Model
print("\n2️⃣ With Model (예측 모델 적용)")

# Confusion Matrix 값 (실제 값으로 대체)
tp, fp, tn, fn = 123, 45, 9800, 32  # 예시 값

red_count = tp + fp  # Red 등급 대출 거절
prevented_loss = tp * avg_loan_amount * DEFAULT_LOSS_RATE
opportunity_loss = fp * avg_loan_amount * INTEREST_RATE

print(f"  Red 등급 대출 거절: {red_count:,}건")
print(f"  거절된 대출 중 실제 부도: {tp:,}건 (TP)")
print(f"  거절된 대출 중 정상 기업: {fp:,}건 (FP)")
print(f"  예방된 부도 손실: {prevented_loss/1e8:.1f}억원")
print(f"  기회 손실 (정상 거절): {opportunity_loss/1e8:.1f}억원")

net_improvement = prevented_loss - opportunity_loss
print(f"  순 개선 효과: {net_improvement/1e8:+.1f}억원")

# 3. ROI 계산
print("\n3️⃣ ROI 계산")
model_development_cost = 5000  # 만원 (인건비 + 인프라)
annual_operation_cost = 2000   # 만원 (유지보수 + 모니터링)
total_cost = model_development_cost + annual_operation_cost

roi = (net_improvement / 1e4 - total_cost) / total_cost * 100

print(f"  모델 개발 비용: {model_development_cost:,}만원")
print(f"  연간 운영 비용: {annual_operation_cost:,}만원")
print(f"  총 비용: {total_cost:,}만원")
print(f"  순 편익: {net_improvement/1e4:,.0f}만원")
print(f"  ROI: {roi:+.0f}%")

if roi > 0:
    payback_period = total_cost / (net_improvement / 1e4)
    print(f"  투자 회수 기간: {payback_period:.2f}개월")
```

#### 6.2 Type II Error 비즈니스 임팩트 (Medium Priority)

**Part 3 마지막에 추가:**
```python
print("\n" + "="*80)
print("⚠️ Type II Error (부도 미탐지) 비즈니스 임팩트")
print("="*80)

fn_count = fn  # Confusion Matrix에서
total_bankruptcies = tp + fn

type2_error_rate = fn / total_bankruptcies
print(f"총 부도 기업: {total_bankruptcies:,}건")
print(f"미탐지된 부도: {fn:,}건")
print(f"Type II Error Rate: {type2_error_rate:.2%}")

# 비즈니스 임팩트
avg_loss_per_bankruptcy = avg_loan_amount * DEFAULT_LOSS_RATE
total_missed_loss = fn * avg_loss_per_bankruptcy

print(f"\n💰 미탐지로 인한 손실:")
print(f"  건당 평균 손실: {avg_loss_per_bankruptcy/1e8:.2f}억원")
print(f"  총 미탐지 손실: {total_missed_loss/1e8:.1f}억원")

# 목표 대비 평가
target_type2 = 0.20
print(f"\n🎯 목표 달성 여부:")
print(f"  목표 Type II Error: ≤ {target_type2:.0%}")
print(f"  실제 Type II Error: {type2_error_rate:.2%}")

if type2_error_rate <= target_type2:
    print(f"  ✅ 목표 달성!")
else:
    gap = (type2_error_rate - target_type2) * total_bankruptcies
    print(f"  ❌ 목표 미달 ({gap:.0f}건 추가 탐지 필요)")
```

---

### 7. 재현성 검증

#### 7.1 RANDOM_STATE 전역 설정 (High Priority)

**모든 노트북 최상단에 추가:**
```python
# ============================================================================
# 재현성 설정
# ============================================================================

import numpy as np
import random

RANDOM_STATE = 42

# NumPy
np.random.seed(RANDOM_STATE)

# Python random
random.seed(RANDOM_STATE)

# scikit-learn (0.24+)
from sklearn.utils import check_random_state
check_random_state(RANDOM_STATE)

print(f"✅ Random Seed 설정 완료: {RANDOM_STATE}")
```

#### 7.2 패키지 버전 명시 (High Priority)

**모든 노트북 최상단에 추가:**
```python
# ============================================================================
# 환경 정보 출력
# ============================================================================

import sys
import pandas as pd
import numpy as np
import sklearn
import lightgbm as lgb
import xgboost as xgb
import plotly

print("="*80)
print("📦 패키지 버전 정보")
print("="*80)
print(f"Python: {sys.version}")
print(f"pandas: {pd.__version__}")
print(f"numpy: {np.__version__}")
print(f"scikit-learn: {sklearn.__version__}")
print(f"LightGBM: {lgb.__version__}")
print(f"XGBoost: {xgb.__version__}")
print(f"Plotly: {plotly.__version__}")
print("="*80)
```

**추가로 requirements.txt 생성:**
```bash
# 현재 환경의 패키지 버전 저장
pip freeze > requirements_발표노트북.txt
```

#### 7.3 의존성 체크 (Medium Priority)

**노트북 중간에 추가:**
```python
# ============================================================================
# 필수 변수 체크
# ============================================================================

REQUIRED_VARS = {
    'df': 'DataFrame',
    'target_col': 'str',
    'X_train': 'DataFrame/array',
    'y_train': 'Series/array'
}

print("🔍 환경 검증 중...")
missing_vars = []

for var, var_type in REQUIRED_VARS.items():
    if var not in locals() and var not in globals():
        missing_vars.append(f"{var} ({var_type})")

if missing_vars:
    print(f"❌ 필수 변수 누락: {', '.join(missing_vars)}")
    print(f"   이전 셀을 순서대로 실행하세요.")
    raise RuntimeError("필수 변수 누락")
else:
    print(f"✅ 모든 필수 변수 로딩 완료")
```

---

### 8. 문서화 품질

#### 8.1 복잡한 코드 주석 추가 (Medium Priority)

**Part 2 - Beneish M-Score 계산:**
```python
# ============================================================================
# Beneish M-Score 계산 (재무조작 탐지)
# ============================================================================
#
# 출처: Beneish, M. D. (1999). "The Detection of Earnings Manipulation"
#
# M-Score = -4.84 + 0.92*DSRI + 0.528*GMI + 0.404*AQI + 0.892*SGI +
#           0.115*DEPI - 0.172*SGAI + 4.679*TATA - 0.327*LVGI
#
# 각 변수 의미:
# - DSRI (Days Sales in Receivables Index): 매출채권 증가율
# - GMI (Gross Margin Index): 매출총이익률 하락
# - AQI (Asset Quality Index): 자산 품질 악화
# - SGI (Sales Growth Index): 매출 급성장
# - DEPI (Depreciation Index): 감가상각 감소
# - SGAI (SG&A Index): 판관비 증가
# - TATA (Total Accruals to Total Assets): 발생액 비율
# - LVGI (Leverage Index): 레버리지 증가
#
# 임계값: M-Score > -2.22 → 재무조작 의심 (정확도 76%)
# ============================================================================

# 한국형 M-Score (데이터 제약으로 대체 지표 사용)
m_score = -4.84  # 기본 상수

if '매출채권비율' in features.columns:
    # DSRI 대체: 매출채권 / 매출 비율
    m_score += features['매출채권비율'] * 0.92

if '재고_이상지표' in features.columns:
    # AQI 대체: 재고자산 / 총자산 비율
    m_score += features['재고_이상지표'] * 0.404

# ... (계속)

# 한국 시장 특성 반영 (경험적 조정)
features['M_Score_한국형'] = m_score - 2.22
features['재무조작_의심'] = (features['M_Score_한국형'] > 0).astype(int)

print("✅ Beneish M-Score 계산 완료")
print(f"  조작 의심 기업: {features['재무조작_의심'].sum():,}개 "
      f"({features['재무조작_의심'].mean()*100:.1f}%)")
```

#### 8.2 수식 LaTeX 표기 (Low Priority)

**Markdown 셀에서:**
```markdown
## 주요 재무 비율 정의

- **유동비율** (Current Ratio):
  $$\text{유동비율} = \frac{\text{유동자산}}{\text{유동부채}}$$

- **부채비율** (Debt Ratio):
  $$\text{부채비율} = \frac{\text{총부채}}{\text{자기자본}} \times 100$$

- **Beneish M-Score**:
  $$M = -4.84 + 0.92 \times DSRI + 0.528 \times GMI + \cdots$$

- **Information Value (IV)**:
  $$IV = \sum_{i=1}^{n} (\text{Good}_i\% - \text{Bad}_i\%) \times \ln\left(\frac{\text{Good}_i\%}{\text{Bad}_i\%}\right)$$
```

---

### 9. 성능 및 효율성

#### 9.1 VIF 계산 최적화 (Medium Priority)

**Part 2 - Cell 28:**
```python
# 샘플 크기 동적 조정
MIN_SAMPLE_SIZE = 1000
MAX_SAMPLE_SIZE = 5000

if len(all_features_clean) > MAX_SAMPLE_SIZE:
    sample_size = MAX_SAMPLE_SIZE
elif len(all_features_clean) < MIN_SAMPLE_SIZE:
    sample_size = len(all_features_clean)
else:
    sample_size = len(all_features_clean)

sample_pct = sample_size / len(all_features_clean) * 100
print(f"VIF 계산용 샘플: {sample_size:,}개 ({sample_pct:.1f}%)")

sample_data = all_features_clean.sample(n=sample_size, random_state=RANDOM_STATE)

# 진행률 표시
from tqdm import tqdm
import time

print("VIF 계산 중 (예상 소요 시간: 2-3분)...")
start_time = time.time()

vif_values = []
for i in tqdm(range(len(sample_data.columns)), desc="VIF 계산"):
    try:
        vif = variance_inflation_factor(sample_data.values, i)
        if np.isinf(vif) or np.isnan(vif):
            vif = VIF_INFINITE_REPLACEMENT
        vif_values.append(vif)
    except Exception as e:
        print(f"\n⚠️ Column {sample_data.columns[i]} VIF 계산 실패: {e}")
        vif_values.append(VIF_INFINITE_REPLACEMENT)

elapsed = time.time() - start_time
print(f"✅ VIF 계산 완료 (소요 시간: {elapsed:.1f}초)")
```

#### 9.2 특성 생성 최적화 (Low Priority)

**Part 2 - 특성 생성 함수화:**
```python
def create_all_features(df):
    """모든 도메인 특성 생성 (최적화된 버전)"""

    features_dict = {}

    # 1. 유동성 위기 특성 (10개)
    if all(col in df.columns for col in ['현금', '유동부채']):
        features_dict['즉각지급능력'] = (
            (df['현금'] + df.get('현금성자산', 0)) /
            (df['유동부채'] + 1)
        )
        features_dict['현금소진일수'] = (
            (df['현금'] + df.get('현금성자산', 0)) /
            (df.get('영업비용', df['매출원가']) / 365 + 1)
        )
        # ... 계속

    # 2. 지급불능 패턴 특성 (8개)
    # ...

    # DataFrame 한 번만 생성
    features_df = pd.DataFrame(features_dict, index=df.index)

    return features_df
```

---

### 10. 발표 준비도

#### 10.1 긴 실행 시간 셀 캐싱 (High Priority)

**Part 2 - VIF 계산:**
```python
import joblib
import os

# 캐시 디렉토리 생성
CACHE_DIR = '../cache'
os.makedirs(CACHE_DIR, exist_ok=True)

# 발표 모드 설정
USE_CACHED_RESULTS = True  # 발표 시 True, 개발 시 False

vif_cache_file = os.path.join(CACHE_DIR, 'vif_results.pkl')

if USE_CACHED_RESULTS and os.path.exists(vif_cache_file):
    print("📂 캐시된 VIF 결과 로딩 중...")
    vif_df = joblib.load(vif_cache_file)
    print(f"✅ 로딩 완료 (0.1초)")
else:
    print("🔄 VIF 계산 중 (2-3분 소요)...")
    # ... (VIF 계산 코드)

    # 결과 캐싱
    joblib.dump(vif_df, vif_cache_file)
    print(f"💾 결과 캐시 저장: {vif_cache_file}")
```

**Part 3 - AutoML:**
```python
automl_cache_file = os.path.join(CACHE_DIR, 'automl_results.pkl')

if USE_CACHED_RESULTS and os.path.exists(automl_cache_file):
    print("📂 캐시된 AutoML 결과 로딩 중...")
    auto_result = joblib.load(automl_cache_file)
    print(f"✅ 로딩 완료")
else:
    print("🔄 AutoML 실행 중 (예상 소요: 10-20분)...")
    auto_result = auto.fit(X_train, y_train)

    joblib.dump(auto_result, automl_cache_file)
    print(f"💾 결과 캐시 저장")
```

#### 10.2 출력 길이 제한 (Medium Priority)

**Part 2 - Smart Feature Selection:**
```python
MAX_DISPLAY_FEATURES = 10

high_vif_sorted = high_vif.sort_values('VIF', ascending=False)
display_vif = high_vif_sorted.head(MAX_DISPLAY_FEATURES)

print(f"\n📊 VIF > {VIF_HIGH_THRESHOLD}인 특성 상위 {MAX_DISPLAY_FEATURES}개")
print(f"    (총 {len(high_vif)}개)")
print("="*80)

for idx, row in display_vif.iterrows():
    print(f"\n{row['Feature']}")
    print(f"  VIF: {row['VIF']:.2f}")
    print(f"  IV:  {row['IV']:.4f}")
    print(f"  AUC: {row['AUC']:.4f}")
    # ... (결정 로직)

if len(high_vif) > MAX_DISPLAY_FEATURES:
    print(f"\n... 외 {len(high_vif) - MAX_DISPLAY_FEATURES}개 특성")
    print(f"    (상세 내용은 로그 파일 참조)")
```

#### 10.3 워닝 필터링 개선 (Medium Priority)

**Part 3:**
```python
import warnings

# ❌ 나쁜 방법
# warnings.filterwarnings('ignore')  # 모든 경고 숨김

# ✅ 좋은 방법 - 특정 경고만 필터링
warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')
warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')

# 또는 컨텍스트 매니저로
with warnings.catch_warnings():
    warnings.filterwarnings('ignore', category=UserWarning)
    # AutoML 실행
    auto_result = auto.fit(X_train, y_train)
```

#### 10.4 핵심 결과 강조 (High Priority)

**Part 3 마지막 셀:**
```markdown
# ============================================================================
# 🎯 Part 3 핵심 성과 요약
# ============================================================================

| 평가 지표 | 값 | 목표 | 달성 여부 |
|-----------|-----|------|-----------|
| **PR-AUC (Test)** | **0.7542** | ≥ 0.70 | ✅ |
| **Recall (Test)** | **82.3%** | ≥ 80% | ✅ |
| **Precision (Test)** | **15.2%** | - | - |
| **F2-Score (Test)** | **0.6891** | ≥ 0.65 | ✅ |
| **Type II Error** | **17.7%** | ≤ 20% | ✅ |

---

## 선택된 최종 모델

- **모델**: Voting Ensemble (LightGBM + XGBoost + CatBoost)
- **전처리**: Winsorizer(0.5%/99.5%) + RobustScaler
- **리샘플링**: SMOTE (k_neighbors=3)
- **임계값**: 0.XX (Recall 80% 기준)

---

## 주요 개선 사항 (v3)

1. ✅ **Priority 1**: Winsorizer True 적용 → PR-AUC +0.03
2. ✅ **Priority 2**: SMOTE 사용 → Recall +5%
3. ✅ **Priority 3**: Voting Ensemble → 안정성 향상

---

## Next Steps → Part 4

- SHAP 분석으로 특성 중요도 해석
- False Negative 케이스 분석
- 비즈니스 임팩트 계산 (ROI)
```

---

## 📅 우선순위별 작업 계획

### 🔥 High Priority (즉시 수정 필수) - 3.5시간

| 순위 | 작업 | 위치 | 예상 시간 | 비고 |
|------|------|------|-----------|------|
| 1 | **Data Leakage 수정** | Part 2 Cell 19 | 1시간 | 가장 심각 |
| 2 | **매직 넘버 → 상수 정의** | 모든 노트북 최상단 | 1시간 | 코드 품질 |
| 3 | **비즈니스 가정 config 분리** | Part 4 | 30분 | 유지보수성 |
| 4 | **RANDOM_STATE 통일** | 모든 노트북 | 20분 | 재현성 |
| 5 | **패키지 버전 출력** | 모든 노트북 | 15분 | 재현성 |
| 6 | **경로 변수화** | 모든 노트북 | 30분 | 유지보수성 |
| 7 | **색상 팔레트 통일** | 모든 노트북 | 20분 | 전문성 |
| 8 | **VIF/AutoML 캐싱** | Part 2, 3 | 15분 | 발표 준비 |

### ⚡ Medium Priority (발표 전 권장) - 4시간

| 작업 | 위치 | 예상 시간 |
|------|------|-----------|
| 통계 검정 함수화 | Part 1 | 1시간 |
| 정규성 검정 추가 | Part 1 | 30분 |
| 축 레이블 단위 추가 | 모든 시각화 | 30분 |
| 출력 길이 제한 | Part 2 | 30분 |
| ROI 계산 상세화 | Part 4 | 1시간 |
| Type II Error 임팩트 | Part 3 | 30분 |
| 주석 및 문서화 | Part 2 (M-Score) | 1시간 |

### 💡 Low Priority (시간 여유 시) - 2.5시간

| 작업 | 예상 시간 |
|------|-----------|
| 한글 폰트 유틸리티 분리 | 15분 |
| LaTeX 수식 표기 | 30분 |
| 용어 정의 통일 | 15분 |
| 에러 처리 개선 | 30분 |
| 특성 생성 최적화 | 1시간 |

---

## 🎯 최종 권장 작업 순서

### Phase 1: 즉시 수정 (발표 전 필수)
1. **Part 2 Data Leakage 수정** (1시간)
2. **모든 노트북 상수 정의** (1시간)
3. **RANDOM_STATE + 패키지 버전** (35분)
4. **경로 + 색상 통일** (50분)

**Phase 1 소계: 3.5시간**

### Phase 2: 발표 준비 (발표 당일 아침)
1. **VIF/AutoML 결과 캐싱** (15분)
2. **핵심 결과 강조 Markdown** (20분)
3. **전체 노트북 순서대로 실행 검증** (30분)

**Phase 2 소계: 1시간**

### Phase 3: 추가 개선 (시간 여유 시)
1. **ROI 계산 상세화** (1시간)
2. **통계 검정 함수화** (1시간)
3. **문서화 보완** (1시간)

**Phase 3 소계: 3시간**

---

## 📊 개선 후 예상 점수

| 평가 차원 | 현재 | 개선 후 | 증가 |
|----------|------|---------|------|
| 설명 가능성 | 22.5 | 24 | +1.5 |
| 스토리텔링 | 18.75 | 19 | +0.25 |
| 시각화+해석 | 18 | 19 | +1 |
| 도메인 전문성 | 14 | 14.5 | +0.5 |
| 통계적 엄격성 | 9.25 | 9.5 | +0.25 |
| 재현 가능성 | 5 | 5 | 0 |
| **한계 인정** | **2.75** | **4.5** | **+1.75** |
| **총점** | **90.25** | **95.5** | **+5.25** |

**목표 87점 대비: +8.5점 초과 달성 예상**

---

## 💾 체크리스트

### 발표 전날
- [ ] Phase 1 모든 작업 완료
- [ ] VIF/AutoML 결과 캐싱 완료
- [ ] 전체 노트북 순서대로 실행 테스트
- [ ] 모든 시각화 한글 폰트 확인
- [ ] 핵심 결과 강조 Markdown 추가

### 발표 당일 아침
- [ ] 캐시 파일 존재 확인
- [ ] USE_CACHED_RESULTS = True 설정
- [ ] 각 노트북 1회 실행 (10분 이내)
- [ ] 모든 출력 정상 확인

### 발표 중
- [ ] 셀 실행 없이 스크롤만 사용
- [ ] 핵심 결과 섹션만 강조
- [ ] 한계 섹션 솔직하게 설명

---

## 🔗 참고 자료

- 원본 분석 보고서: `docs/발표노트북_개선점_종합분석.md` (이 파일)
- 프로젝트 가이드: `CLAUDE.md`
- 노트북 요약: `docs/notebook_summaries/`
- 개선 전 평가: 90.25/100
- 개선 후 예상: 95.5/100

---

**작성자**: Claude Code
**최종 수정**: 2025-11-22
