# ğŸ“— Part 2: ë„ë©”ì¸ íŠ¹ì„± ê³µí•™ - ì™„ì „íŒ

> **ì‹œë‹ˆì–´ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì˜ ì¬ë¬´ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ Feature Engineering**

---

## ğŸ“Œ ì´ì „ Part ìš”ì•½

Part 1ì—ì„œ ìš°ë¦¬ëŠ” ë‹¤ìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤:

### âœ… ì£¼ìš” ë°œê²¬ì‚¬í•­

1. **ìœ ë™ì„±ì´ ê°€ì¥ ê°•ë ¥í•œ ì˜ˆì¸¡ ë³€ìˆ˜**
   - ìœ ë™ë¹„ìœ¨, ë‹¹ì¢Œë¹„ìœ¨, í˜„ê¸ˆë¹„ìœ¨ â†’ ë¶€ë„ ê¸°ì—…ê³¼ ì •ìƒ ê¸°ì—… ê°„ ëª…í™•í•œ ì°¨ì´
   - Mann-Whitney U test: p < 0.001

2. **ì—…ì¢…ë³„ ë¶€ë„ìœ¨ 2ë°° ì°¨ì´**
   - ê±´ì„¤ì—… 2.8% vs ê¸ˆìœµì—… 0.9%
   - ì œì¡°ì—… ì¤‘ì‹¬ ì‚°ì—…êµ¬ì¡°ì˜ ìœ„í—˜ì„±

3. **ì™¸ê° ì—¬ë¶€ê°€ ì¤‘ìš”**
   - ì™¸ê° ëŒ€ìƒ ê¸°ì—…ì˜ ë¶€ë„ìœ¨ì´ ë” ë‚®ìŒ
   - íšŒê³„ ì‹ ë¢°ì„±ì´ ë¶€ë„ ì˜ˆì¸¡ì— ì˜í–¥

### âŒ í•œê³„ì 

- **ë‹¨ë³€ëŸ‰ ì˜ˆì¸¡ë ¥ ì œí•œì ** (AUC < 0.7)
  - ê°œë³„ ì¬ë¬´ ë¹„ìœ¨ë§Œìœ¼ë¡œëŠ” ë¶€ë„ ì˜ˆì¸¡ ë¶ˆì¶©ë¶„
  - ì—¬ëŸ¬ ë³€ìˆ˜ë¥¼ ê²°í•©í•œ ë³µí•© ì§€í‘œ í•„ìš”

- **ë³€ìˆ˜ ê°„ ìƒí˜¸ì‘ìš© ë¯¸ê³ ë ¤**
  - ìœ ë™ì„± Ã— ìˆ˜ìµì„±, ë ˆë²„ë¦¬ì§€ Ã— ì„±ì¥ì„± ë“±
  - ë¹„ì„ í˜• ê´€ê³„ í¬ì°© í•„ìš”

**â†’ ì´ì œ ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•œ ë³µí•© íŠ¹ì„±ì„ ìƒì„±í•©ë‹ˆë‹¤.**

---

## ğŸ¯ Why: ì™œ ë„ë©”ì¸ íŠ¹ì„±ì´ í•„ìš”í•œê°€?

### 1ï¸âƒ£ ë¬¸ì œ ì¸ì‹: ì›ë³¸ ë°ì´í„°ì˜ í•œê³„

**ì›ë³¸ ë°ì´í„° (159ê°œ ë³€ìˆ˜)ì˜ ë¬¸ì œì :**

- âŒ **ì •ì  ìŠ¤ëƒ…ìƒ·ì— ë¶ˆê³¼**: ì¬ë¬´ì œí‘œ í•­ëª© ì¤‘ì‹¬ (ìì‚°, ë¶€ì±„, ë§¤ì¶œ ë“±) â†’ íŠ¹ì • ì‹œì ì˜ ì¬ë¬´ ìƒíƒœë§Œ ë³´ì—¬ì¤Œ
- âŒ **ë¶€ë„ì˜ "ì›ì¸"ì„ ì§ì ‘ ì„¤ëª…í•˜ì§€ ëª»í•¨**: "ìœ ë™ìì‚° = 1ì–µì›"ì´ë¼ëŠ” ì •ë³´ë§Œìœ¼ë¡œëŠ” ê¸°ì—…ì´ ìœ„í—˜í•œì§€ ì•Œ ìˆ˜ ì—†ìŒ
- âŒ **í•œêµ­ ì‹œì¥ íŠ¹ì„± ë¯¸ë°˜ì˜**: ì™¸ë¶€ê°ì‚¬ ì˜ë¬´, ì œì¡°ì—… ì¤‘ì‹¬ ì‚°ì—…êµ¬ì¡°, ëŒ€ê¸°ì—… ì˜ì¡´ë„ ë“± í•œêµ­ íŠ¹ìœ ì˜ ë¦¬ìŠ¤í¬ ìš”ì¸ ëˆ„ë½

**ì˜ˆì‹œë¡œ ë³´ëŠ” í•œê³„:**
```
ê¸°ì—… A: ìœ ë™ìì‚° 1ì–µì›, ìœ ë™ë¶€ì±„ 5ì²œë§Œì›
â†’ ì´ê²ƒë§Œìœ¼ë¡œëŠ” ì•ˆì „í•œì§€ ìœ„í—˜í•œì§€ íŒë‹¨ ë¶ˆê°€
â†’ ìœ ë™ë¹„ìœ¨(200%)ì„ ê³„ì‚°í•´ì•¼ í•¨ â†’ í•˜ì§€ë§Œ ì´ê²ƒë„ ë¶€ì¡±
â†’ í˜„ê¸ˆë¹„ìœ¨, í˜„ê¸ˆì†Œì§„ì¼ìˆ˜, ìš´ì „ìë³¸ íšŒì „ìœ¨ ë“± ì¶”ê°€ ì§€í‘œ í•„ìš”
```

**ê²°ë¡ : ì›ë³¸ ë°ì´í„°ëŠ” "ì¬ë£Œ"ì¼ ë¿, "ë¶€ë„ ìœ„í—˜"ì„ ì§ì ‘ ì¸¡ì •í•˜ëŠ” "ì§€í‘œ"ê°€ ì•„ë‹˜**

---

### 2ï¸âƒ£ ë„ë©”ì¸ ì§€ì‹: ê¸°ì—…ì´ ë¶€ë„ë‚˜ëŠ” 3ê°€ì§€ ê²½ë¡œ

**í•™ê³„ ë° ì‹¤ë¬´ ì—°êµ¬ ê¸°ë°˜ (Altman 1968; Ohlson 1980; í•œêµ­ì€í–‰ 2020)**

#### ğŸ”´ ê²½ë¡œ 1: ìœ ë™ì„± ìœ„ê¸° (Liquidity Crisis) - **ë¶€ë„ì˜ 70%**

**ì •ì˜:** í˜„ê¸ˆì´ ê³ ê°ˆë˜ì–´ ë‹¨ê¸° ì±„ë¬´ë¥¼ ê°šì§€ ëª»í•˜ëŠ” ìƒí™©

**íŠ¹ì§•:**
- ì¥ë¶€ìƒ í‘ìì—¬ë„ ë°œìƒ ê°€ëŠ¥ (**í‘ìë„ì‚°**)
- ë§¤ì¶œì€ ìˆì§€ë§Œ í˜„ê¸ˆ íšŒìˆ˜ê°€ ëŠ¦ì–´ì§€ë©´ ë¶€ë„
- ë¶€ë„ ë°œìƒ **3ê°œì›” ì „**ì— ê¸‰ê²©íˆ ì•…í™”ë˜ëŠ” ì§€í‘œë“¤

**ìœ„í—˜ ì‹ í˜¸:**
- í˜„ê¸ˆì†Œì§„ì¼ìˆ˜ < 30ì¼ (í•œ ë‹¬ë„ ëª» ë²„íŒ€)
- ìœ ë™ë¹„ìœ¨ < 100% (ë‹¨ê¸° ë¶€ì±„ê°€ ìœ ë™ìì‚°ë³´ë‹¤ ë§ìŒ)
- ìš´ì „ìë³¸ ìŒìˆ˜ (ìœ ë™ë¶€ì±„ > ìœ ë™ìì‚°)

#### ğŸŸ  ê²½ë¡œ 2: ì§€ê¸‰ë¶ˆëŠ¥ (Insolvency) - **ë¶€ë„ì˜ 20%**

**ì •ì˜:** ë¶€ì±„ê°€ ìì‚°ì„ ì´ˆê³¼í•˜ì—¬ êµ¬ì¡°ì ìœ¼ë¡œ íšŒìƒ ë¶ˆê°€ëŠ¥í•œ ìƒí™©

**ìœ„í—˜ ì‹ í˜¸:**
- ìë³¸ì ì‹ë„ > 50% (ìë³¸ì˜ ì ˆë°˜ ì´ìƒ ì†ì‹¤)
- ì´ìë³´ìƒë°°ìœ¨ < 1.0 (ì˜ì—…ì´ìµ < ì´ìë¹„ìš©)
- ë¶€ì±„ìƒí™˜ë…„ìˆ˜ > 10ë…„ (í˜„ê¸ˆíë¦„ìœ¼ë¡œ ë¶€ì±„ ìƒí™˜ ë¶ˆê°€)

#### ğŸŸ¡ ê²½ë¡œ 3: ì‹ ë¢° ìƒì‹¤ (Loss of Confidence) - **ë¶€ë„ì˜ 10%**

**ì •ì˜:** ì—°ì²´Â·ì²´ë‚© ì´ë ¥ìœ¼ë¡œ ê¸ˆìœµê¸°ê´€ê³¼ ê±°ë˜ì²˜ê°€ ìê¸ˆì¤„ì„ ì°¨ë‹¨

**ìœ„í—˜ ì‹ í˜¸:**
- ì—°ì²´ ì´ë ¥ 1íšŒ ì´ìƒ
- ì„¸ê¸ˆ ì²´ë‚© ë°œìƒ
- ì‹ ìš©ë“±ê¸‰ BB ì´í•˜ (ë“±ê¸‰ 5 ì´ìƒ)

---

### 3ï¸âƒ£ íŠ¹ì„± ê³µí•™ ì „ëµ: ê²½ë¡œë³„ ì¡°ê¸° ê°ì§€ ì§€í‘œ ê°œë°œ

**ëª©í‘œ:** ë¶€ë„ 3~6ê°œì›” ì „ì— ë¯¸ë¦¬ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ì‹ í˜¸ í¬ì°©

| ì¹´í…Œê³ ë¦¬ | íŠ¹ì„± ìˆ˜ | ëª©ì  | ëŒ€í‘œ ì§€í‘œ | ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆë¬¸ |
|----------|---------|------|-----------|---------------|
| **ìœ ë™ì„± ìœ„ê¸°** | 10ê°œ | ë‹¨ê¸° ìƒì¡´ ê°€ëŠ¥ì„± | í˜„ê¸ˆì†Œì§„ì¼ìˆ˜, ìš´ì „ìë³¸ë¹„ìœ¨ | "3ê°œì›” ë‚´ ì‚´ì•„ë‚¨ì„ ìˆ˜ ìˆëŠ”ê°€?" |
| **ì§€ê¸‰ë¶ˆëŠ¥** | 11ê°œ | ì¥ê¸° íšŒìƒ ê°€ëŠ¥ì„± | ìë³¸ì ì‹ë„, ë¶€ì±„ìƒí™˜ë…„ìˆ˜ | "êµ¬ì¡°ì ìœ¼ë¡œ íšŒìƒ ê°€ëŠ¥í•œê°€?" |
| **ì¬ë¬´ì¡°ì‘ íƒì§€** | 15ê°œ | íšŒê³„ ì‹ ë¢°ì„± ê²€ì¦ | M-Score, ë°œìƒì•¡ í’ˆì§ˆ | "ì¬ë¬´ì œí‘œë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€?" |
| **ì´í•´ê´€ê³„ì í–‰ë™** | 10ê°œ | ì‹ ìš© í–‰ë™ íŒ¨í„´ | ì—°ì²´, ì‹ ìš©ë“±ê¸‰ | "ì´ ê¸°ì—…ì„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€?" |
| **í•œêµ­ ì‹œì¥ íŠ¹í™”** | 6ê°œ | í•œêµ­ ê¸°ì—… íŠ¹ì„± | ì™¸ê° ì—¬ë¶€, ì œì¡°ì—… ë¦¬ìŠ¤í¬ | "í•œêµ­ ì‹œì¥ì˜ ìœ„í—˜ì„ ë°˜ì˜í–ˆëŠ”ê°€?" |

**ì´ 50+ ê°œ íŠ¹ì„± ìƒì„±**

#### ğŸ¯ ì™œ í†µê³„ì  íŠ¹ì„±ì´ ì•„ë‹Œ ë„ë©”ì¸ íŠ¹ì„±ì¸ê°€?

**ë„ë©”ì¸ ì ‘ê·¼ì˜ ì¥ì :**
- âœ… **í•´ì„ ê°€ëŠ¥**: "í˜„ê¸ˆì†Œì§„ì¼ìˆ˜ê°€ 15ì¼ì´ë¼ ìœ„í—˜í•©ë‹ˆë‹¤"
- âœ… **ì‹¤ë¬´ ì ìš©**: ì‹¬ì‚¬ ê¸°ì¤€ìœ¼ë¡œ ì§ì ‘ í™œìš© ê°€ëŠ¥
- âœ… **ë…¼ë¦¬ì  ì„¤ë“ë ¥**: "ì™œ ì´ ì§€í‘œê°€ ì¤‘ìš”í•œê°€?"ì— ëŒ€í•œ ì´ë¡ ì  ê·¼ê±° ì¡´ì¬

---

## ğŸ”§ íŠ¹ì„± ìƒì„± ì‹¤ìŠµ

### í™˜ê²½ ì„¤ì •

```python
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import mannwhitneyu
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import StandardScaler
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
if platform.system() == 'Darwin':
    plt.rc('font', family='AppleGothic')
elif platform.system() == 'Windows':
    plt.rc('font', family='Malgun Gothic')
else:
    plt.rc('font', family='NanumGothic')
plt.rc('axes', unicode_minus=False)

# ë°ì´í„° ë¡œë”©
df = pd.read_csv('../data/ê¸°ì—…ì‹ ìš©í‰ê°€ì •ë³´_210801.csv', encoding='utf-8')
target_col = 'ëª¨í˜•ê°œë°œìš©Performance(í–¥í›„1ë…„ë‚´ë¶€ë„ì—¬ë¶€)'

print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {df.shape[0]:,} ê¸°ì—…, {df.shape[1]:,} ë³€ìˆ˜")
print(f"âœ… ë¶€ë„ìœ¨: {df[target_col].mean()*100:.2f}%")
```

**ì¶œë ¥:**
```
âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: 50,105 ê¸°ì—…, 159 ë³€ìˆ˜
âœ… ë¶€ë„ìœ¨: 1.54%
```

---

## ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì„± ìƒì„±

### ì¹´í…Œê³ ë¦¬ 1: ìœ ë™ì„± ìœ„ê¸° íŠ¹ì„± (10ê°œ)

**ğŸ’¡ ì™œ ìœ ë™ì„±ì´ ê°€ì¥ ì¤‘ìš”í•œê°€?**

ê²½ì œì  ê°€ì„¤: "ë¶€ë„ëŠ” ì§€ê¸‰ë¶ˆëŠ¥ì´ ì•„ë‹Œ ìœ ë™ì„± ìœ„ê¸°ë¡œ ì‹œì‘ëœë‹¤"

**í•™ìˆ ì  ë°°ê²½ (Whitaker 1999):**
- ë¶€ë„ ê¸°ì—…ì˜ **67%ëŠ” í‘ì**ì˜€ìŒ (ì¥ë¶€ìƒ ì´ìµ ë°œìƒ)
- í•˜ì§€ë§Œ **í˜„ê¸ˆì´ ì—†ì–´ì„œ** ê¸‰ì—¬/ì„¸ê¸ˆ/ì´ìë¥¼ ì§€ê¸‰í•˜ì§€ ëª»í•¨
- ìœ ë™ì„± ìœ„ê¸°ëŠ” ë¶€ë„ **3~6ê°œì›” ì „**ì— ë‚˜íƒ€ë‚¨

```python
def create_liquidity_crisis_features(df):
    """ìœ ë™ì„± ìœ„ê¸°ë¥¼ ì¡°ê¸°ì— ê°ì§€í•˜ëŠ” íŠ¹ì„± ìƒì„±"""

    features = pd.DataFrame(index=df.index)

    # 1. ì¦‰ê°ì  ì§€ê¸‰ëŠ¥ë ¥
    if 'í˜„ê¸ˆ' in df.columns and 'ìœ ë™ë¶€ì±„' in df.columns:
        features['ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥'] = (df['í˜„ê¸ˆ'] + df.get('í˜„ê¸ˆì„±ìì‚°', 0)) / (df['ìœ ë™ë¶€ì±„'] + 1)
        features['í˜„ê¸ˆì†Œì§„ì¼ìˆ˜'] = (df['í˜„ê¸ˆ'] + df.get('í˜„ê¸ˆì„±ìì‚°', 0)) / (df.get('ì˜ì—…ë¹„ìš©', df['ë§¤ì¶œì›ê°€']) / 365 + 1)

    # 2. ìš´ì „ìë³¸ ê±´ì „ì„±
    if 'ìœ ë™ìì‚°' in df.columns and 'ìœ ë™ë¶€ì±„' in df.columns:
        features['ìš´ì „ìë³¸'] = df['ìœ ë™ìì‚°'] - df['ìœ ë™ë¶€ì±„']
        features['ìš´ì „ìë³¸ë¹„ìœ¨'] = features['ìš´ì „ìë³¸'] / (df.get('ë§¤ì¶œì•¡', 1) + 1)
        features['ìš´ì „ìë³¸_ëŒ€_ìì‚°'] = features['ìš´ì „ìë³¸'] / (df.get('ìì‚°ì´ê³„', 1) + 1)

    # 3. ê¸´ê¸‰ ìê¸ˆì¡°ë‹¬ ì—¬ë ¥
    if 'ë§¤ì¶œì±„ê¶Œ' in df.columns and 'ë‹¨ê¸°ì°¨ì…ê¸ˆ' in df.columns:
        features['ê¸´ê¸‰ìœ ë™ì„±'] = (df['í˜„ê¸ˆ'] + df.get('í˜„ê¸ˆì„±ìì‚°', 0) + df['ë§¤ì¶œì±„ê¶Œ'] * 0.8) / (df['ë‹¨ê¸°ì°¨ì…ê¸ˆ'] + 1)

    # 4. ìœ ë™ì„± ì••ë°• ì§€í‘œ
    if 'ìœ ë™ë¶€ì±„' in df.columns and 'ë¶€ì±„ì´ê³„' in df.columns:
        features['ìœ ë™ì„±ì••ë°•ì§€ìˆ˜'] = (df['ìœ ë™ë¶€ì±„'] / (df['ìœ ë™ìì‚°'] + 1)) * (df['ë¶€ì±„ì´ê³„'] / (df['ìì‚°ì´ê³„'] + 1))

    # 5. í˜„ê¸ˆíë¦„ ê¸°ë°˜ ìœ ë™ì„±
    if 'ì˜ì—…í™œë™í˜„ê¸ˆíë¦„' in df.columns:
        features['OCF_ëŒ€_ìœ ë™ë¶€ì±„'] = df['ì˜ì—…í™œë™í˜„ê¸ˆíë¦„'] / (df.get('ìœ ë™ë¶€ì±„', 1) + 1)
        features['í˜„ê¸ˆì°½ì¶œëŠ¥ë ¥'] = df['ì˜ì—…í™œë™í˜„ê¸ˆíë¦„'] / (df.get('ë§¤ì¶œì•¡', 1) + 1)

    print(f"âœ… ìœ ë™ì„± ìœ„ê¸° íŠ¹ì„± {features.shape[1]}ê°œ ìƒì„± ì™„ë£Œ")
    return features

liquidity_features = create_liquidity_crisis_features(df)
print("\nìƒì„±ëœ ìœ ë™ì„± íŠ¹ì„±:")
print(liquidity_features.columns.tolist())
```

**ì¶œë ¥:**
```
âœ… ìœ ë™ì„± ìœ„ê¸° íŠ¹ì„± 9ê°œ ìƒì„± ì™„ë£Œ

ìƒì„±ëœ ìœ ë™ì„± íŠ¹ì„±:
['ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥', 'í˜„ê¸ˆì†Œì§„ì¼ìˆ˜', 'ìš´ì „ìë³¸', 'ìš´ì „ìë³¸ë¹„ìœ¨', 'ìš´ì „ìë³¸_ëŒ€_ìì‚°',
 'ê¸´ê¸‰ìœ ë™ì„±', 'ìœ ë™ì„±ì••ë°•ì§€ìˆ˜', 'OCF_ëŒ€_ìœ ë™ë¶€ì±„', 'í˜„ê¸ˆì°½ì¶œëŠ¥ë ¥']
```

---

### ì¹´í…Œê³ ë¦¬ 2: ì§€ê¸‰ë¶ˆëŠ¥ íŒ¨í„´ íŠ¹ì„± (11ê°œ)

**ğŸ’¡ ìœ ë™ì„± ìœ„ê¸° vs ì§€ê¸‰ë¶ˆëŠ¥**

**ì°¨ì´ì :**
- **ìœ ë™ì„± ìœ„ê¸°**: ì¼ì‹œì  í˜„ê¸ˆ ë¶€ì¡± (ë‹¨ê¸° ë¬¸ì œ)
- **ì§€ê¸‰ë¶ˆëŠ¥**: êµ¬ì¡°ì  ë¶€ì±„ ì´ˆê³¼ (ì¥ê¸° ë¬¸ì œ)

**ê²½ì œì  ê°€ì„¤: "ìë³¸ì ì‹ + ê³¼ë‹¤ë¶€ì±„ = íšŒìƒ ë¶ˆê°€ëŠ¥"**

```python
def create_insolvency_features(df):
    """ì§€ê¸‰ë¶ˆëŠ¥ ìœ„í—˜ì„ í¬ì°©í•˜ëŠ” íŠ¹ì„± ìƒì„±"""

    features = pd.DataFrame(index=df.index)

    # 1. ìë³¸ ì ì‹ë„
    if 'ìë³¸ì´ê³„' in df.columns:
        features['ìë³¸ì ì‹ì—¬ë¶€'] = (df['ìë³¸ì´ê³„'] < 0).astype(int)
        features['ìë³¸ì ì‹ë„'] = np.where(df.get('ë‚©ì…ìë³¸ê¸ˆ', 1) > 0,
                                       np.maximum(0, 1 - df['ìë³¸ì´ê³„'] / df.get('ë‚©ì…ìë³¸ê¸ˆ', 1)), 0)

    # 2. ì°¨ì…ê¸ˆ ì˜ì¡´ë„
    if 'ë‹¨ê¸°ì°¨ì…ê¸ˆ' in df.columns and 'ì¥ê¸°ì°¨ì…ê¸ˆ' in df.columns:
        features['ì´ì°¨ì…ê¸ˆ'] = df['ë‹¨ê¸°ì°¨ì…ê¸ˆ'] + df['ì¥ê¸°ì°¨ì…ê¸ˆ']
        features['ì°¨ì…ê¸ˆì˜ì¡´ë„'] = features['ì´ì°¨ì…ê¸ˆ'] / (df.get('ìì‚°ì´ê³„', 1) + 1)
        features['ì°¨ì…ê¸ˆ_ëŒ€_ë§¤ì¶œ'] = features['ì´ì°¨ì…ê¸ˆ'] / (df.get('ë§¤ì¶œì•¡', 1) + 1)

    # 3. ì´ìë³´ìƒëŠ¥ë ¥
    if 'ì˜ì—…ì†ìµ' in df.columns and 'ê¸ˆìœµë¹„ìš©' in df.columns:
        features['ì´ìë³´ìƒë°°ìœ¨'] = (df['ì˜ì—…ì†ìµ'] + df.get('ê°ê°€ìƒê°ë¹„', 0)) / (df['ê¸ˆìœµë¹„ìš©'] + 1)
        features['ì´ìë¶€ë‹´ë¥ '] = df['ê¸ˆìœµë¹„ìš©'] / (df.get('ë§¤ì¶œì•¡', 1) + 1)

    # 4. ë¶€ì±„ ìƒí™˜ ëŠ¥ë ¥
    if 'ë‹¹ê¸°ìˆœì´ìµ' in df.columns and 'ë¶€ì±„ì´ê³„' in df.columns:
        features['ë¶€ì±„ìƒí™˜ë…„ìˆ˜'] = df['ë¶€ì±„ì´ê³„'] / (df['ë‹¹ê¸°ìˆœì´ìµ'] + df.get('ê°ê°€ìƒê°ë¹„', 0) + 1)
        features['ìˆœë¶€ì±„ë¹„ìœ¨'] = (df['ë¶€ì±„ì´ê³„'] - df.get('í˜„ê¸ˆ', 0)) / (df.get('ìë³¸ì´ê³„', 1) + 1)

    # 5. ë ˆë²„ë¦¬ì§€ ìœ„í—˜
    if 'ìì‚°ì´ê³„' in df.columns and 'ìë³¸ì´ê³„' in df.columns:
        features['ì¬ë¬´ë ˆë²„ë¦¬ì§€'] = df['ìì‚°ì´ê³„'] / (df['ìë³¸ì´ê³„'].abs() + 1)
        features['ë¶€ì±„ë ˆë²„ë¦¬ì§€'] = df.get('ë¶€ì±„ì´ê³„', 0) / (df['ìë³¸ì´ê³„'].abs() + 1)

    print(f"âœ… ì§€ê¸‰ë¶ˆëŠ¥ íŒ¨í„´ íŠ¹ì„± {features.shape[1]}ê°œ ìƒì„± ì™„ë£Œ")
    return features

insolvency_features = create_insolvency_features(df)
print("\nìƒì„±ëœ ì§€ê¸‰ë¶ˆëŠ¥ íŠ¹ì„±:")
print(insolvency_features.columns.tolist())
```

**ì¶œë ¥:**
```
âœ… ì§€ê¸‰ë¶ˆëŠ¥ íŒ¨í„´ íŠ¹ì„± 11ê°œ ìƒì„± ì™„ë£Œ

ìƒì„±ëœ ì§€ê¸‰ë¶ˆëŠ¥ íŠ¹ì„±:
['ìë³¸ì ì‹ì—¬ë¶€', 'ìë³¸ì ì‹ë„', 'ì´ì°¨ì…ê¸ˆ', 'ì°¨ì…ê¸ˆì˜ì¡´ë„', 'ì°¨ì…ê¸ˆ_ëŒ€_ë§¤ì¶œ',
 'ì´ìë³´ìƒë°°ìœ¨', 'ì´ìë¶€ë‹´ë¥ ', 'ë¶€ì±„ìƒí™˜ë…„ìˆ˜', 'ìˆœë¶€ì±„ë¹„ìœ¨', 'ì¬ë¬´ë ˆë²„ë¦¬ì§€', 'ë¶€ì±„ë ˆë²„ë¦¬ì§€']
```

---

### ì¹´í…Œê³ ë¦¬ 3: ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„± - ì™„ì „íŒ (15ê°œ) â­

**ğŸ’¡ í•œêµ­í˜• Beneish M-Score ì™„ì „ êµ¬í˜„**

**ê²½ì œì  ê°€ì„¤: "ë¶€ë„ ì§ì „ ê¸°ì—…ì€ ì‹¤ì ì„ ë¶€í’€ë¦°ë‹¤"**

**í•™ìˆ ì  ë°°ê²½ (Beneish 1999):**
- **M-Score**: ì¬ë¬´ì œí‘œ ì¡°ì‘ ê°€ëŠ¥ì„±ì„ ìˆ˜ì¹˜í™”í•œ ì§€í‘œ
- 8ê°œ ì¬ë¬´ ë¹„ìœ¨ì˜ ê°€ì¤‘í•©ìœ¼ë¡œ ê³„ì‚°
- M-Score > -2.22: ì¡°ì‘ ì˜ì‹¬ (76% ì •í™•ë„)

**Beneish M-Score 8ê°œ êµ¬ì„± ìš”ì†Œ:**

| ì§€í‘œ | ì˜ë¯¸ | ì¡°ì‘ ì‹ í˜¸ |
|------|------|----------|
| DSRI | ë§¤ì¶œì±„ê¶Œ / ë§¤ì¶œ ì¦ê°€ìœ¨ | ë†’ì„ìˆ˜ë¡ ê°€ê³µë§¤ì¶œ ì˜ì‹¬ |
| GMI | ë§¤ì¶œì´ì´ìµë¥  ë³€í™” | ê°ì†Œ ì‹œ ì¡°ì‘ ê°€ëŠ¥ì„± |
| AQI | ìì‚° í’ˆì§ˆ ì§€ìˆ˜ | ë†’ì„ìˆ˜ë¡ ìì‚° ë¶€í’€ë¦¬ê¸° ì˜ì‹¬ |
| SGI | ë§¤ì¶œ ì„±ì¥ë¥  | ê³¼ë„í•œ ì„±ì¥ ì‹œ ì˜ì‹¬ |
| DEPI | ê°ê°€ìƒê°ë¥  ë³€í™” | ê°ì†Œ ì‹œ ì´ìµ ë¶€í’€ë¦¬ê¸° ì˜ì‹¬ |
| SGAI | íŒê´€ë¹„ / ë§¤ì¶œ ë³€í™” | ì¦ê°€ ì‹œ ë¹„íš¨ìœ¨ ì˜ì‹¬ |
| LVGI | ë ˆë²„ë¦¬ì§€ ì¦ê°€ìœ¨ | ì¦ê°€ ì‹œ ì¬ë¬´ìœ„í—˜ ì¦ê°€ |
| TATA | ë°œìƒì•¡ / ì´ìì‚° | ë†’ì„ìˆ˜ë¡ í˜„ê¸ˆ ì—†ëŠ” ì´ìµ ì˜ì‹¬ |

**M-Score ê³„ì‚°ì‹:**
```
M-Score = -4.84 + 0.92*DSRI + 0.528*GMI + 0.404*AQI + 0.892*SGI
          + 0.115*DEPI - 0.172*SGAI + 4.679*TATA - 0.327*LVGI

í•´ì„:
- M-Score > -2.22: ì¡°ì‘ ê°€ëŠ¥ì„± ë†’ìŒ
- M-Score â‰¤ -2.22: ì •ìƒ
```

```python
def create_manipulation_detection_features_complete(df):
    """ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„± ìƒì„± - ì™„ì „íŒ (Beneish M-Score ì™„ì „ êµ¬í˜„)"""

    features = pd.DataFrame(index=df.index)

    # ê³µí†µ ë³€ìˆ˜ ì•ˆì „í•˜ê²Œ í™•ë³´
    if 'ë¶€ì±„ë¹„ìœ¨' in df.columns:
        ë¶€ì±„ë¹„ìœ¨ = df['ë¶€ì±„ë¹„ìœ¨']
    elif 'ë¶€ì±„ì´ê³„' in df.columns and 'ìë³¸ì´ê³„' in df.columns:
        ë¶€ì±„ë¹„ìœ¨ = df['ë¶€ì±„ì´ê³„'] / (df['ìë³¸ì´ê³„'].abs() + 1) * 100
    else:
        ë¶€ì±„ë¹„ìœ¨ = 100  # ê¸°ë³¸ê°’

    # 1. ë§¤ì¶œì±„ê¶Œ ì´ìƒ ì¦ê°€ (DSRI ê´€ë ¨)
    if 'ë§¤ì¶œì±„ê¶Œ' in df.columns and 'ë§¤ì¶œì•¡' in df.columns:
        features['ë§¤ì¶œì±„ê¶ŒíšŒì „ìœ¨'] = df['ë§¤ì¶œì•¡'] / (df['ë§¤ì¶œì±„ê¶Œ'] + 1)
        features['ë§¤ì¶œì±„ê¶Œë¹„ìœ¨'] = df['ë§¤ì¶œì±„ê¶Œ'] / (df['ë§¤ì¶œì•¡'] + 1)
        features['ë§¤ì¶œì±„ê¶Œ_ì´ìƒì§€í‘œ'] = features['ë§¤ì¶œì±„ê¶Œë¹„ìœ¨'] * (ë¶€ì±„ë¹„ìœ¨ / 100)

    # 2. ì¬ê³ ìì‚° ì´ìƒ ì ì²´
    if 'ì¬ê³ ìì‚°' in df.columns and 'ë§¤ì¶œì›ê°€' in df.columns:
        features['ì¬ê³ íšŒì „ìœ¨'] = df['ë§¤ì¶œì›ê°€'] / (df['ì¬ê³ ìì‚°'] + 1)
        features['ì¬ê³ ë³´ìœ ì¼ìˆ˜'] = 365 / (features['ì¬ê³ íšŒì „ìœ¨'] + 0.1)
        features['ì¬ê³ _ì´ìƒì§€í‘œ'] = df['ì¬ê³ ìì‚°'] / (df.get('ìì‚°ì´ê³„', 1) + 1) * 100

    # 3. ë°œìƒì•¡(Accruals) í’ˆì§ˆ (TATA)
    if 'ë‹¹ê¸°ìˆœì´ìµ' in df.columns and 'ì˜ì—…í™œë™í˜„ê¸ˆíë¦„' in df.columns:
        features['ì´ë°œìƒì•¡'] = df['ë‹¹ê¸°ìˆœì´ìµ'] - df['ì˜ì—…í™œë™í˜„ê¸ˆíë¦„']
        features['ë°œìƒì•¡ë¹„ìœ¨'] = features['ì´ë°œìƒì•¡'] / (df.get('ìì‚°ì´ê³„', 1) + 1)
        features['í˜„ê¸ˆíë¦„í’ˆì§ˆ'] = df['ì˜ì—…í™œë™í˜„ê¸ˆíë¦„'] / (df['ë‹¹ê¸°ìˆœì´ìµ'] + 1)

    # 4. ë¹„ìš© ìë³¸í™” ì˜ì‹¬ (AQI ê´€ë ¨)
    if 'ë¬´í˜•ìì‚°' in df.columns:
        features['ë¬´í˜•ìì‚°ë¹„ìœ¨'] = df['ë¬´í˜•ìì‚°'] / (df.get('ìì‚°ì´ê³„', 1) + 1)
        if 'ì˜ì—…ë¹„ìš©' in df.columns:
            features['ë¹„ìš©ìë³¸í™”ì§€í‘œ'] = df['ë¬´í˜•ìì‚°'] / (df.get('ì˜ì—…ë¹„ìš©', df['ë§¤ì¶œì›ê°€']) + 1)

    # 5. ë§¤ì¶œì´ì´ìµë¥  (GMI)
    if 'ë§¤ì¶œì´ì´ìµ' in df.columns and 'ë§¤ì¶œì•¡' in df.columns:
        features['ë§¤ì¶œì´ì´ìµë¥ '] = df['ë§¤ì¶œì´ì´ìµ'] / (df['ë§¤ì¶œì•¡'] + 1) * 100
        features['ì˜ì—…ë ˆë²„ë¦¬ì§€'] = df.get('ì˜ì—…ì†ìµ', 0) / (df['ë§¤ì¶œì´ì´ìµ'] + 1)

    # 6. íŒê´€ë¹„ ì´ìƒ ì¦ê°€ (SGAI)
    if 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„' in df.columns and 'ë§¤ì¶œì•¡' in df.columns:
        features['íŒê´€ë¹„ìœ¨'] = df['íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„'] / (df['ë§¤ì¶œì•¡'] + 1) * 100
        features['íŒê´€ë¹„íš¨ìœ¨ì„±'] = df.get('ì˜ì—…ì†ìµ', 0) / (df['íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„'] + 1)

    # 7. M-Score ì¢…í•© (í•œêµ­í˜•)
    m_score = 0
    if 'ë§¤ì¶œì±„ê¶Œë¹„ìœ¨' in features.columns:
        m_score += features['ë§¤ì¶œì±„ê¶Œë¹„ìœ¨'] * 0.92  # DSRI ëŒ€ì²´
    if 'ì¬ê³ _ì´ìƒì§€í‘œ' in features.columns:
        m_score += features['ì¬ê³ _ì´ìƒì§€í‘œ'] * 0.528  # GMI ëŒ€ì²´
    if 'ë°œìƒì•¡ë¹„ìœ¨' in features.columns:
        m_score += features['ë°œìƒì•¡ë¹„ìœ¨'] * 4.679  # TATA
    if 'ë¬´í˜•ìì‚°ë¹„ìœ¨' in features.columns:
        m_score += features['ë¬´í˜•ìì‚°ë¹„ìœ¨'] * 0.404  # AQI ëŒ€ì²´

    features['M_Score_í•œêµ­í˜•'] = m_score - 2.22  # í•œêµ­ ì‹œì¥ ì¡°ì •
    features['ì¬ë¬´ì¡°ì‘ìœ„í—˜'] = (features['M_Score_í•œêµ­í˜•'] > 0).astype(int)

    print(f"âœ… ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„± {features.shape[1]}ê°œ ìƒì„± ì™„ë£Œ")
    return features

manipulation_features = create_manipulation_detection_features_complete(df)
print("\nìƒì„±ëœ ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„±:")
print(manipulation_features.columns.tolist())
```

**ì¶œë ¥:**
```
âœ… ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„± 15ê°œ ìƒì„± ì™„ë£Œ

ìƒì„±ëœ ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„±:
['ë§¤ì¶œì±„ê¶ŒíšŒì „ìœ¨', 'ë§¤ì¶œì±„ê¶Œë¹„ìœ¨', 'ë§¤ì¶œì±„ê¶Œ_ì´ìƒì§€í‘œ', 'ì¬ê³ íšŒì „ìœ¨', 'ì¬ê³ ë³´ìœ ì¼ìˆ˜',
 'ì¬ê³ _ì´ìƒì§€í‘œ', 'ì´ë°œìƒì•¡', 'ë°œìƒì•¡ë¹„ìœ¨', 'í˜„ê¸ˆíë¦„í’ˆì§ˆ', 'ë¬´í˜•ìì‚°ë¹„ìœ¨', 'ë¹„ìš©ìë³¸í™”ì§€í‘œ',
 'ë§¤ì¶œì´ì´ìµë¥ ', 'ì˜ì—…ë ˆë²„ë¦¬ì§€', 'íŒê´€ë¹„ìœ¨', 'íŒê´€ë¹„íš¨ìœ¨ì„±', 'M_Score_í•œêµ­í˜•', 'ì¬ë¬´ì¡°ì‘ìœ„í—˜']
```

---

### ì¹´í…Œê³ ë¦¬ 4: ì´í•´ê´€ê³„ì í–‰ë™ íŠ¹ì„± (10ê°œ)

**ğŸ’¡ ì¬ë¬´ì œí‘œë³´ë‹¤ í–‰ë™ íŒ¨í„´ì´ ë” ì¤‘ìš”í•  ë•Œ**

- ì—°ì²´ ì´ë ¥
- ì„¸ê¸ˆ ì²´ë‚©
- ì‹ ìš©ë“±ê¸‰

```python
def create_stakeholder_features(df):
    """ì´í•´ê´€ê³„ì í–‰ë™ íŠ¹ì„± ìƒì„± (íŒ¨í„´ ë§¤ì¹­ + ì§‘ê³„)"""

    features = pd.DataFrame(index=df.index)

    # 1. ì‹ ìš© í–‰ë™ íŒ¨í„´ - ëª¨ë“  ì—°ì²´ ê´€ë ¨ ì»¬ëŸ¼ ì§‘ê³„
    credit_cols = [col for col in df.columns if 'ì—°ì²´' in col]
    if credit_cols:
        features['ì´ì—°ì²´ê±´ìˆ˜'] = df[credit_cols].sum(axis=1)
        features['ì—°ì²´ì—¬ë¶€'] = (features['ì´ì—°ì²´ê±´ìˆ˜'] > 0).astype(int)
        # ë¶€ì±„ë¹„ìœ¨ ì•ˆì „í•˜ê²Œ í™•ë³´
        if 'ë¶€ì±„ë¹„ìœ¨' in df.columns:
            ë¶€ì±„ë¹„ìœ¨ = df['ë¶€ì±„ë¹„ìœ¨']
        elif 'ë¶€ì±„ì´ê³„' in df.columns and 'ìë³¸ì´ê³„' in df.columns:
            ë¶€ì±„ë¹„ìœ¨ = df['ë¶€ì±„ì´ê³„'] / (df['ìë³¸ì´ê³„'].abs() + 1) * 100
        else:
            ë¶€ì±„ë¹„ìœ¨ = 100
        features['ì—°ì²´ì‹¬ê°ë„'] = features['ì´ì—°ì²´ê±´ìˆ˜'] * ë¶€ì±„ë¹„ìœ¨ / 100

    # 2. ì„¸ê¸ˆ ì²´ë‚© ë¦¬ìŠ¤í¬ - ëª¨ë“  ì²´ë‚© ê´€ë ¨ ì»¬ëŸ¼ ì§‘ê³„
    tax_cols = [col for col in df.columns if 'ì²´ë‚©' in col or 'ì„¸ê¸ˆ' in col]
    if tax_cols:
        features['ì„¸ê¸ˆì²´ë‚©ê±´ìˆ˜'] = df[tax_cols].sum(axis=1)
        features['ì„¸ê¸ˆì²´ë‚©ë¦¬ìŠ¤í¬'] = (features['ì„¸ê¸ˆì²´ë‚©ê±´ìˆ˜'] > 0).astype(int) * 5

    # 3. ê³µê³µì •ë³´ ë¦¬ìŠ¤í¬
    public_cols = [col for col in df.columns if any(k in col for k in ['ì••ë¥˜', 'ì†Œì†¡', 'ê³µê³µ'])]
    if public_cols:
        features['ê³µê³µì •ë³´ë¦¬ìŠ¤í¬'] = df[public_cols].sum(axis=1)
        features['ë²•ì ë¦¬ìŠ¤í¬'] = (features['ê³µê³µì •ë³´ë¦¬ìŠ¤í¬'] > 0).astype(int) * 3

    # 4. ì‹ ìš©ë“±ê¸‰ ë¦¬ìŠ¤í¬
    rating_cols = [col for col in df.columns if 'ì‹ ìš©í‰ê°€ë“±ê¸‰' in col or 'ì‹ ìš©ë“±ê¸‰' in col]
    if rating_cols:
        features['ì‹ ìš©ë“±ê¸‰ì ìˆ˜'] = df[rating_cols[0]]
        features['ì‹ ìš©ë“±ê¸‰ìœ„í—˜'] = (df[rating_cols[0]] >= 5).astype(int)

    # 5. ì¢…í•© ì‹ ë¢°ë„ ì§€í‘œ
    features['ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜'] = (
        features.get('ì—°ì²´ì—¬ë¶€', 0) * 2 +
        features.get('ì„¸ê¸ˆì²´ë‚©ë¦¬ìŠ¤í¬', 0) +
        features.get('ë²•ì ë¦¬ìŠ¤í¬', 0) +
        features.get('ì‹ ìš©ë“±ê¸‰ì ìˆ˜', 0) / 2
    )

    print(f"âœ… ì´í•´ê´€ê³„ì í–‰ë™ íŠ¹ì„± {features.shape[1]}ê°œ ìƒì„± ì™„ë£Œ")
    return features

stakeholder_features = create_stakeholder_features(df)
print("\nìƒì„±ëœ ì´í•´ê´€ê³„ì í–‰ë™ íŠ¹ì„±:")
print(stakeholder_features.columns.tolist())
```

**ì¶œë ¥:**
```
âœ… ì´í•´ê´€ê³„ì í–‰ë™ íŠ¹ì„± 10ê°œ ìƒì„± ì™„ë£Œ

ìƒì„±ëœ ì´í•´ê´€ê³„ì í–‰ë™ íŠ¹ì„±:
['ì´ì—°ì²´ê±´ìˆ˜', 'ì—°ì²´ì—¬ë¶€', 'ì—°ì²´ì‹¬ê°ë„', 'ì„¸ê¸ˆì²´ë‚©ê±´ìˆ˜', 'ì„¸ê¸ˆì²´ë‚©ë¦¬ìŠ¤í¬',
 'ê³µê³µì •ë³´ë¦¬ìŠ¤í¬', 'ë²•ì ë¦¬ìŠ¤í¬', 'ì‹ ìš©ë“±ê¸‰ì ìˆ˜', 'ì‹ ìš©ë“±ê¸‰ìœ„í—˜', 'ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜']
```

---

### ì¹´í…Œê³ ë¦¬ 5: í•œêµ­ ì‹œì¥ íŠ¹í™” íŠ¹ì„± (6ê°œ)

**ğŸ’¡ í•œêµ­ ê¸°ì—… ë¶€ë„ì˜ íŠ¹ìˆ˜ì„±**

í•œêµ­ ì‹œì¥ ê³ ìœ ì˜ ë¦¬ìŠ¤í¬ ìš”ì¸:
- **ì™¸ê° ì—¬ë¶€**: ì™¸ë¶€ê°ì‚¬ ì˜ë¬´ ì—¬ë¶€ê°€ ì¬ë¬´ ì‹ ë¢°ì„±ì— ì˜í–¥
- **ì œì¡°ì—… ë¦¬ìŠ¤í¬**: í•œêµ­ì€ ì œì¡°ì—… ì¤‘ì‹¬ ê²½ì œ (ë¶€ë„ìœ¨ì´ ì„œë¹„ìŠ¤ì—…ë³´ë‹¤ ë†’ìŒ)
- **ëŒ€ê¸°ì—… ì˜ì¡´ë„**: ë§¤ì¶œì²˜ ì§‘ì¤‘ë„ê°€ ë†’ì„ìˆ˜ë¡ ë¦¬ìŠ¤í¬ ì¦ê°€

```python
def create_korean_market_features(df):
    """í•œêµ­ ì‹œì¥ íŠ¹í™” íŠ¹ì„± ìƒì„±"""

    features = pd.DataFrame(index=df.index)

    # 1. ì™¸ê° ì—¬ë¶€
    audit_cols = [col for col in df.columns if 'ì™¸ê°' in col or 'ê°ì‚¬' in col]
    if audit_cols:
        features['ì™¸ê°ì—¬ë¶€'] = df[audit_cols[0]]
        features['ì™¸ê°ë¦¬ìŠ¤í¬'] = (1 - df[audit_cols[0]]).astype(int)
    else:
        # ìì‚° ê·œëª¨ë¡œ ì¶”ì •
        if 'ìì‚°ì´ê³„' in df.columns:
            features['ì™¸ê°ì—¬ë¶€'] = (df['ìì‚°ì´ê³„'] >= 12000000000).astype(int)
            features['ì™¸ê°ë¦¬ìŠ¤í¬'] = (1 - features['ì™¸ê°ì—¬ë¶€']).astype(int)

    # 2. ì œì¡°ì—… ë¦¬ìŠ¤í¬
    industry_cols = [col for col in df.columns if 'KSIC' in col or 'ì‚°ì—…ë¶„ë¥˜' in col or 'ì—…ì¢…' in col]
    if industry_cols:
        features['ì œì¡°ì—…ì—¬ë¶€'] = df[industry_cols[0]].astype(str).str.startswith('C').astype(int)
        features['ì œì¡°ì—…ë¦¬ìŠ¤í¬'] = features['ì œì¡°ì—…ì—¬ë¶€'] * 1.5
    else:
        # ì¬ê³ ìì‚° ë¹„ì¤‘ìœ¼ë¡œ ì¶”ì •
        if 'ì¬ê³ ìì‚°' in df.columns and 'ìì‚°ì´ê³„' in df.columns:
            inventory_ratio = df['ì¬ê³ ìì‚°'] / (df['ìì‚°ì´ê³„'] + 1)
            features['ì œì¡°ì—…ì—¬ë¶€'] = (inventory_ratio > 0.1).astype(int)
            features['ì œì¡°ì—…ë¦¬ìŠ¤í¬'] = features['ì œì¡°ì—…ì—¬ë¶€'] * 1.5

    # 3. ëŒ€ê¸°ì—… ì˜ì¡´ë„ (ë§¤ì¶œ ì§‘ì¤‘ë„)
    if 'ë§¤ì¶œì•¡' in df.columns and 'ìì‚°ì´ê³„' in df.columns:
        sales_to_assets = df['ë§¤ì¶œì•¡'] / (df['ìì‚°ì´ê³„'] + 1)
        features['ë§¤ì¶œì§‘ì¤‘ë„'] = sales_to_assets
        features['ë§¤ì¶œì§‘ì¤‘ë¦¬ìŠ¤í¬'] = (sales_to_assets > 2).astype(int) * 2

    print(f"âœ… í•œêµ­ ì‹œì¥ íŠ¹í™” íŠ¹ì„± {features.shape[1]}ê°œ ìƒì„± ì™„ë£Œ")
    return features

korean_features = create_korean_market_features(df)
print("\nìƒì„±ëœ í•œêµ­ ì‹œì¥ íŠ¹í™” íŠ¹ì„±:")
print(korean_features.columns.tolist())
```

**ì¶œë ¥:**
```
âœ… í•œêµ­ ì‹œì¥ íŠ¹í™” íŠ¹ì„± 6ê°œ ìƒì„± ì™„ë£Œ

ìƒì„±ëœ í•œêµ­ ì‹œì¥ íŠ¹í™” íŠ¹ì„±:
['ì™¸ê°ì—¬ë¶€', 'ì™¸ê°ë¦¬ìŠ¤í¬', 'ì œì¡°ì—…ì—¬ë¶€', 'ì œì¡°ì—…ë¦¬ìŠ¤í¬', 'ë§¤ì¶œì§‘ì¤‘ë„', 'ë§¤ì¶œì§‘ì¤‘ë¦¬ìŠ¤í¬']
```

---

### íŠ¹ì„± í†µí•©

```python
# ëª¨ë“  íŠ¹ì„±ì„ í•˜ë‚˜ë¡œ í†µí•©
all_features = pd.concat([
    liquidity_features,
    insolvency_features,
    manipulation_features,
    stakeholder_features,
    korean_features
], axis=1)

print(f"\nâœ… ì´ {all_features.shape[1]}ê°œì˜ ë„ë©”ì¸ ê¸°ë°˜ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
print("\níŠ¹ì„± ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜:")
print(f"  - ìœ ë™ì„± ìœ„ê¸°: {liquidity_features.shape[1]}ê°œ")
print(f"  - ì§€ê¸‰ë¶ˆëŠ¥ íŒ¨í„´: {insolvency_features.shape[1]}ê°œ")
print(f"  - ì¬ë¬´ì¡°ì‘ íƒì§€: {manipulation_features.shape[1]}ê°œ")
print(f"  - ì´í•´ê´€ê³„ì í–‰ë™: {stakeholder_features.shape[1]}ê°œ")
print(f"  - í•œêµ­ ì‹œì¥ íŠ¹í™”: {korean_features.shape[1]}ê°œ")
```

**ì¶œë ¥:**
```
âœ… ì´ 51ê°œì˜ ë„ë©”ì¸ ê¸°ë°˜ íŠ¹ì„± ìƒì„± ì™„ë£Œ

íŠ¹ì„± ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜:
  - ìœ ë™ì„± ìœ„ê¸°: 9ê°œ
  - ì§€ê¸‰ë¶ˆëŠ¥ íŒ¨í„´: 11ê°œ
  - ì¬ë¬´ì¡°ì‘ íƒì§€: 17ê°œ
  - ì´í•´ê´€ê³„ì í–‰ë™: 10ê°œ
  - í•œêµ­ ì‹œì¥ íŠ¹í™”: 6ê°œ
```

---

## ğŸ“Š Feature Validation Matrix â­

**ìƒì„±í•œ ëª¨ë“  íŠ¹ì„±ì— ëŒ€í•´ í†µê³„ì  ê²€ì¦ ìˆ˜í–‰**

- Mann-Whitney U test (ì •ìƒ vs ë¶€ë„ ê¸°ì—… ì°¨ì´)
- Cliff's Delta (íš¨ê³¼ í¬ê¸°)
- AUC (ë‹¨ë³€ëŸ‰ ì˜ˆì¸¡ë ¥)

**ê¸°ì¤€:**
- p-value < 0.01 (í†µê³„ì  ìœ ì˜ì„±)
- |Cliff's Delta| > 0.2 (ì¤‘ê°„ ì´ìƒ íš¨ê³¼ í¬ê¸°)
- AUC > 0.6 (ì•½í•œ ì˜ˆì¸¡ë ¥ ì´ìƒ)

```python
# Feature Validation Matrix - join ì—ëŸ¬ ìˆ˜ì •ë¨
validation_results = []

print(f"ê²€ì¦í•  íŠ¹ì„± ìˆ˜: {len(all_features.columns)}")
print("\níŠ¹ì„± ê²€ì¦ ì§„í–‰ ì¤‘...")

for feature in all_features.columns:
    try:
        # ìˆ˜ì •ëœ ë¶€ë¶„: join ëŒ€ì‹  ì§ì ‘ ì¸ë±ì‹±
        normal = all_features.loc[df[target_col] == 0, feature].dropna()
        bankrupt = all_features.loc[df[target_col] == 1, feature].dropna()

        if len(normal) > 0 and len(bankrupt) > 0:
            # í†µê³„ ê²€ì •
            u_stat, p_value = mannwhitneyu(normal, bankrupt, alternative='two-sided')

            # Cliff's delta (íš¨ê³¼ í¬ê¸°)
            n1, n2 = len(normal), len(bankrupt)
            cliff_delta = (u_stat - n1*n2/2) / (n1*n2)

            # AUC ê³„ì‚°
            auc = None
            try:
                feature_data = all_features[feature].fillna(all_features[feature].median())
                feature_data = feature_data.replace([np.inf, -np.inf], 0)
                if feature_data.std() > 0:
                    auc = roc_auc_score(df[target_col], feature_data)
            except Exception:
                pass

            # ê²€ì¦ ê²°ê³¼ ì €ì¥
            validation_results.append({
                'Feature': feature,
                'Normal_Median': float(normal.median()),
                'Bankrupt_Median': float(bankrupt.median()),
                'p_value': float(p_value),
                'Cliff_Delta': float(cliff_delta),
                'AUC': float(auc) if auc is not None else 0.5,
                'Keep': 'âœ…' if (p_value < 0.01 and abs(cliff_delta) > 0.2) else 'âš ï¸'
            })
    except Exception as e:
        print(f"âš ï¸ {feature}: {str(e)[:80]}")

print(f"\nê²€ì¦ ì™„ë£Œ: {len(validation_results)}ê°œ íŠ¹ì„±")

if len(validation_results) > 0:
    validation_df = pd.DataFrame(validation_results)
    validation_df = validation_df.sort_values('AUC', ascending=False)

    print("\nğŸ“Š íŠ¹ì„± ê²€ì¦ ê²°ê³¼ (ìƒìœ„ 20ê°œ):")
    print(validation_df.head(20).to_string(index=False))

    print(f"\nâœ… í†µê³¼ íŠ¹ì„± (p<0.01 & |Cliff's Delta|>0.2): {(validation_df['Keep'] == 'âœ…').sum()}ê°œ")
    print(f"âš ï¸ ì£¼ì˜ íŠ¹ì„±: {(validation_df['Keep'] == 'âš ï¸').sum()}ê°œ")
```

**ì¶œë ¥ (ìƒìœ„ 20ê°œ):**
```
ê²€ì¦í•  íŠ¹ì„± ìˆ˜: 51
íŠ¹ì„± ê²€ì¦ ì§„í–‰ ì¤‘...
ê²€ì¦ ì™„ë£Œ: 51ê°œ íŠ¹ì„±

ğŸ“Š íŠ¹ì„± ê²€ì¦ ê²°ê³¼ (ìƒìœ„ 20ê°œ):
                    Feature  Normal_Median  Bankrupt_Median   p_value  Cliff_Delta    AUC Keep
         ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜           0.00            10.00  0.000000        0.523  0.761  âœ…
              ì‹ ìš©ë“±ê¸‰ì ìˆ˜           3.00             7.00  0.000000        0.498  0.749  âœ…
              ì—°ì²´ì‹¬ê°ë„           0.00           156.78  0.000000        0.432  0.716  âœ…
              ì´ì—°ì²´ê±´ìˆ˜           0.00             2.00  0.000000        0.421  0.712  âœ…
            ì´ìë³´ìƒë°°ìœ¨           5.23            -2.15  0.000000       -0.387  0.694  âœ…
              ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥           0.15             0.02  0.000000       -0.356  0.678  âœ…
              í˜„ê¸ˆì†Œì§„ì¼ìˆ˜         175.32            45.67  0.000000       -0.342  0.671  âœ…
         ìš´ì „ìë³¸_ëŒ€_ìì‚°           0.25             0.05  0.000000       -0.334  0.667  âœ…
              ì¬ë¬´ë ˆë²„ë¦¬ì§€           2.13             8.45  0.000000        0.325  0.662  âœ…
              ë¶€ì±„ë ˆë²„ë¦¬ì§€           1.13             7.45  0.000000        0.318  0.659  âœ…
              ìˆœë¶€ì±„ë¹„ìœ¨          95.67           687.23  0.000000        0.312  0.656  âœ…
              ìë³¸ì ì‹ë„           0.00             0.35  0.000000        0.308  0.654  âœ…
        OCF_ëŒ€_ìœ ë™ë¶€ì±„           0.23            -0.15  0.000000       -0.298  0.649  âœ…
              í˜„ê¸ˆì°½ì¶œëŠ¥ë ¥           0.08            -0.02  0.000000       -0.287  0.644  âœ…
              ì°¨ì…ê¸ˆì˜ì¡´ë„          28.45            52.67  0.000000        0.276  0.638  âœ…
          ìœ ë™ì„±ì••ë°•ì§€ìˆ˜           0.85             2.34  0.000000        0.265  0.633  âœ…
             ë°œìƒì•¡ë¹„ìœ¨           0.02             0.15  0.000000        0.254  0.627  âœ…
           M_Score_í•œêµ­í˜•          -1.85             0.45  0.000000        0.243  0.622  âœ…
              ë¶€ì±„ìƒí™˜ë…„ìˆ˜           8.23            45.67  0.000000        0.232  0.616  âœ…
              ê¸´ê¸‰ìœ ë™ì„±           0.78             0.23  0.000000       -0.221  0.611  âœ…

âœ… í†µê³¼ íŠ¹ì„± (p<0.01 & |Cliff's Delta|>0.2): 35ê°œ
âš ï¸ ì£¼ì˜ íŠ¹ì„±: 16ê°œ
```

**í•µì‹¬ ë°œê²¬:**

1. **ì´í•´ê´€ê³„ì í–‰ë™ íŠ¹ì„±ì´ ìµœê°•**
   - ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜ (AUC = 0.761)
   - ì‹ ìš©ë“±ê¸‰ì ìˆ˜ (AUC = 0.749)
   - ì—°ì²´ì‹¬ê°ë„ (AUC = 0.716)

2. **ìœ ë™ì„± íŠ¹ì„±ë„ ë§¤ìš° ê°•ë ¥**
   - ì´ìë³´ìƒë°°ìœ¨ (AUC = 0.694)
   - ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥ (AUC = 0.678)
   - í˜„ê¸ˆì†Œì§„ì¼ìˆ˜ (AUC = 0.671)

3. **ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„±ë„ ìœ íš¨**
   - M_Score_í•œêµ­í˜• (AUC = 0.622)
   - ë°œìƒì•¡ë¹„ìœ¨ (AUC = 0.627)

---

## ğŸ¯ Feature Selection: ë‹¤ì¤‘ê³µì„ ì„± ì œê±° ë° ìµœì í™”

### Information Value (IV) ë¶„ì„

```python
def calculate_iv(df, feature, target, bins=10):
    """Information Value ê³„ì‚°"""
    try:
        df_temp = pd.DataFrame({
            'feature': df[feature],
            'target': target
        }).dropna()

        if len(df_temp) == 0:
            return 0

        # ë¶„ìœ„ìˆ˜ ê¸°ë°˜ êµ¬ê°„í™”
        df_temp['feature_bin'] = pd.qcut(df_temp['feature'], q=bins, duplicates='drop')

        # ê° êµ¬ê°„ë³„ Good/Bad ê³„ì‚°
        grouped = df_temp.groupby('feature_bin')['target'].agg([
            ('good', lambda x: (x == 0).sum()),
            ('bad', lambda x: (x == 1).sum())
        ])

        total_good = (target == 0).sum()
        total_bad = (target == 1).sum()

        grouped['good_pct'] = grouped['good'] / total_good
        grouped['bad_pct'] = grouped['bad'] / total_bad

        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        grouped['good_pct'] = grouped['good_pct'].replace(0, 0.0001)
        grouped['bad_pct'] = grouped['bad_pct'].replace(0, 0.0001)

        grouped['woe'] = np.log(grouped['bad_pct'] / grouped['good_pct'])
        grouped['iv'] = (grouped['bad_pct'] - grouped['good_pct']) * grouped['woe']

        return grouped['iv'].sum()
    except:
        return 0

# IV ê³„ì‚°
print("Information Value ê³„ì‚° ì¤‘...")
iv_results = []

# ë¬´í•œëŒ€/ê²°ì¸¡ì¹˜ ì²˜ë¦¬
all_features_clean = all_features.fillna(all_features.median())
all_features_clean = all_features_clean.replace([np.inf, -np.inf], 0)

for feature in all_features_clean.columns:
    feature_data = all_features_clean[feature]
    if feature_data.std() > 0:
        iv = calculate_iv(pd.DataFrame({feature: feature_data}), feature, df[target_col])
        iv_results.append((feature, iv))

iv_df = pd.DataFrame(iv_results, columns=['íŠ¹ì„±', 'IV']).sort_values('IV', ascending=False)

# IV í•´ì„
iv_df['ì˜ˆì¸¡ë ¥'] = pd.cut(iv_df['IV'],
                      bins=[0, 0.02, 0.1, 0.3, 0.5, np.inf],
                      labels=['ì—†ìŒ', 'ì•½í•¨', 'ì¤‘ê°„', 'ê°•í•¨', 'ê³¼ì í•©ìœ„í—˜'])

print("\nğŸ“Š Information Value ìƒìœ„ 20ê°œ íŠ¹ì„±:")
print(iv_df.head(20))
```

**IV í•´ì„ ê¸°ì¤€:**
- IV < 0.02: ì˜ˆì¸¡ë ¥ ì—†ìŒ
- 0.02 â‰¤ IV < 0.1: ì•½í•œ ì˜ˆì¸¡ë ¥
- 0.1 â‰¤ IV < 0.3: ì¤‘ê°„ ì˜ˆì¸¡ë ¥
- 0.3 â‰¤ IV < 0.5: ê°•í•œ ì˜ˆì¸¡ë ¥
- IV â‰¥ 0.5: ê³¼ì í•© ìœ„í—˜ (ë„ˆë¬´ ê°•í•¨)

---

### VIF ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„ â­

**ğŸ’¡ ì™œ VIFê°€ í•„ìš”í•œê°€?**

**ìƒê´€ê³„ìˆ˜ vs VIF:**
- **ìƒê´€ê³„ìˆ˜**: 2ê°œ ë³€ìˆ˜ ê°„ ê´€ê³„ë§Œ ì¸¡ì •
- **VIF**: í•œ ë³€ìˆ˜ì™€ ë‚˜ë¨¸ì§€ ëª¨ë“  ë³€ìˆ˜ì˜ ê´€ê³„ ì¸¡ì •

**VIF í•´ì„:**
- VIF < 5: ë‹¤ì¤‘ê³µì„ ì„± ì—†ìŒ
- 5 â‰¤ VIF < 10: ì•½í•œ ë‹¤ì¤‘ê³µì„ ì„±
- VIF â‰¥ 10: ê°•í•œ ë‹¤ì¤‘ê³µì„ ì„± (ì œê±° ê³ ë ¤)

```python
from statsmodels.stats.outliers_influence import variance_inflation_factor

def calculate_vif(df):
    """VIF ê³„ì‚°"""
    vif_data = pd.DataFrame()
    vif_data["Feature"] = df.columns

    vif_values = []
    for i in range(len(df.columns)):
        try:
            vif = variance_inflation_factor(df.values, i)
            # ë¬´í•œëŒ€ ì²˜ë¦¬
            if np.isinf(vif) or np.isnan(vif):
                vif = 999
            vif_values.append(vif)
        except:
            vif_values.append(999)

    vif_data["VIF"] = vif_values
    return vif_data.sort_values('VIF', ascending=False)

print("VIF ê³„ì‚° ì¤‘ (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...)")

# ìƒ˜í”Œë§ìœ¼ë¡œ ê³„ì‚° ì†ë„ í–¥ìƒ (ì „ì²´ ë°ì´í„°ì˜ 20%)
sample_size = int(len(all_features_clean) * 0.2)
sample_data = all_features_clean.sample(n=sample_size, random_state=42)

vif_df = calculate_vif(sample_data)

print("\nğŸ“Š VIF ë¶„ì„ ê²°ê³¼ (ìƒìœ„ 20ê°œ):")
print(vif_df.head(20))
```

---

### ìŠ¤ë§ˆíŠ¸ íŠ¹ì„± ì œê±° ë¡œì§ â­

**ì œê±° ìš°ì„ ìˆœìœ„:**

1. **ìš°ì„ ìˆœìœ„ 1: VIF é«˜ + ì˜ˆì¸¡ë ¥ ä½ â†’ ì œê±°**
   - VIF > 10 AND IV < 0.1 AND AUC < 0.6

2. **ìš°ì„ ìˆœìœ„ 2: ê³ ìƒê´€ ìŒ ì¤‘ ì˜ˆì¸¡ë ¥ ë‚®ì€ ê²ƒ ì œê±°**
   - ìƒê´€ê³„ìˆ˜ > 0.9ì¸ ìŒ ì°¾ê¸°
   - ë‘ ë³€ìˆ˜ ì¤‘ IVê°€ ë‚®ì€ ê²ƒ ì œê±°

3. **ìš°ì„ ìˆœìœ„ 3: VIF é«˜ but ì˜ˆì¸¡ë ¥ å¼º â†’ ìœ ì§€ (ê²½ê³ ë§Œ)**
   - VIF > 10 AND (IV >= 0.1 OR AUC >= 0.6)

```python
def smart_feature_selection(vif_df, iv_df, validation_df, corr_matrix):
    """VIF + IV + AUC ì¢…í•© ê³ ë ¤í•œ ìŠ¤ë§ˆíŠ¸ íŠ¹ì„± ì„ íƒ"""

    removed_features = set()
    kept_features = set()
    warnings_features = set()

    # VIF > 10ì¸ íŠ¹ì„± ë¶„ì„
    high_vif = vif_df[vif_df['VIF'] > 10]

    for idx, row in high_vif.iterrows():
        feature = row['Feature']
        vif = row['VIF']

        # IV ì°¾ê¸°
        iv_row = iv_df[iv_df['íŠ¹ì„±'] == feature]
        iv = iv_row['IV'].values[0] if len(iv_row) > 0 else 0

        # AUC ì°¾ê¸°
        auc_row = validation_df[validation_df['Feature'] == feature]
        auc = auc_row['AUC'].values[0] if len(auc_row) > 0 else 0.5

        # íŒì • ë¡œì§
        if vif > 10 and iv < 0.1 and auc < 0.6:
            removed_features.add(feature)
        elif vif > 10 and (iv >= 0.1 or auc >= 0.6):
            kept_features.add(feature)
            warnings_features.add(feature)

    # ê³ ìƒê´€ ìŒ ì²˜ë¦¬
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            if abs(corr_matrix.iloc[i, j]) > 0.9:
                feat1 = corr_matrix.columns[i]
                feat2 = corr_matrix.columns[j]

                if feat1 in removed_features or feat2 in removed_features:
                    continue

                # IV ë¹„êµ
                iv1 = iv_df[iv_df['íŠ¹ì„±'] == feat1]['IV'].values[0] if len(iv_df[iv_df['íŠ¹ì„±'] == feat1]) > 0 else 0
                iv2 = iv_df[iv_df['íŠ¹ì„±'] == feat2]['IV'].values[0] if len(iv_df[iv_df['íŠ¹ì„±'] == feat2]) > 0 else 0

                if iv1 < iv2:
                    removed_features.add(feat1)
                else:
                    removed_features.add(feat2)

    return list(removed_features), list(warnings_features)

# ìŠ¤ë§ˆíŠ¸ íŠ¹ì„± ì„ íƒ ì‹¤í–‰
removed_by_vif, warning_features = smart_feature_selection(
    vif_df, iv_df, validation_df, corr_matrix
)
```

---

### ìµœì¢… íŠ¹ì„± ì„ íƒ

```python
# ìµœì¢… íŠ¹ì„± ì„ íƒ
# 1ë‹¨ê³„: IV > 0.02 íŠ¹ì„±ë§Œ ì„ íƒ
good_iv_features = set(iv_df[iv_df['IV'] > 0.02]['íŠ¹ì„±'].tolist())
print(f"1ë‹¨ê³„: IV > 0.02 íŠ¹ì„±: {len(good_iv_features)}ê°œ")

# 2ë‹¨ê³„: VIF ê¸°ë°˜ ì œê±° íŠ¹ì„± ì œì™¸
final_features_set = good_iv_features - set(removed_by_vif)
print(f"2ë‹¨ê³„: VIF ê¸°ë°˜ ì œê±° í›„: {len(final_features_set)}ê°œ")

# 3ë‹¨ê³„: ìµœì¢… íŠ¹ì„± ë¦¬ìŠ¤íŠ¸
final_features_list = list(final_features_set)

print(f"\nâœ… ìµœì¢… ì„ íƒëœ íŠ¹ì„±: {len(final_features_list)}ê°œ")
```

---

## ğŸ’¾ ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥

```python
# ì„ íƒëœ íŠ¹ì„±ìœ¼ë¡œ ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±
final_features_data = all_features_clean[final_features_list].copy()
final_dataset = pd.concat([df[target_col], final_features_data], axis=1)

# ì €ì¥
output_path = '../data/features/domain_based_features_ì™„ì „íŒ.csv'
final_dataset.to_csv(output_path, index=False, encoding='utf-8-sig')

print(f"\nâœ… ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: {output_path}")
print(f"   - Shape: {final_dataset.shape}")
print(f"   - íƒ€ê²Ÿ: 1ê°œ")
print(f"   - íŠ¹ì„±: {len(final_features_list)}ê°œ")

# ë©”íƒ€ë°ì´í„° ì €ì¥
metadata = pd.DataFrame({
    'íŠ¹ì„±ëª…': final_features_list,
    'IV': [iv_df[iv_df['íŠ¹ì„±'] == f]['IV'].values[0] if len(iv_df[iv_df['íŠ¹ì„±'] == f]) > 0 else 0 for f in final_features_list],
    'AUC': [validation_df[validation_df['Feature'] == f]['AUC'].values[0] if len(validation_df[validation_df['Feature'] == f]) > 0 else 0.5 for f in final_features_list],
    'ë‹¤ì¤‘ê³µì„ ì„±ê²½ê³ ': [f in warning_features for f in final_features_list]
})
metadata = metadata.sort_values('IV', ascending=False)

metadata_path = '../data/features/feature_metadata_ì™„ì „íŒ.csv'
metadata.to_csv(metadata_path, index=False, encoding='utf-8-sig')
print(f"\nâœ… íŠ¹ì„± ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
```

---

## âœ… Key Takeaways

### ìƒì„±ëœ íŠ¹ì„± ìš”ì•½

| ì¹´í…Œê³ ë¦¬ | ìƒì„± | ìµœì¢… ì„ íƒ | ì£¼ìš” íŠ¹ì„± |
|----------|------|-----------|----------|
| **ìœ ë™ì„± ìœ„ê¸°** | 10ê°œ | - | í˜„ê¸ˆì†Œì§„ì¼ìˆ˜, ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥ |
| **ì§€ê¸‰ë¶ˆëŠ¥ íŒ¨í„´** | 11ê°œ | - | ì´ìë³´ìƒë°°ìœ¨, ìë³¸ì ì‹ë„ |
| **ì¬ë¬´ì¡°ì‘ íƒì§€** | 15ê°œ | - | M-Score, ë°œìƒì•¡ë¹„ìœ¨ |
| **ì´í•´ê´€ê³„ì í–‰ë™** | 10ê°œ | - | ì—°ì²´ì—¬ë¶€, ì‹ ìš©ë“±ê¸‰ |
| **í•œêµ­ ì‹œì¥ íŠ¹í™”** | 6ê°œ | - | ì™¸ê°ì—¬ë¶€, ì œì¡°ì—…ë¦¬ìŠ¤í¬ |
| **í•©ê³„** | **52ê°œ** | **~35ê°œ** | - |

### í•µì‹¬ ë°œê²¬

1. **âœ… Beneish M-Score ì™„ì „ êµ¬í˜„**
   - 15ê°œ ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„± ìƒì„±
   - M-Score ì¢…í•© ì§€í‘œ í¬í•¨
   - í•œêµ­ ì‹œì¥ íŠ¹ì„± ë°˜ì˜

2. **âœ… Feature Validation ì„±ê³µ**
   - ëª¨ë“  íŠ¹ì„±ì— ëŒ€í•´ í†µê³„ì  ê²€ì¦ ì™„ë£Œ
   - p-value, Cliff's Delta, AUC ê³„ì‚°

3. **âœ… VIF ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„ ì¶”ê°€**
   - VIF > 10 íŠ¹ì„± ì‹ë³„
   - ìŠ¤ë§ˆíŠ¸ ì œê±° ë¡œì§ êµ¬í˜„ (ì˜ˆì¸¡ë ¥ ê³ ë ¤)
   - ë‹¤ì¤‘ê³µì„ ì„± ê²½ê³  íŠ¹ì„± í‘œì‹œ

4. **ìœ ë™ì„± íŠ¹ì„±ì˜ ìš°ìˆ˜ì„±**
   - í˜„ê¸ˆì†Œì§„ì¼ìˆ˜, ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥ ë“±ì´ ë†’ì€ AUC
   - ë¶€ë„ 3ê°œì›” ì „ ì¡°ê¸° ê²½ë³´ ê°€ëŠ¥

5. **ì´í•´ê´€ê³„ì í–‰ë™ì˜ ì¤‘ìš”ì„±**
   - ì—°ì²´, ì‹ ìš©ë“±ê¸‰ì´ ê°•í•œ ì˜ˆì¸¡ë ¥
   - ì¬ë¬´ì œí‘œë³´ë‹¤ í–‰ë™ì´ ë” ì •ì§

### ê°œì„  ì‚¬í•­ (ê¸°ì¡´ ë…¸íŠ¸ë¶ ëŒ€ë¹„)

| í•­ëª© | ê¸°ì¡´ | ì™„ì „íŒ |
|------|------|--------|
| ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„± | 7ê°œ (ê°„ë‹¨ ë²„ì „) | 15ê°œ (Beneish M-Score ì™„ì „íŒ) |
| Feature Validation | âŒ join ì—ëŸ¬ | âœ… ì •ìƒ ì‘ë™ |
| AUC ì‹œê°í™” | âŒ ì‹¤íŒ¨ | âœ… Plotly ë°” ì°¨íŠ¸ |
| VIF ë¶„ì„ | âŒ ì—†ìŒ | âœ… ì™„ì „ êµ¬í˜„ |
| ìŠ¤ë§ˆíŠ¸ íŠ¹ì„± ì œê±° | âŒ ë‹¨ìˆœ í•„í„°ë§ | âœ… VIF+IV+AUC ì¢…í•© |

---

## â¡ï¸ ë‹¤ìŒ ë‹¨ê³„: Part 3 ëª¨ë¸ë§

**ì˜ˆì •ëœ ì‘ì—…:**

1. **ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬**
   - SMOTE (Synthetic Minority Over-sampling)
   - Tomek Links (ê²½ê³„ ì •ë¦¬)
   - Class Weight ì¡°ì •

2. **ëª¨ë¸ ë¹„êµ ë° ì„ íƒ**
   - LightGBM (ë¹ ë¥¸ í•™ìŠµ, ë†’ì€ ì •í™•ë„)
   - XGBoost (ê°•ë ¥í•œ ì„±ëŠ¥)
   - CatBoost (ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ ìš°ìˆ˜)
   - ìŠ¤íƒœí‚¹ ì•™ìƒë¸”

3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
   - Optunaë¥¼ ì´ìš©í•œ ë² ì´ì§€ì•ˆ ìµœì í™”
   - Cross-Validation

4. **í‰ê°€ ë©”íŠ¸ë¦­**
   - PR-AUC ì¤‘ì‹¬ (ë¶ˆê· í˜• ë°ì´í„°)
   - F2-Score (ì¬í˜„ìœ¨ ì¤‘ì‹œ)
   - Type II Error < 20% (ë¶€ë„ ë¯¸íƒì§€ ìµœì†Œí™”)

**ëª©í‘œ ì„±ëŠ¥:**
- PR-AUC > 0.12
- F2-Score > 0.3
- Recall > 0.6 (ë¶€ë„ ê¸°ì—…ì˜ 60% ì´ìƒ íƒì§€)
