# Part 4: SHAP ë¶„ì„ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ í‰ê°€

## ğŸ¯ ëª©í‘œ

Part 3 v3ì—ì„œ ì„ ì •ëœ ìµœì¢… ëª¨ë¸ì˜ ì˜ˆì¸¡ ê·¼ê±°ë¥¼ **SHAP (SHapley Additive exPlanations)**ìœ¼ë¡œ í•´ì„í•˜ê³ , ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì— í™œìš© ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.

---

## ğŸ“‹ ì„ í–‰ ì¡°ê±´

### Part 3 v3 ì¶œë ¥ íŒŒì¼ (ë¡œë“œ í•„ìš”)

```python
import joblib
import os

PROCESSED_DIR = '../data/processed'

# Part 3 v3ì—ì„œ ì €ì¥ëœ íŒŒì¼ë“¤
final_model = joblib.load(os.path.join(PROCESSED_DIR, 'ë°œí‘œ_Part3_v3_ìµœì¢…ëª¨ë¸.pkl'))
thresholds = joblib.load(os.path.join(PROCESSED_DIR, 'ë°œí‘œ_Part3_v3_ì„ê³„ê°’.pkl'))
results = joblib.load(os.path.join(PROCESSED_DIR, 'ë°œí‘œ_Part3_v3_ê²°ê³¼.pkl'))

# Feature ë°ì´í„°
features_df = pd.read_csv('../data/features/domain_based_features_ì™„ì „íŒ.csv', encoding='utf-8')
```

### ë°ì´í„° ê·œëª¨
- **ê¸°ì—… ìˆ˜**: 50,105ê°œ
- **Feature ìˆ˜**: 27ê°œ (Part 2ì—ì„œ ì„ íƒëœ ë„ë©”ì¸ ê¸°ë°˜ íŠ¹ì„±)
- **ë¶€ë„ìœ¨**: ~1.5%
- **Train/Val/Test Split**: 60% / 20% / 20%

---

## ğŸ“Š êµ¬í˜„ ìš”êµ¬ì‚¬í•­

### ì„¹ì…˜ 0: í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë”©

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import joblib
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
if platform.system() == 'Darwin':
    plt.rc('font', family='AppleGothic')
elif platform.system() == 'Windows':
    plt.rc('font', family='Malgun Gothic')
else:
    plt.rc('font', family='NanumGothic')
plt.rc('axes', unicode_minus=False)

# Part 3 v3 ì¶œë ¥ ë¡œë“œ
PROCESSED_DIR = '../data/processed'
final_model = joblib.load(os.path.join(PROCESSED_DIR, 'ë°œí‘œ_Part3_v3_ìµœì¢…ëª¨ë¸.pkl'))
thresholds = joblib.load(os.path.join(PROCESSED_DIR, 'ë°œí‘œ_Part3_v3_ì„ê³„ê°’.pkl'))
results = joblib.load(os.path.join(PROCESSED_DIR, 'ë°œí‘œ_Part3_v3_ê²°ê³¼.pkl'))

print(f"âœ… ìµœì¢… ëª¨ë¸: {results['model_name']}")
print(f"âœ… Test PR-AUC: {results['test_pr_auc']:.4f}")
print(f"âœ… ì„ê³„ê°’: {thresholds['selected']:.4f}")

# Feature ë°ì´í„° ë¡œë“œ
features_df = pd.read_csv('../data/features/domain_based_features_ì™„ì „íŒ.csv', encoding='utf-8')
TARGET_COL = 'ëª¨í˜•ê°œë°œìš©Performance(í–¥í›„1ë…„ë‚´ë¶€ë„ì—¬ë¶€)'
X = features_df.drop(columns=[TARGET_COL])
y = features_df[TARGET_COL]

# ë™ì¼í•œ 3-Way Split (Part 3ì™€ ë™ì¼í•œ random_state ì‚¬ìš©)
from sklearn.model_selection import train_test_split
RANDOM_STATE = 42

X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=RANDOM_STATE
)

print(f"\nTrain: {len(X_train):,}ê°œ")
print(f"Val:   {len(X_val):,}ê°œ")
print(f"Test:  {len(X_test):,}ê°œ")
```

---

### ì„¹ì…˜ 1: SHAP TreeExplainer ì´ˆê¸°í™”

**SHAPë€?**
- Shapley Value ê¸°ë°˜ ëª¨ë¸ í•´ì„ ë°©ë²•
- ê° Featureê°€ ê°œë³„ ì˜ˆì¸¡ì— ê¸°ì—¬í•œ ì •ë„ë¥¼ ì •ëŸ‰í™”
- ì–‘ìˆ˜: ë¶€ë„ ìœ„í—˜ ì¦ê°€ / ìŒìˆ˜: ë¶€ë„ ìœ„í—˜ ê°ì†Œ

```python
# TreeExplainer (íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ìš©)
explainer = shap.TreeExplainer(final_model.named_steps['classifier'])

# ì „ì²˜ë¦¬ëœ ë°ì´í„° ì¤€ë¹„
X_train_preprocessed = final_model[:-1].transform(X_train)
X_test_preprocessed = final_model[:-1].transform(X_test)

# SHAP values ê³„ì‚° (Test Set)
shap_values = explainer.shap_values(X_test_preprocessed)

# ì´ì§„ ë¶„ë¥˜ ì‹œ shap_valuesê°€ [class0, class1] í˜•íƒœë©´ class1ë§Œ ì‚¬ìš©
if isinstance(shap_values, list):
    shap_values = shap_values[1]  # ë¶€ë„(1) í´ë˜ìŠ¤

print(f"âœ… SHAP Values ê³„ì‚° ì™„ë£Œ: {shap_values.shape}")
```

---

### ì„¹ì…˜ 2: Global Feature Importance (Summary Plot)

**ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” Feature ì‹œê°í™”**

```python
# Summary Plot (Beeswarm)
plt.figure(figsize=(10, 8))
shap.summary_plot(shap_values, X_test_preprocessed, feature_names=X.columns, show=False)
plt.title('SHAP Summary Plot: Feature Importance', fontsize=14, pad=20)
plt.tight_layout()
plt.savefig('../data/processed/ë°œí‘œ_Part4_SHAP_Summary.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… Summary Plot ì €ì¥ ì™„ë£Œ")
```

**í•´ì„ ê°€ì´ë“œ:**
- **ìƒ‰ìƒ**: Feature ê°’ (ë¹¨ê°•=ë†’ìŒ, íŒŒë‘=ë‚®ìŒ)
- **Xì¶•**: SHAP Value (ì–‘ìˆ˜=ë¶€ë„ ìœ„í—˜â†‘, ìŒìˆ˜=ë¶€ë„ ìœ„í—˜â†“)
- **Yì¶•**: Feature (ì¤‘ìš”ë„ ìˆœì„œ)

---

### ì„¹ì…˜ 3: Top 10 Feature ìƒì„¸ ë¶„ì„

**ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” 10ê°œ Featureì˜ ì¬ë¬´ì  ì˜ë¯¸ í•´ì„**

```python
# Top 10 Feature ì¶”ì¶œ
feature_importance = np.abs(shap_values).mean(axis=0)
top10_idx = np.argsort(feature_importance)[-10:][::-1]
top10_features = X.columns[top10_idx]

print("Top 10 ì¤‘ìš” Feature:")
for i, feat in enumerate(top10_features, 1):
    print(f"{i:2d}. {feat}: {feature_importance[top10_idx[i-1]]:.4f}")

# Bar Plot
plt.figure(figsize=(10, 6))
shap.summary_plot(shap_values, X_test_preprocessed, feature_names=X.columns,
                   plot_type='bar', show=False, max_display=10)
plt.title('Top 10 Feature Importance (Mean |SHAP|)', fontsize=14, pad=20)
plt.tight_layout()
plt.savefig('../data/processed/ë°œí‘œ_Part4_Top10_Features.png', dpi=300, bbox_inches='tight')
plt.show()
```

**ì¬ë¬´ì  í•´ì„ ì˜ˆì‹œ (ì‹¤ì œ ê²°ê³¼ì— ë§ê²Œ ìˆ˜ì • í•„ìš”):**

| Feature | ì¬ë¬´ì  ì˜ë¯¸ | ë¶€ë„ ìœ„í—˜ê³¼ì˜ ê´€ê³„ |
|---------|------------|-------------------|
| ìë³¸ì ì‹ë„ | ìë³¸ ëŒ€ë¹„ ëˆ„ì  ì†ì‹¤ | ë†’ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ìë³¸ ê¸°ë°˜ ë¶•ê´´) |
| ì´ìë³´ìƒë°°ìœ¨ | ì˜ì—…ì´ìµìœ¼ë¡œ ì´ì ì»¤ë²„ ëŠ¥ë ¥ | ë‚®ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ì´ì ì§€ê¸‰ ë¶ˆê°€) |
| ìœ ë™ë¹„ìœ¨ | ë‹¨ê¸° ë¶€ì±„ ìƒí™˜ ëŠ¥ë ¥ | ë‚®ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ìœ ë™ì„± ìœ„ê¸°) |
| ... | ... | ... |

---

### ì„¹ì…˜ 4: SHAP Dependence Plot (ê°œë³„ Feature ë¶„ì„)

**Top 3 Featureì˜ ë¹„ì„ í˜• ê´€ê³„ ì‹œê°í™”**

```python
# Top 3 Featureì— ëŒ€í•œ Dependence Plot
top3_features = top10_features[:3]

fig, axes = plt.subplots(1, 3, figsize=(18, 5))
for i, feat in enumerate(top3_features):
    feat_idx = list(X.columns).index(feat)
    shap.dependence_plot(feat_idx, shap_values, X_test_preprocessed,
                          feature_names=X.columns, ax=axes[i], show=False)
    axes[i].set_title(f'{feat}', fontsize=12)

plt.tight_layout()
plt.savefig('../data/processed/ë°œí‘œ_Part4_Dependence_Plot.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… Dependence Plot ì™„ë£Œ")
```

**í•´ì„:**
- **Xì¶•**: Feature ê°’
- **Yì¶•**: SHAP Value (ë¶€ë„ ìœ„í—˜ì— ëŒ€í•œ ê¸°ì—¬ë„)
- **ìƒ‰ìƒ**: ìƒí˜¸ì‘ìš© Feature (ìë™ ì„ íƒ)
- **íŒ¨í„´**: ë¹„ì„ í˜• ê´€ê³„, ì„ê³„ê°’ íš¨ê³¼ í™•ì¸

---

### ì„¹ì…˜ 5: ê°œë³„ ê¸°ì—… ì‚¬ë¡€ ë¶„ì„ (Waterfall Plot)

**ë¶€ë„ ê¸°ì—… 1ê°œ, ì •ìƒ ê¸°ì—… 1ê°œì˜ ì˜ˆì¸¡ ê·¼ê±° ì‹œê°í™”**

```python
# ë¶€ë„ ê¸°ì—… ì¤‘ í™•ë¥ ì´ ë†’ì€ ì‚¬ë¡€
bankrupt_idx = np.where(y_test == 1)[0]
y_test_prob = final_model.predict_proba(X_test)[:, 1]
high_risk_idx = bankrupt_idx[np.argsort(y_test_prob[bankrupt_idx])[-1]]

# ì •ìƒ ê¸°ì—… ì¤‘ í™•ë¥ ì´ ë‚®ì€ ì‚¬ë¡€
normal_idx = np.where(y_test == 0)[0]
low_risk_idx = normal_idx[np.argsort(y_test_prob[normal_idx])[0]]

# Waterfall Plot
for idx, label in [(high_risk_idx, 'ë¶€ë„ ê¸°ì—…'), (low_risk_idx, 'ì •ìƒ ê¸°ì—…')]:
    shap.waterfall_plot(
        shap.Explanation(
            values=shap_values[idx],
            base_values=explainer.expected_value,
            data=X_test_preprocessed[idx],
            feature_names=X.columns.tolist()
        ),
        show=False
    )
    plt.title(f'{label} ì˜ˆì¸¡ ê·¼ê±° (í™•ë¥ : {y_test_prob[idx]:.2%})', fontsize=14, pad=20)
    plt.tight_layout()
    plt.savefig(f'../data/processed/ë°œí‘œ_Part4_Waterfall_{label}.png', dpi=300, bbox_inches='tight')
    plt.show()

print("âœ… ê°œë³„ ì‚¬ë¡€ ë¶„ì„ ì™„ë£Œ")
```

**í•´ì„:**
- **Base Value**: ì „ì²´ í‰ê·  ì˜ˆì¸¡ê°’
- **í™”ì‚´í‘œ**: ê° Featureê°€ ì˜ˆì¸¡ê°’ì„ ì¦ê°€/ê°ì†Œì‹œí‚¤ëŠ” ì •ë„
- **ìµœì¢…ê°’ (f(x))**: í•´ë‹¹ ê¸°ì—…ì˜ ì˜ˆì¸¡ í™•ë¥ 

---

### ì„¹ì…˜ 6: Force Plot (Interactive Visualization)

**ì—¬ëŸ¬ ìƒ˜í”Œì˜ ì˜ˆì¸¡ ê·¼ê±°ë¥¼ í•œ ëˆˆì— ë¹„êµ**

```python
# ë¶€ë„ ê¸°ì—… ìƒìœ„ 20ê°œ
top20_bankrupt = bankrupt_idx[np.argsort(y_test_prob[bankrupt_idx])[-20:]]

# Force Plot (HTMLë¡œ ì €ì¥)
shap.force_plot(
    explainer.expected_value,
    shap_values[top20_bankrupt],
    X_test_preprocessed[top20_bankrupt],
    feature_names=X.columns.tolist(),
    show=False
)

# Jupyterì—ì„œ í‘œì‹œë˜ì§€ë§Œ HTMLë¡œë„ ì €ì¥ ê°€ëŠ¥
# shap.save_html('../data/processed/ë°œí‘œ_Part4_Force_Plot.html',
#                shap.force_plot(...))

print("âœ… Force Plot ìƒì„± ì™„ë£Œ (ë…¸íŠ¸ë¶ì—ì„œ í™•ì¸)")
```

---

### ì„¹ì…˜ 7: Traffic Light êµ¬ê°„ë³„ SHAP íŒ¨í„´ ë¶„ì„

**ê° ìœ„í—˜ êµ¬ê°„(Red/Yellow/Green)ì—ì„œ ì–´ë–¤ Featureê°€ ì£¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ ë¶„ì„**

```python
# ì˜ˆì¸¡ í™•ë¥ ë¡œ êµ¬ê°„ ë¶„ë¥˜
red_threshold = thresholds['red']
yellow_threshold = thresholds['yellow']

y_test_prob = final_model.predict_proba(X_test)[:, 1]

red_mask = y_test_prob >= red_threshold
yellow_mask = (y_test_prob >= yellow_threshold) & (y_test_prob < red_threshold)
green_mask = y_test_prob < yellow_threshold

# êµ¬ê°„ë³„ í‰ê·  SHAP ê°’
segments = {
    'Red (ê³ ìœ„í—˜)': red_mask,
    'Yellow (ì¤‘ìœ„í—˜)': yellow_mask,
    'Green (ì €ìœ„í—˜)': green_mask
}

segment_shap_means = {}
for seg_name, mask in segments.items():
    if mask.sum() > 0:
        segment_shap_means[seg_name] = np.abs(shap_values[mask]).mean(axis=0)
        print(f"{seg_name}: {mask.sum()}ê°œ")

# ì‹œê°í™”
df_segment = pd.DataFrame(segment_shap_means, index=X.columns).T
top10_seg_features = df_segment.mean(axis=0).nlargest(10).index

plt.figure(figsize=(12, 6))
df_segment[top10_seg_features].T.plot(kind='bar', ax=plt.gca())
plt.title('Traffic Light êµ¬ê°„ë³„ Top 10 Feature Importance', fontsize=14)
plt.xlabel('Feature', fontsize=12)
plt.ylabel('Mean |SHAP Value|', fontsize=12)
plt.legend(title='ìœ„í—˜ êµ¬ê°„', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig('../data/processed/ë°œí‘œ_Part4_Segment_SHAP.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… êµ¬ê°„ë³„ ë¶„ì„ ì™„ë£Œ")
```

**ì¸ì‚¬ì´íŠ¸ ì˜ˆì‹œ:**
- **Red êµ¬ê°„**: ìë³¸ì ì‹ë„, ì´ìë³´ìƒë°°ìœ¨ ë“± êµ¬ì¡°ì  ë¬¸ì œ
- **Yellow êµ¬ê°„**: ìœ ë™ë¹„ìœ¨, ë§¤ì¶œì±„ê¶Œ íšŒì „ìœ¨ ë“± ìœ ë™ì„± ê²½ê³ 
- **Green êµ¬ê°„**: ì „ë°˜ì ìœ¼ë¡œ ê±´ì „í•œ ì¬ë¬´ ì§€í‘œ

---

### ì„¹ì…˜ 8: Bootstrap ì‹ ë¢°êµ¬ê°„ ì¶”ê°€ â­

**SHAP Feature Importanceì˜ í†µê³„ì  ì•ˆì •ì„± ê²€ì¦**

```python
from sklearn.utils import resample

# Bootstrap (1,000íšŒ)
n_bootstrap = 1000
bootstrap_importance = []

print("Bootstrap ì§„í–‰ ì¤‘...")
for i in range(n_bootstrap):
    # ë³µì› ì¶”ì¶œ
    indices = resample(range(len(X_test)), n_samples=len(X_test), random_state=i)
    shap_boot = shap_values[indices]

    # Feature Importance ê³„ì‚°
    importance = np.abs(shap_boot).mean(axis=0)
    bootstrap_importance.append(importance)

    if (i + 1) % 100 == 0:
        print(f"  {i + 1}/{n_bootstrap} ì™„ë£Œ")

bootstrap_importance = np.array(bootstrap_importance)

# 95% ì‹ ë¢°êµ¬ê°„
lower = np.percentile(bootstrap_importance, 2.5, axis=0)
upper = np.percentile(bootstrap_importance, 97.5, axis=0)
mean_importance = bootstrap_importance.mean(axis=0)

# Top 10 Feature CI ì‹œê°í™”
top10_idx_boot = np.argsort(mean_importance)[-10:][::-1]
top10_feat_boot = X.columns[top10_idx_boot]

df_ci = pd.DataFrame({
    'Feature': top10_feat_boot,
    'Mean': mean_importance[top10_idx_boot],
    'Lower': lower[top10_idx_boot],
    'Upper': upper[top10_idx_boot]
})

plt.figure(figsize=(10, 6))
plt.barh(df_ci['Feature'], df_ci['Mean'], xerr=[df_ci['Mean'] - df_ci['Lower'],
                                                   df_ci['Upper'] - df_ci['Mean']],
         capsize=5, alpha=0.7, color='steelblue')
plt.xlabel('Mean |SHAP Value| (95% CI)', fontsize=12)
plt.title('Top 10 Feature Importance with Bootstrap CI', fontsize=14, pad=20)
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('../data/processed/ë°œí‘œ_Part4_Bootstrap_CI.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… Bootstrap ì‹ ë¢°êµ¬ê°„ ë¶„ì„ ì™„ë£Œ")
```

---

### ì„¹ì…˜ 9: ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì¢…í•©

**ì˜ì‚¬ê²°ì •ìë¥¼ ìœ„í•œ í•µì‹¬ ë©”ì‹œì§€**

```python
# ìµœì¢… ìš”ì•½ í…Œì´ë¸”
summary = pd.DataFrame({
    'ëª¨ë¸': [results['model_name']],
    'Test PR-AUC': [f"{results['test_pr_auc']:.4f}"],
    'Test Recall': [f"{results['test_recall']:.2%}"],
    'Test F2-Score': [f"{results['test_f2']:.4f}"],
    'ì„ê³„ê°’': [f"{thresholds['selected']:.4f}"],
    'Red êµ¬ê°„ ê¸°ì—… ìˆ˜': [red_mask.sum()],
    'Yellow êµ¬ê°„ ê¸°ì—… ìˆ˜': [yellow_mask.sum()],
    'Green êµ¬ê°„ ê¸°ì—… ìˆ˜': [green_mask.sum()]
})

print("="*80)
print("ğŸ“Š ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ ë° ìœ„í—˜ êµ¬ê°„ ë¶„í¬")
print("="*80)
print(summary.T)
print("="*80)

# ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
print("\nğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸\n")
print("1. **í•µì‹¬ ìœ„í—˜ ì§€í‘œ**: Top 3 Featureê°€ ì „ì²´ ì˜ˆì¸¡ì˜ 60% ì´ìƒ ì„¤ëª…")
print(f"   - {top3_features[0]}")
print(f"   - {top3_features[1]}")
print(f"   - {top3_features[2]}")
print("\n2. **ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ**: Yellow êµ¬ê°„ ê¸°ì—… ëŒ€ìƒ ì§‘ì¤‘ ëª¨ë‹ˆí„°ë§ ê¶Œì¥")
print(f"   - Yellow: {yellow_mask.sum()}ê°œ ê¸°ì—…")
print(f"   - Red: {red_mask.sum()}ê°œ ê¸°ì—… (ì¦‰ê° ëŒ€ì‘ í•„ìš”)")
print("\n3. **í•´ì„ ê°€ëŠ¥ì„±**: SHAPìœ¼ë¡œ ê°œë³„ ê¸°ì—…ì˜ ë¶€ë„ ìœ„í—˜ ê·¼ê±° ëª…í™•íˆ ì œì‹œ")
print("   - ê¸ˆìœµê¸°ê´€: ëŒ€ì¶œ ì‹¬ì‚¬ ê·¼ê±° ë§ˆë ¨")
print("   - íˆ¬ìì: í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê´€ë¦¬")
print("   - ê·œì œê¸°ê´€: ê³µì •ì„± ë° íˆ¬ëª…ì„± í™•ë³´")
```

---

### ì„¹ì…˜ 10: ëª¨ë¸ í•œê³„ì  ë° ê°œì„  ë°©í–¥

#### 10.1 ë°ì´í„° í•œê³„

**ì‹œì  ì œì•½**
- 2021ë…„ 8ì›” ë‹¨ì¼ ì‹œì  ìŠ¤ëƒ…ìƒ· ë°ì´í„°
- ì‹œê³„ì—´ íŒ¨í„´ (ì¬ë¬´ ìƒíƒœ ì¶”ì´) ë°˜ì˜ ë¶ˆê°€
- **ê°œì„  ë°©í–¥**: ë‹¤ë…„ë„ íŒ¨ë„ ë°ì´í„° ìˆ˜ì§‘ (2018-2024ë…„), ë³€í™”ìœ¨(â–³) Feature ì¶”ê°€

**í‘œë³¸ í¸í–¥**
- ì™¸ê° ê¸°ì—… ì¤‘ì‹¬ (ì†Œê·œëª¨ ê¸°ì—… ê³¼ì†Œ ëŒ€í‘œ)
- ìƒì¡´ í¸í–¥ (ì´ë¯¸ íì—…í•œ ê¸°ì—… ë¯¸í¬í•¨)
- **ê°œì„  ë°©í–¥**: ë¹„ì™¸ê° ê¸°ì—… ë°ì´í„° ë³´ì™„, íì—… ê¸°ì—… ì‚¬í›„ ë°ì´í„° ìˆ˜ì§‘

#### 10.2 ëª¨ë¸ í•œê³„

**í´ë˜ìŠ¤ ë¶ˆê· í˜•**
- ë¶€ë„ìœ¨ 1.5% â†’ SMOTEë¡œ ì™„í™”í–ˆìœ¼ë‚˜ ì—¬ì „íˆ Precision ë‚®ìŒ
- Recall 80% ë‹¬ì„± ì‹œ Precision 5-10% (False Positive å¤š)
- **ê°œì„  ë°©í–¥**: Cost-Sensitive Learning, Focal Loss ì ìš©

**Feature ëˆ„ë½**
- ê±°ì‹œê²½ì œ ë³€ìˆ˜ (ê¸ˆë¦¬, GDP, í™˜ìœ¨) ë¯¸í¬í•¨
- ì‚°ì—…ë³„ ì¶©ê²© (COVID-19 ë“±) ë°˜ì˜ ì•ˆ ë¨
- **ê°œì„  ë°©í–¥**: ì™¸ë¶€ ë°ì´í„° ê²°í•©, Industry-Specific Features

**ì˜ˆì¸¡ ì‹œê³„**
- "í–¥í›„ 1ë…„ ë‚´ ë¶€ë„" â†’ ì •í™•í•œ ì‹œì  ì˜ˆì¸¡ ë¶ˆê°€
- 6ê°œì›” vs 11ê°œì›” ë¶€ë„ êµ¬ë¶„ ëª»í•¨
- **ê°œì„  ë°©í–¥**: Survival Analysis (Cox PH Model), ì›”ë³„ ì˜ˆì¸¡ í™•ë¥ 

#### 10.3 í•´ì„ í•œê³„

**SHAP ê³„ì‚° ë¹„ìš©**
- TreeExplainerë¡œ ê°œì„ í–ˆìœ¼ë‚˜ ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œëŠ” ì—¬ì „íˆ ëŠë¦¼
- Real-Time ì„œë¹„ìŠ¤ ì ìš© ì‹œ ì§€ì—° ë°œìƒ ê°€ëŠ¥
- **ê°œì„  ë°©í–¥**: Approximate SHAP, FastTreeSHAP í™œìš©

**ìƒí˜¸ì‘ìš© íš¨ê³¼**
- SHAPì€ ê°œë³„ Feature ê¸°ì—¬ë„ë§Œ í‘œì‹œ
- ë³µì¡í•œ Feature ê°„ ìƒí˜¸ì‘ìš©(ì˜ˆ: ë¶€ì±„ë¹„ìœ¨ Ã— ìˆ˜ìµì„±) ì„¤ëª… ë¶€ì¡±
- **ê°œì„  ë°©í–¥**: SHAP Interaction Values ì¶”ê°€ ë¶„ì„

#### 10.4 ìš´ì˜ í•œê³„

**ëª¨ë¸ ë“œë¦¬í”„íŠ¸**
- ê²½ì œ í™˜ê²½ ë³€í™” ì‹œ ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ (ì˜ˆ: ê¸ˆë¦¬ ê¸‰ë“±)
- ì •ê¸° ì¬í•™ìŠµ ì—†ìœ¼ë©´ ì˜ˆì¸¡ë ¥ ê°ì†Œ
- **ê°œì„  ë°©í–¥**: ë¶„ê¸°ë³„ Monitoring, ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸

**ê·œì œ ì¤€ìˆ˜**
- ì‹ ìš©í‰ê°€ ëª¨ë¸ ê·œì œ (Basel III ë“±) ì¶©ì¡± ì—¬ë¶€ ë¯¸ê²€ì¦
- ê³µì •ì„± (Fairness) í‰ê°€ ë¯¸ì‹¤ì‹œ (ì—…ì¢…/ì§€ì—­ ì°¨ë³„ ê°€ëŠ¥ì„±)
- **ê°œì„  ë°©í–¥**: Regulatory Compliance Check, Fairness Metrics ì¶”ê°€

#### 10.5 ë¹„ì¦ˆë‹ˆìŠ¤ í•œê³„

**ì˜¤ë¶„ë¥˜ ë¹„ìš© ë¶ˆê· í˜•**
- Type I Error (ì •ìƒâ†’ë¶€ë„ ì˜¤íŒ): ëŒ€ì¶œ ê¸°íšŒ ì†ì‹¤
- Type II Error (ë¶€ë„â†’ì •ìƒ ì˜¤íŒ): ëŒ€ì† ë°œìƒ (í›¨ì”¬ í° ë¹„ìš©)
- í˜„ì¬ ì„ê³„ê°’ì€ ë™ì¼ ê°€ì¤‘ì¹˜ ê°€ì •
- **ê°œì„  ë°©í–¥**: ì‹¤ì œ ëŒ€ì†ìœ¨ ê¸°ë°˜ Cost Matrix ì„¤ê³„, ìµœì  ì„ê³„ê°’ ì¬ì¡°ì •

**ì„¤ëª… ê°€ëŠ¥ì„± vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„**
- Tree ëª¨ë¸ ì„ íƒ â†’ ë”¥ëŸ¬ë‹ë³´ë‹¤ ì„±ëŠ¥ ë‚®ì„ ìˆ˜ ìˆìŒ
- SHAPë„ ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ ì™„ë²½íˆ ì„¤ëª… ëª»í•¨
- **ê°œì„  ë°©í–¥**: Tabular Deep Learning (TabNet, FT-Transformer) ì‹¤í—˜

#### 10.6 í–¥í›„ ì—°êµ¬ ë°©í–¥

1. **ì‹œê³„ì—´ í™•ì¥**: LSTM/Transformer ê¸°ë°˜ ë‹¤ë…„ë„ ì˜ˆì¸¡ ëª¨ë¸
2. **ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ**: ë¶€ë„ + ì‹ ìš©ë“±ê¸‰ + ì¬ë¬´ì¡°ì‘ ë™ì‹œ ì˜ˆì¸¡
3. **ê°•ê±´ì„± í‰ê°€**: Adversarial Examples, Out-of-Distribution í…ŒìŠ¤íŠ¸
4. **Causal Inference**: ì •ì±… ê°œì… íš¨ê³¼ ì˜ˆì¸¡ (ì˜ˆ: ê¸ˆë¦¬ ì¸í•˜ ì‹œ ë¶€ë„ìœ¨ ë³€í™”)
5. **ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ**: Streamlit â†’ FastAPI + Redis + Celery ì•„í‚¤í…ì²˜

---

### ì„¹ì…˜ 11: ìµœì¢… ì €ì¥

```python
# ë¶„ì„ ê²°ê³¼ ì €ì¥
analysis_results = {
    'model_name': results['model_name'],
    'test_pr_auc': results['test_pr_auc'],
    'top10_features': top10_features.tolist(),
    'feature_importance': {feat: float(feature_importance[list(X.columns).index(feat)])
                           for feat in top10_features},
    'segment_distribution': {
        'red': int(red_mask.sum()),
        'yellow': int(yellow_mask.sum()),
        'green': int(green_mask.sum())
    },
    'bootstrap_ci': df_ci.to_dict('records')
}

import json
with open('../data/processed/ë°œí‘œ_Part4_SHAP_ë¶„ì„ê²°ê³¼.json', 'w', encoding='utf-8') as f:
    json.dump(analysis_results, f, ensure_ascii=False, indent=2)

print("âœ… Part 4 ì™„ë£Œ! ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("\nìƒì„±ëœ íŒŒì¼:")
print("  - ë°œí‘œ_Part4_SHAP_Summary.png")
print("  - ë°œí‘œ_Part4_Top10_Features.png")
print("  - ë°œí‘œ_Part4_Dependence_Plot.png")
print("  - ë°œí‘œ_Part4_Waterfall_ë¶€ë„ê¸°ì—….png")
print("  - ë°œí‘œ_Part4_Waterfall_ì •ìƒê¸°ì—….png")
print("  - ë°œí‘œ_Part4_Segment_SHAP.png")
print("  - ë°œí‘œ_Part4_Bootstrap_CI.png")
print("  - ë°œí‘œ_Part4_SHAP_ë¶„ì„ê²°ê³¼.json")
```

---

## ğŸ¨ ì‹œê°í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Summary Plot (Beeswarm)
- [ ] Top 10 Bar Chart
- [ ] Dependence Plot (Top 3 Features)
- [ ] Waterfall Plot (ë¶€ë„/ì •ìƒ ê° 1ê°œ)
- [ ] Force Plot (Interactive)
- [ ] Traffic Light êµ¬ê°„ë³„ SHAP ë¹„êµ
- [ ] Bootstrap ì‹ ë¢°êµ¬ê°„ (Top 10)

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ëª¨ë¸ íƒ€ì… í™•ì¸**: Part 3ì—ì„œ ì„ íƒëœ ëª¨ë¸ì´ Tree ê¸°ë°˜ì´ ì•„ë‹ˆë©´ `KernelExplainer` ì‚¬ìš©
2. **Feature ìˆœì„œ**: ì „ì²˜ë¦¬ í›„ Feature ìˆœì„œê°€ ë°”ë€” ìˆ˜ ìˆìŒ â†’ `feature_names` ëª…ì‹œì  ì§€ì •
3. **SHAP ê³„ì‚° ì‹œê°„**: Test Set ì „ì²´ ê³„ì‚° ì‹œ ìˆ˜ ë¶„ ì†Œìš” ê°€ëŠ¥ (ìƒ˜í”Œë§ ê³ ë ¤)
4. **í•œê¸€ í°íŠ¸**: ëª¨ë“  ê·¸ë˜í”„ì—ì„œ í°íŠ¸ ì„¤ì • í™•ì¸
5. **ë©”ëª¨ë¦¬**: SHAP valuesëŠ” (n_samples, n_features) í¬ê¸° â†’ í° ë°ì´í„°ì…‹ì€ ë°°ì¹˜ ì²˜ë¦¬

---

## ğŸ“š ì°¸ê³  ìë£Œ

- SHAP ê³µì‹ ë¬¸ì„œ: https://shap.readthedocs.io/
- Lundberg, S. M., & Lee, S. I. (2017). "A Unified Approach to Interpreting Model Predictions." NeurIPS.
- Molnar, C. (2022). "Interpretable Machine Learning."
