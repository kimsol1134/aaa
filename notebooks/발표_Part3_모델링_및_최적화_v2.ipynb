{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“— ë°œí‘œìš© Part 3: ëª¨ë¸ë§ ë° ìµœì í™” v2\n",
    "\n",
    "## ğŸ¯ Part 3 ëª©í‘œ ë° ì´ì „ Part ìš”ì•½\n",
    "\n",
    "### ì´ì „ Part ì™„ë£Œ ì‚¬í•­\n",
    "\n",
    "**Part 1: ë¬¸ì œ ì •ì˜ ë° í•µì‹¬ ë°œê²¬**\n",
    "- 50,105ê°œ í•œêµ­ ê¸°ì—…, ë¶€ë„ìœ¨ 1.51% (1:66 ë¶ˆê· í˜•)\n",
    "- **í•µì‹¬ ë°œê²¬**: ìœ ë™ì„±ì´ ê°€ì¥ ê°•ë ¥í•œ ì˜ˆì¸¡ ë³€ìˆ˜\n",
    "- ì—…ì¢…ë³„ ë¶€ë„ìœ¨ 2ë°° ì°¨ì´ (ì œì¡°ì—… vs ì„œë¹„ìŠ¤ì—…)\n",
    "\n",
    "**Part 2: ë„ë©”ì¸ íŠ¹ì„± ê³µí•™**\n",
    "- 52ê°œ ë„ë©”ì¸ ê¸°ë°˜ íŠ¹ì„± ìƒì„±\n",
    "- VIF/IV/AUC ê¸°ë°˜ íŠ¹ì„± ì„ íƒ â†’ **27ê°œ ìµœì¢… íŠ¹ì„±**\n",
    "- 7ê°œ ì¹´í…Œê³ ë¦¬: ìœ ë™ì„±, ì§€ê¸‰ë¶ˆëŠ¥, ì¬ë¬´ì¡°ì‘, í•œêµ­ì‹œì¥, ì´í•´ê´€ê³„ì, ë³µí•©ë¦¬ìŠ¤í¬, ìƒí˜¸ì‘ìš©\n",
    "\n",
    "### Part 3 v2 ëª©í‘œ ë° ê°œì„  ì‚¬í•­\n",
    "\n",
    "**ğŸš¨ í•µì‹¬ ê°œì„ : Data Leakage ì™„ì „ ì œê±°**\n",
    "\n",
    "```\n",
    "âŒ v1ì˜ ë¬¸ì œì :\n",
    "- Test setìœ¼ë¡œ ëª¨ë¸ ì„ íƒ\n",
    "- Test setìœ¼ë¡œ ì„ê³„ê°’ ìµœì í™”\n",
    "- Test setìœ¼ë¡œ Traffic Light ê¸°ì¤€ ê²°ì •\n",
    "\n",
    "âœ… v2 í•´ê²°ì±…:\n",
    "- 3-Way Split (Train/Validation/Test)\n",
    "- Test setì€ ìµœì¢… í‰ê°€ ì§ì „ ë‹¨ í•œ ë²ˆë§Œ\n",
    "- ëª¨ë“  ì˜ì‚¬ê²°ì •ì€ Validation set ê¸°ë°˜\n",
    "```\n",
    "\n",
    "**ì£¼ìš” ê°œì„  ì‚¬í•­:**\n",
    "1. **3-Way Data Split** (Train 60% / Validation 20% / Test 20%)\n",
    "2. **ë¦¬ìƒ˜í”Œë§ ì „ëµ ëŒ€ì¡° ì‹¤í—˜** (SMOTE vs Class Weight)\n",
    "3. **Validation ê¸°ë°˜ ëª¨ë¸ ì„ íƒ** + Statistical Significance Test\n",
    "4. **Validation ê¸°ë°˜ ì„ê³„ê°’ ìµœì í™”** (F2-Score, Recall ìš°ì„ )\n",
    "5. **ë°ì´í„° ê¸°ë°˜ Traffic Light** (Recall 80%/95% ë³´ì¥)\n",
    "6. **Test Setì€ ë§ˆì§€ë§‰ í‰ê°€ë§Œ** (ì ˆëŒ€ ì˜ì‚¬ê²°ì •ì— ì‚¬ìš© ì•ˆ í•¨)\n",
    "\n",
    "**ëª©í‘œ ì„±ëŠ¥:**\n",
    "- PR-AUC: 0.15~0.20 (ë¶ˆê· í˜• ë°ì´í„° ê³ ë ¤)\n",
    "- F2-Score: 0.35~0.50 (Recall ìš°ì„ )\n",
    "- Recall: 60~80%\n",
    "- Type II Error: 20~40% (ë¶€ë„ ë¯¸íƒì§€ ìµœì†Œí™”)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import platform\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ - ì „ì²˜ë¦¬\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ - ëª¨ë¸\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ - íŠœë‹\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# í‰ê°€ ë©”íŠ¸ë¦­\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, roc_curve,\n",
    "    make_scorer, fbeta_score, recall_score, precision_score\n",
    ")\n",
    "\n",
    "# í†µê³„ ê²€ì •\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (CLAUDE.md ì¤€ìˆ˜)\n",
    "if platform.system() == 'Darwin':\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "else:\n",
    "    plt.rc('font', family='NanumGothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "# ì‹œê°í™” ì„¤ì •\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# ëœë¤ ì‹œë“œ (ì¬í˜„ì„±)\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"   - NumPy: {np.__version__}\")\n",
    "print(f\"   - Pandas: {pd.__version__}\")\n",
    "print(f\"   - Scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"   - LightGBM: {lgb.__version__}\")\n",
    "print(f\"   - XGBoost: {xgb.__version__}\")\n",
    "print(f\"   - CatBoost: {catboost.__version__}\")\n",
    "print(f\"   - Platform: {platform.system()}\")\n",
    "print(f\"   - Random State: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn ë²„ì „ ì¶”ê°€ ì„í¬íŠ¸\n",
    "import sklearn\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° ë¡œë”© ë° 3-Way Split â­\n",
    "\n",
    "### 1.1 ë°ì´í„° ë¡œë”©\n",
    "\n",
    "Part 2ì—ì„œ ìƒì„±í•œ **27ê°œ ë„ë©”ì¸ ê¸°ë°˜ íŠ¹ì„±**ì„ ë¡œë”©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ (í•˜ë“œì½”ë”© ê¸ˆì§€)\n",
    "DATA_DIR = '../data'\n",
    "FEATURES_FILE = os.path.join(DATA_DIR, 'features', 'domain_based_features_ì™„ì „íŒ.csv')\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "print(f\"ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘: {FEATURES_FILE}\")\n",
    "df = pd.read_csv(FEATURES_FILE, encoding='utf-8')\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ\")\n",
    "print(f\"   - ì „ì²´ ê¸°ì—… ìˆ˜: {len(df):,}\")\n",
    "print(f\"   - ì „ì²´ ë³€ìˆ˜ ìˆ˜: {len(df.columns)}\")\n",
    "print(f\"   - ë©”ëª¨ë¦¬ ì‚¬ìš©: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸\n",
    "TARGET_COL = 'ëª¨í˜•ê°œë°œìš©Performance(í–¥í›„1ë…„ë‚´ë¶€ë„ì—¬ë¶€)'\n",
    "\n",
    "print(f\"ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜: {TARGET_COL}\")\n",
    "print(f\"\\në¶€ë„ ë¶„í¬:\")\n",
    "print(df[TARGET_COL].value_counts())\n",
    "print(f\"\\në¶€ë„ìœ¨: {df[TARGET_COL].mean():.4%}\")\n",
    "print(f\"ë¶ˆê· í˜• ë¹„ìœ¨: 1:{int(1/df[TARGET_COL].mean())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 íŠ¹ì„± ë° íƒ€ê²Ÿ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì„±(X)ê³¼ íƒ€ê²Ÿ(y) ë¶„ë¦¬\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "print(f\"âœ… íŠ¹ì„± ë° íƒ€ê²Ÿ ë¶„ë¦¬ ì™„ë£Œ\")\n",
    "print(f\"   - X shape: {X.shape}\")\n",
    "print(f\"   - y shape: {y.shape}\")\n",
    "print(f\"   - íŠ¹ì„± ëª©ë¡ (27ê°œ):\")\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f\"      {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 3-Way Split: Train / Validation / Test â­â­â­\n",
    "\n",
    "**ğŸš¨ Data Leakage ë°©ì§€ë¥¼ ìœ„í•œ í•µì‹¬ ì„¤ê³„:**\n",
    "\n",
    "```\n",
    "ì „ì²´ ë°ì´í„° (50,105)\n",
    "â”œâ”€ Train Set (60%, ~30,063): ëª¨ë¸ í•™ìŠµ + CV íŠœë‹\n",
    "â”œâ”€ Validation Set (20%, ~10,021): ëª¨ë¸ ì„ íƒ, ì„ê³„ê°’ ìµœì í™”, ì˜ì‚¬ê²°ì •\n",
    "â””â”€ Test Set (20%, ~10,021): ìµœì¢… í‰ê°€ë§Œ (ì ˆëŒ€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ!)\n",
    "```\n",
    "\n",
    "**ì¤‘ìš”:**\n",
    "- Test setì€ ì´ ë…¸íŠ¸ë¶ ë§ˆì§€ë§‰ ì„¹ì…˜ì—ì„œ **ë‹¨ í•œ ë²ˆë§Œ** í‰ê°€\n",
    "- ëª¨ë“  ì˜ì‚¬ê²°ì •(ëª¨ë¸ ì„ íƒ, ì„ê³„ê°’ ë“±)ì€ **Validation set**ì—ì„œë§Œ\n",
    "- Stratified splitìœ¼ë¡œ ê° setì˜ ë¶€ë„ìœ¨ ë™ì¼í•˜ê²Œ ìœ ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ì°¨ ë¶„í• : Train+Val (80%) vs Test (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 2ì°¨ ë¶„í• : Train (75% of 80% = 60%) vs Validation (25% of 80% = 20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=0.25, \n",
    "    stratify=y_temp, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… 3-Way Split ì™„ë£Œ\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Set:      {len(X_train):,} ({len(X_train)/len(X)*100:.1f}%, ë¶€ë„ìœ¨: {y_train.mean():.4%})\")\n",
    "print(f\"Validation Set: {len(X_val):,} ({len(X_val)/len(X)*100:.1f}%, ë¶€ë„ìœ¨: {y_val.mean():.4%})\")\n",
    "print(f\"Test Set:       {len(X_test):,} ({len(X_test)/len(X)*100:.1f}%, ë¶€ë„ìœ¨: {y_test.mean():.4%})\")\n",
    "print(\"=\"*70)\n",
    "print(\"âš ï¸  Test Setì€ ìµœì¢… í‰ê°€ ì „ê¹Œì§€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶„í•  ì‹œê°í™”\n",
    "fig = go.Figure()\n",
    "\n",
    "sets = ['Train', 'Validation', 'Test']\n",
    "sizes = [len(X_train), len(X_val), len(X_test)]\n",
    "bankruptcy_rates = [y_train.mean()*100, y_val.mean()*100, y_test.mean()*100]\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=sets,\n",
    "    y=sizes,\n",
    "    text=[f\"{s:,}<br>({s/len(X)*100:.1f}%)\" for s in sizes],\n",
    "    textposition='auto',\n",
    "    name='ê¸°ì—… ìˆ˜',\n",
    "    marker_color=['#3498db', '#2ecc71', '#e74c3c']\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3-Way Data Split (Train/Validation/Test)',\n",
    "    xaxis_title='ë°ì´í„°ì…‹',\n",
    "    yaxis_title='ê¸°ì—… ìˆ˜',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# ë¶€ë„ìœ¨ í™•ì¸\n",
    "fig2 = go.Figure()\n",
    "\n",
    "fig2.add_trace(go.Bar(\n",
    "    x=sets,\n",
    "    y=bankruptcy_rates,\n",
    "    text=[f\"{r:.4%}\" for r in [r/100 for r in bankruptcy_rates]],\n",
    "    textposition='auto',\n",
    "    marker_color=['#3498db', '#2ecc71', '#e74c3c']\n",
    "))\n",
    "\n",
    "fig2.update_layout(\n",
    "    title='ë¶€ë„ìœ¨ ë¶„í¬ (Stratified Split ê²€ì¦)',\n",
    "    xaxis_title='ë°ì´í„°ì…‹',\n",
    "    yaxis_title='ë¶€ë„ìœ¨ (%)',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig2.show()\n",
    "\n",
    "print(\"âœ… ê° ë°ì´í„°ì…‹ì˜ ë¶€ë„ìœ¨ì´ ë™ì¼í•˜ê²Œ ìœ ì§€ë¨ (Stratified Split ì„±ê³µ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 ë°ì´í„° ê¸°ë³¸ í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set ê¸°ë³¸ í†µê³„\n",
    "print(\"ğŸ“Š Train Set ê¸°ë³¸ í†µê³„ (ì „ì²˜ë¦¬ ì „)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "missing_counts = X_train.isnull().sum()\n",
    "missing_pct = (missing_counts / len(X_train) * 100).round(2)\n",
    "\n",
    "if missing_counts.sum() > 0:\n",
    "    print(\"\\nâš ï¸ ê²°ì¸¡ì¹˜ ë°œê²¬:\")\n",
    "    missing_df = pd.DataFrame({\n",
    "        'ê²°ì¸¡ ìˆ˜': missing_counts[missing_counts > 0],\n",
    "        'ë¹„ìœ¨(%)': missing_pct[missing_counts > 0]\n",
    "    }).sort_values('ë¹„ìœ¨(%)', ascending=False)\n",
    "    print(missing_df)\nelse:\n",
    "    print(\"âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ\")\n",
    "\n",
    "# ë¬´í•œëŒ€ ê°’ í™•ì¸\n",
    "inf_counts = np.isinf(X_train).sum()\n",
    "if inf_counts.sum() > 0:\n",
    "    print(\"\\nâš ï¸ ë¬´í•œëŒ€ ê°’ ë°œê²¬:\")\n",
    "    print(inf_counts[inf_counts > 0])\n",
    "else:\n",
    "    print(\"âœ… ë¬´í•œëŒ€ ê°’ ì—†ìŒ\")\n",
    "\n",
    "# ê¸°ë³¸ í†µê³„ëŸ‰\n",
    "print(\"\\nğŸ“ˆ Train Set ê¸°ìˆ  í†µê³„:\")\n",
    "print(X_train.describe().T[['mean', 'std', 'min', 'max']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Section 1 ì™„ë£Œ\n",
    "\n",
    "**ì™„ë£Œ ì‚¬í•­:**\n",
    "- âœ… í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”©\n",
    "- âœ… ë°ì´í„° ë¡œë”© (50,105ê°œ ê¸°ì—…, 27ê°œ íŠ¹ì„±)\n",
    "- âœ… 3-Way Split (Train 60% / Validation 20% / Test 20%)\n",
    "- âœ… Stratified Split ê²€ì¦ (ë¶€ë„ìœ¨ ë™ì¼ ìœ ì§€)\n",
    "- âœ… ë°ì´í„° ê¸°ë³¸ í†µê³„ í™•ì¸\n",
    "\n",
    "**ë‹¤ìŒ ë‹¨ê³„:**\n",
    "- Section 2: ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì •ì˜\n",
    "- Section 3: ë¦¬ìƒ˜í”Œë§ ì „ëµ ëŒ€ì¡° ì‹¤í—˜ (SMOTE vs Class Weight)\n",
    "\n",
    "**âš ï¸ ì¤‘ìš” í™•ì¸:**\n",
    "- Test setì€ ì•„ì§ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ âœ…\n",
    "- ëª¨ë“  ì‘ì—…ì€ Train/Validation setì—ì„œë§Œ ì§„í–‰ âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì •ì˜\n",
    "\n",
    "### 2.1 Custom Transformers\n",
    "\n",
    "**ì „ì²˜ë¦¬ ìˆœì„œ (CLAUDE.md ì¤€ìˆ˜):**\n",
    "1. ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬ (InfiniteHandler)\n",
    "2. ê²°ì¸¡ì¹˜ ë³´ê°„ (SimpleImputer - median)\n",
    "3. ë¡œê·¸ ë³€í™˜ (LogTransformer - ì„ íƒì )\n",
    "4. ìŠ¤ì¼€ì¼ë§ (RobustScaler - ì´ìƒì¹˜ì— ê°•ê±´)\n",
    "\n",
    "**ì°¸ê³ **: Tree ê¸°ë°˜ ëª¨ë¸ì€ ì´ìƒì¹˜ì— ê°•ê±´í•˜ë¯€ë¡œ WinsorizerëŠ” ì œì™¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformer 1: ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬\n",
    "class InfiniteHandler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"ë¬´í•œëŒ€ ê°’ì„ 0ìœ¼ë¡œ ëŒ€ì²´\"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X = X.replace([np.inf, -np.inf], 0)\n",
    "        return X\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(\"âœ… InfiniteHandler ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 íŒŒì´í”„ë¼ì¸ ìƒì„± í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessing_pipeline(use_log=False):\n",
    "    \"\"\"\n",
    "    ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    use_log : bool, default=False\n",
    "        ë¡œê·¸ ë³€í™˜ ì ìš© ì—¬ë¶€ (Tree ëª¨ë¸ì€ ë¶ˆí•„ìš”)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pipeline : Pipeline\n",
    "    \"\"\"\n",
    "    steps = [\n",
    "        ('inf_handler', InfiniteHandler()),\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "    ]\n",
    "    \n",
    "    # Tree ëª¨ë¸ì—ëŠ” ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”í•˜ì§€ë§Œ, ì•™ìƒë¸”ì— LR í¬í•¨ ê°€ëŠ¥ì„± ê³ ë ¤\n",
    "    steps.append(('scaler', RobustScaler()))\n",
    "    \n",
    "    return Pipeline(steps)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_pipeline = create_preprocessing_pipeline()\n",
    "print(\"âœ… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"\\níŒŒì´í”„ë¼ì¸ ë‹¨ê³„:\")\n",
    "for name, transformer in test_pipeline.steps:\n",
    "    print(f\"  - {name}: {transformer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë¦¬ìƒ˜í”Œë§ ì „ëµ ëŒ€ì¡° ì‹¤í—˜ â­\n",
    "\n",
    "### 3.1 ì „ëµ ì„¤ê³„\n",
    "\n",
    "**ë¬¸ì œ**: SMOTE + Class Weight ë™ì‹œ ì‚¬ìš© ì‹œ ë…¸ì´ì¦ˆ ì¦í­, ê³¼ì í•© ìœ„í—˜\n",
    "\n",
    "**í•´ê²°**: ë‘ ì „ëµì„ ëª…í™•íˆ ë¶„ë¦¬í•˜ì—¬ ì‹¤í—˜\n",
    "\n",
    "```\n",
    "Strategy A: SMOTE ê³„ì—´ (Class Weight ì—†ìŒ)\n",
    "  - SMOTE(0.2)\n",
    "  - BorderlineSMOTE(0.2)\n",
    "  - SMOTETomek(0.2)\n",
    "\n",
    "Strategy B: Class Weight Only (ë¦¬ìƒ˜í”Œë§ ì—†ìŒ)\n",
    "  - scale_pos_weight = sqrt(neg/pos)\n",
    "  - scale_pos_weight = neg/pos\n",
    "  - class_weight = 'balanced'\n",
    "```\n",
    "\n",
    "**í‰ê°€**: Validation Setì—ì„œ PR-AUC, F2-Score ë¹„êµ\n",
    "\n",
    "**ê¶Œì¥**: ê¸ˆìœµ ë°ì´í„° íŠ¹ì„±ìƒ **Strategy B (Class Weight)**ê°€ ë” ë‚˜ì„ ê°€ëŠ¥ì„± ë†’ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶ˆê· í˜• ë¹„ìœ¨ ê³„ì‚°\n",
    "n_pos = y_train.sum()\n",
    "n_neg = len(y_train) - n_pos\n",
    "imbalance_ratio = n_neg / n_pos\n",
    "\n",
    "print(f\"ğŸ“Š Train Set ë¶ˆê· í˜• ë¶„ì„\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"ë¶€ë„ ê¸°ì—… (Positive):  {n_pos:,} ({n_pos/len(y_train)*100:.2f}%)\")\n",
    "print(f\"ì •ìƒ ê¸°ì—… (Negative):  {n_neg:,} ({n_neg/len(y_train)*100:.2f}%)\")\n",
    "print(f\"ë¶ˆê· í˜• ë¹„ìœ¨:           1:{imbalance_ratio:.1f}\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"\\nClass Weight ê³„ì‚°:\")\n",
    "print(f\"  - sqrt(neg/pos) = {np.sqrt(imbalance_ratio):.2f}\")\n",
    "print(f\"  - neg/pos = {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ë¹ ë¥¸ ì‹¤í—˜: LightGBMìœ¼ë¡œ ë‘ ì „ëµ ë¹„êµ\n",
    "\n",
    "ì „ì²´ AutoML ì „ì— LightGBM í•˜ë‚˜ë¡œ ë¹ ë¥´ê²Œ ë‘ ì „ëµì„ ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ (Train setì— fit, Val setì— transform)\n",
    "preprocessor = create_preprocessing_pipeline()\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜ (ì»¬ëŸ¼ëª… ìœ ì§€)\n",
    "X_train_processed = pd.DataFrame(X_train_processed, columns=X_train.columns, index=X_train.index)\n",
    "X_val_processed = pd.DataFrame(X_val_processed, columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "print(\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ (Train set fit, Validation set transform)\")\n",
    "print(f\"   - X_train_processed: {X_train_processed.shape}\")\n",
    "print(f\"   - X_val_processed: {X_val_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy A: SMOTE ê³„ì—´\n",
    "print(\"ğŸ“Š Strategy A: SMOTE ê³„ì—´ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "smote_methods = {\n",
    "    'SMOTE': SMOTE(sampling_strategy=0.2, random_state=RANDOM_STATE),\n",
    "    'BorderlineSMOTE': BorderlineSMOTE(sampling_strategy=0.2, random_state=RANDOM_STATE),\n",
    "    'SMOTETomek': SMOTETomek(sampling_strategy=0.2, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "strategy_a_results = {}\n",
    "\n",
    "for name, sampler in smote_methods.items():\n",
    "    # ë¦¬ìƒ˜í”Œë§\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X_train_processed, y_train)\n",
    "    \n",
    "    # LightGBM í•™ìŠµ (Class Weight ì—†ìŒ)\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        num_leaves=31,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Validation í‰ê°€\n",
    "    y_val_prob = model.predict_proba(X_val_processed)[:, 1]\n",
    "    pr_auc = average_precision_score(y_val, y_val_prob)\n",
    "    \n",
    "    # F2-Score ê³„ì‚° (ìµœì  ì„ê³„ê°’)\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_prob)\n",
    "    beta = 2\n",
    "    f2_scores = (1 + beta**2) * (precisions * recalls) / (beta**2 * precisions + recalls + 1e-10)\n",
    "    best_f2 = np.max(f2_scores)\n",
    "    \n",
    "    strategy_a_results[name] = {\n",
    "        'pr_auc': pr_auc,\n",
    "        'f2_score': best_f2,\n",
    "        'resampled_size': len(X_resampled),\n",
    "        'resampled_pos_rate': y_resampled.mean()\n",
    "    }\n",
    "    \n",
    "    print(f\"{name:20s} | PR-AUC: {pr_auc:.4f} | F2-Score: {best_f2:.4f} | \"\n",
    "          f\"Resampled: {len(X_resampled):,} (ë¶€ë„ìœ¨: {y_resampled.mean():.2%})\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy B: Class Weight Only\n",
    "print(\"\\nğŸ“Š Strategy B: Class Weight Only í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class_weight_methods = {\n",
    "    'No Weight': 1,\n",
    "    'Sqrt Weight': np.sqrt(imbalance_ratio),\n",
    "    'Full Weight': imbalance_ratio\n",
    "}\n",
    "\n",
    "strategy_b_results = {}\n",
    "\n",
    "for name, weight in class_weight_methods.items():\n",
    "    # LightGBM í•™ìŠµ (ë¦¬ìƒ˜í”Œë§ ì—†ìŒ)\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        num_leaves=31,\n",
    "        scale_pos_weight=weight,  # Class Weight\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Validation í‰ê°€\n",
    "    y_val_prob = model.predict_proba(X_val_processed)[:, 1]\n",
    "    pr_auc = average_precision_score(y_val, y_val_prob)\n",
    "    \n",
    "    # F2-Score ê³„ì‚°\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_prob)\n",
    "    beta = 2\n",
    "    f2_scores = (1 + beta**2) * (precisions * recalls) / (beta**2 * precisions + recalls + 1e-10)\n",
    "    best_f2 = np.max(f2_scores)\n",
    "    \n",
    "    strategy_b_results[name] = {\n",
    "        'pr_auc': pr_auc,\n",
    "        'f2_score': best_f2,\n",
    "        'weight': weight\n",
    "    }\n",
    "    \n",
    "    print(f\"{name:20s} | PR-AUC: {pr_auc:.4f} | F2-Score: {best_f2:.4f} | Weight: {weight:.2f}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ë¹„êµ\n",
    "print(\"\\nğŸ“Š ë¦¬ìƒ˜í”Œë§ ì „ëµ ë¹„êµ ê²°ê³¼ (Validation Set ê¸°ë°˜)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Strategy A ìµœê³  ì„±ëŠ¥\n",
    "best_a_name = max(strategy_a_results, key=lambda k: strategy_a_results[k]['pr_auc'])\n",
    "best_a_pr_auc = strategy_a_results[best_a_name]['pr_auc']\n",
    "\n",
    "# Strategy B ìµœê³  ì„±ëŠ¥\n",
    "best_b_name = max(strategy_b_results, key=lambda k: strategy_b_results[k]['pr_auc'])\n",
    "best_b_pr_auc = strategy_b_results[best_b_name]['pr_auc']\n",
    "\n",
    "print(f\"Strategy A (SMOTE ê³„ì—´) ìµœê³ :  {best_a_name:20s} | PR-AUC = {best_a_pr_auc:.4f}\")\n",
    "print(f\"Strategy B (Class Weight) ìµœê³ : {best_b_name:20s} | PR-AUC = {best_b_pr_auc:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if best_b_pr_auc > best_a_pr_auc:\n",
    "    diff = best_b_pr_auc - best_a_pr_auc\n",
    "    pct = diff / best_a_pr_auc * 100\n",
    "    print(f\"âœ… ì„ íƒ: Strategy B (Class Weight)\")\n",
    "    print(f\"   ì´ìœ : {diff:.4f} ({pct:.2f}%) ë” ìš°ìˆ˜, ë…¸ì´ì¦ˆ ì¦í­ ìœ„í—˜ ì—†ìŒ\")\n",
    "    selected_strategy = 'Class Weight'\n",
    "    selected_weight = strategy_b_results[best_b_name]['weight']\n",
    "else:\n",
    "    diff = best_a_pr_auc - best_b_pr_auc\n",
    "    pct = diff / best_b_pr_auc * 100\n",
    "    print(f\"âœ… ì„ íƒ: Strategy A (SMOTE ê³„ì—´)\")\n",
    "    print(f\"   ì´ìœ : {diff:.4f} ({pct:.2f}%) ë” ìš°ìˆ˜\")\n",
    "    selected_strategy = 'SMOTE'\n",
    "    selected_weight = 1\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”: ì „ëµ ë¹„êµ\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('PR-AUC ë¹„êµ', 'F2-Score ë¹„êµ'),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# PR-AUC\n",
    "all_methods = list(strategy_a_results.keys()) + list(strategy_b_results.keys())\n",
    "all_pr_aucs = [strategy_a_results[k]['pr_auc'] for k in strategy_a_results] + \\\n",
    "              [strategy_b_results[k]['pr_auc'] for k in strategy_b_results]\n",
    "colors = ['#3498db']*len(strategy_a_results) + ['#2ecc71']*len(strategy_b_results)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=all_methods, y=all_pr_aucs, marker_color=colors, showlegend=False,\n",
    "           text=[f\"{v:.4f}\" for v in all_pr_aucs], textposition='auto'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# F2-Score\n",
    "all_f2s = [strategy_a_results[k]['f2_score'] for k in strategy_a_results] + \\\n",
    "          [strategy_b_results[k]['f2_score'] for k in strategy_b_results]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=all_methods, y=all_f2s, marker_color=colors, showlegend=False,\n",
    "           text=[f\"{v:.4f}\" for v in all_f2s], textposition='auto'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='ë¦¬ìƒ˜í”Œë§ ì „ëµ ëŒ€ì¡° ì‹¤í—˜ ê²°ê³¼ (Validation Set)',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickangle=-45)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Section 2-3 ì™„ë£Œ\n",
    "\n",
    "**ì™„ë£Œ ì‚¬í•­:**\n",
    "- âœ… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì •ì˜ (InfiniteHandler â†’ Imputer â†’ Scaler)\n",
    "- âœ… ë¦¬ìƒ˜í”Œë§ ì „ëµ ëŒ€ì¡° ì‹¤í—˜ (SMOTE vs Class Weight)\n",
    "- âœ… Validation Set ê¸°ë°˜ ì„±ëŠ¥ ë¹„êµ\n",
    "- âœ… ìš°ìˆ˜í•œ ì „ëµ ì„ íƒ\n",
    "\n",
    "**ë‹¤ìŒ ë‹¨ê³„:**\n",
    "- Section 4: AutoML í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ì„ íƒëœ ì „ëµ ì ìš©)\n",
    "- Section 5: ëª¨ë¸ ì„ íƒ + ì„ê³„ê°’ ìµœì í™”\n",
    "\n",
    "**âš ï¸ ì¤‘ìš” í™•ì¸:**\n",
    "- Test setì€ ì—¬ì „íˆ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ âœ…\n",
    "- ëª¨ë“  ì˜ì‚¬ê²°ì •ì€ Validation set ê¸°ë°˜ âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AutoML: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ â­\n",
    "\n",
    "### 4.1 ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜\n",
    "\n",
    "**ëª¨ë¸ ì„ íƒ:**\n",
    "1. **LightGBM** - ë¹ ë¥´ê³  ë†’ì€ ì •í™•ë„\n",
    "2. **XGBoost** - ê°•ë ¥í•œ ì„±ëŠ¥, ë¶ˆê· í˜• ë°ì´í„°ì— íš¨ê³¼ì \n",
    "3. **CatBoost** - ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ ìš°ìˆ˜\n",
    "4. **Logistic Regression** - í•´ì„ë ¥, ë‹¤ì–‘ì„± í™•ë³´\n",
    "5. **Random Forest** - Tree ê¸°ë°˜, ë©”ì»¤ë‹ˆì¦˜ ë‹¤ë¦„\n",
    "\n",
    "**íŠœë‹ ì „ëµ:**\n",
    "- RandomizedSearchCV (íš¨ìœ¨ì„±)\n",
    "- 5-Fold Stratified CV\n",
    "- PR-AUC ë©”íŠ¸ë¦­ (ë¶ˆê· í˜• ë°ì´í„°)\n",
    "- Train Setë§Œ ì‚¬ìš© (Test/Validation ì ˆëŒ€ ë¯¸ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F2-Score Scorer ì •ì˜ (Recall ìš°ì„ )\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "pr_auc_scorer = make_scorer(average_precision_score, needs_proba=True)\n",
    "\n",
    "print(\"âœ… Scorer ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"   - PR-AUC: ì£¼ìš” í‰ê°€ ì§€í‘œ (ë¶ˆê· í˜• ë°ì´í„°)\")\n",
    "print(\"   - F2-Score: Recall ìš°ì„  (beta=2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ íƒëœ ì „ëµì— ë”°ë¥¸ scale_pos_weight ì„¤ì •\n",
    "# (ë¦¬ìƒ˜í”Œë§ ì „ëµ ì‹¤í—˜ ê²°ê³¼ì— ë”°ë¼ ìë™ ì„¤ì •)\n",
    "if selected_strategy == 'Class Weight':\n",
    "    use_class_weight = True\n",
    "    use_resampling = False\n",
    "    print(f\"âœ… ì„ íƒëœ ì „ëµ: Class Weight (scale_pos_weight={selected_weight:.2f})\")\n",
    "else:\n",
    "    use_class_weight = False\n",
    "    use_resampling = True\n",
    "    print(f\"âœ… ì„ íƒëœ ì „ëµ: SMOTE (sampling_strategy=0.2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ\n",
    "lgbm_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7, 10, -1],\n",
    "    'num_leaves': [15, 31, 63, 127],\n",
    "    'min_child_samples': [10, 20, 30, 50],\n",
    "    'subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda': [0, 0.01, 0.1, 1],\n",
    "    'scale_pos_weight': [selected_weight] if use_class_weight else [1],\n",
    "}\n",
    "\n",
    "# XGBoost íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.5],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda': [0, 0.01, 0.1, 1],\n",
    "    'scale_pos_weight': [selected_weight] if use_class_weight else [1],\n",
    "}\n",
    "\n",
    "# CatBoost íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ\n",
    "catboost_params = {\n",
    "    'iterations': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'depth': [3, 5, 7, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'scale_pos_weight': [selected_weight] if use_class_weight else [1],\n",
    "}\n",
    "\n",
    "# Logistic Regression íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ\n",
    "lr_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [1000],\n",
    "    'class_weight': ['balanced'] if use_class_weight else [None],\n",
    "}\n",
    "\n",
    "# Random Forest íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'class_weight': ['balanced'] if use_class_weight else [None],\n",
    "}\n",
    "\n",
    "print(\"âœ… íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"\\nê° ëª¨ë¸ë³„ íƒìƒ‰ ê³µê°„:\")\n",
    "print(f\"  - LightGBM: {np.prod([len(v) for v in lgbm_params.values()]):,} combinations\")\n",
    "print(f\"  - XGBoost: {np.prod([len(v) for v in xgb_params.values()]):,} combinations\")\n",
    "print(f\"  - CatBoost: {np.prod([len(v) for v in catboost_params.values()]):,} combinations\")\n",
    "print(f\"  - Logistic Regression: {np.prod([len(v) for v in lr_params.values()]):,} combinations\")\n",
    "print(f\"  - Random Forest: {np.prod([len(v) for v in rf_params.values()]):,} combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ëª¨ë¸ë³„ RandomizedSearchCV\n",
    "\n",
    "**âš ï¸ ì£¼ì˜: Train Setë§Œ ì‚¬ìš©, Validation/TestëŠ” ì ˆëŒ€ ì‚¬ìš© ì•ˆ í•¨!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì •ì˜\n",
    "models = {\n",
    "    'LightGBM': (\n",
    "        lgb.LGBMClassifier(random_state=RANDOM_STATE, n_jobs=-1, verbose=-1),\n",
    "        lgbm_params,\n",
    "        100  # n_iter\n",
    "    ),\n",
    "    'XGBoost': (\n",
    "        xgb.XGBClassifier(random_state=RANDOM_STATE, n_jobs=-1, verbosity=0,\n",
    "                         tree_method='hist', enable_categorical=False),\n",
    "        xgb_params,\n",
    "        100\n",
    "    ),\n",
    "    'CatBoost': (\n",
    "        CatBoostClassifier(random_state=RANDOM_STATE, verbose=0),\n",
    "        catboost_params,\n",
    "        50  # CatBoostëŠ” ëŠë¦¬ë¯€ë¡œ 50íšŒ\n",
    "    ),\n",
    "    'LogisticRegression': (\n",
    "        LogisticRegression(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "        lr_params,\n",
    "        50\n",
    "    ),\n",
    "    'RandomForest': (\n",
    "        RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "        rf_params,\n",
    "        50\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"\\níŠœë‹í•  ëª¨ë¸: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV ì‹¤í–‰\n",
    "print(\"ğŸš€ AutoML í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\")\n",
    "print(\"=\"*70)\n",
    "print(\"âš ï¸  Train Set + 5-Fold CVë§Œ ì‚¬ìš© (Validation/Test ë¯¸ì‚¬ìš©)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "search_results = {}\n",
    "best_models = {}\n",
    "\n",
    "for model_name, (model, param_grid, n_iter) in models.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ“Š {model_name} íŠœë‹ ì¤‘... (n_iter={n_iter})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # RandomizedSearchCV\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=n_iter,\n",
    "        scoring=pr_auc_scorer,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    # í•™ìŠµ (Train setë§Œ ì‚¬ìš©!)\n",
    "    search.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    search_results[model_name] = search\n",
    "    best_models[model_name] = search.best_estimator_\n",
    "    \n",
    "    print(f\"\\nâœ… {model_name} ì™„ë£Œ\")\n",
    "    print(f\"   - Best CV PR-AUC: {search.best_score_:.4f}\")\n",
    "    print(f\"   - Best Params: {search.best_params_}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"âœ… ëª¨ë“  ëª¨ë¸ íŠœë‹ ì™„ë£Œ!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 ê²°ê³¼ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ê²°ê³¼ DataFrame ìƒì„±\n",
    "all_results = []\n",
    "\n",
    "for model_name, search in search_results.items():\n",
    "    results_df = pd.DataFrame(search.cv_results_)\n",
    "    results_df['model'] = model_name\n",
    "    all_results.append(results_df)\n",
    "\n",
    "all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# ìƒìœ„ 10ê°œ ëª¨ë¸\n",
    "top10 = all_results_df.nsmallest(10, 'rank_test_score')[[\n",
    "    'model', 'mean_test_score', 'std_test_score', 'mean_train_score', 'params'\n",
    "]].reset_index(drop=True)\n",
    "\n",
    "top10.index = top10.index + 1\n",
    "\n",
    "print(\"ğŸ† ìƒìœ„ 10ê°œ ëª¨ë¸ (Train Set 5-Fold CV ê¸°ë°˜)\")\n",
    "print(\"=\"*70)\n",
    "print(top10.to_string())\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ë³„ ìµœê³  ì„±ëŠ¥ ë¹„êµ\n",
    "model_best_scores = {}\n",
    "for model_name, search in search_results.items():\n",
    "    model_best_scores[model_name] = search.best_score_\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig = go.Figure()\n",
    "\n",
    "models_sorted = sorted(model_best_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "model_names = [m[0] for m in models_sorted]\n",
    "scores = [m[1] for m in models_sorted]\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=model_names,\n",
    "    y=scores,\n",
    "    text=[f\"{s:.4f}\" for s in scores],\n",
    "    textposition='auto',\n",
    "    marker_color=['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ëª¨ë¸ë³„ ìµœê³  ì„±ëŠ¥ ë¹„êµ (Train Set 5-Fold CV PR-AUC)',\n",
    "    xaxis_title='ëª¨ë¸',\n",
    "    yaxis_title='PR-AUC',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nğŸ¥‡ Best Model: {model_names[0]} (PR-AUC: {scores[0]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³¼ì í•© ì²´í¬ (Train vs CV Score)\n",
    "print(\"\\nğŸ“Š ê³¼ì í•© ì²´í¬ (Train Score - CV Score)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, search in search_results.items():\n",
    "    train_score = search.cv_results_['mean_train_score'][search.best_index_]\n",
    "    cv_score = search.best_score_\n",
    "    gap = train_score - cv_score\n",
    "    \n",
    "    status = \"âš ï¸ ê³¼ì í•© ìš°ë ¤\" if gap > 0.1 else \"âœ… ì •ìƒ\"\n",
    "    \n",
    "    print(f\"{model_name:20s} | Train: {train_score:.4f} | CV: {cv_score:.4f} | \"\n",
    "          f\"Gap: {gap:.4f} | {status}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Section 4 ì™„ë£Œ\n",
    "\n",
    "**ì™„ë£Œ ì‚¬í•­:**\n",
    "- âœ… 5ê°œ ëª¨ë¸ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜\n",
    "- âœ… RandomizedSearchCV (Train Set + 5-Fold CVë§Œ)\n",
    "- âœ… ìƒìœ„ 10ê°œ ëª¨ë¸ ë„ì¶œ\n",
    "- âœ… ê³¼ì í•© ì²´í¬\n",
    "\n",
    "**ë‹¤ìŒ ë‹¨ê³„:**\n",
    "- Section 5: ëª¨ë¸ ì„ íƒ (Validation Set ê¸°ë°˜ + Statistical Test)\n",
    "- Section 6: ì„ê³„ê°’ ìµœì í™” + Traffic Light (Validation Set)\n",
    "- Section 7: Test Set ìµœì¢… í‰ê°€ (ë‹¨ í•œ ë²ˆë§Œ!)\n",
    "\n",
    "**âš ï¸ ì¤‘ìš” í™•ì¸:**\n",
    "- Test setì€ ì—¬ì „íˆ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ âœ…\n",
    "- Validation setë„ ì•„ì§ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ âœ…\n",
    "- ëª¨ë“  íŠœë‹ì€ Train Set 5-Fold CVë¡œë§Œ ì§„í–‰ âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ëª¨ë¸ ì„ íƒ: Validation Set ê¸°ë°˜ â­â­â­\n",
    "\n",
    "### 5.1 Single Best Model vs Voting Ensemble\n",
    "\n",
    "**ì¤‘ìš”:** Test setì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•Šê³ , **Validation set**ìœ¼ë¡œë§Œ ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Best Model (CV ê¸°ì¤€)\n",
    "best_model_name = max(model_best_scores, key=model_best_scores.get)\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"ğŸ¥‡ Single Best Model (Train CV ê¸°ì¤€): {best_model_name}\")\n",
    "print(f\"   - Train CV PR-AUC: {model_best_scores[best_model_name]:.4f}\")\n",
    "\n",
    "# Validation Set í‰ê°€\n",
    "y_val_prob_single = best_model.predict_proba(X_val_processed)[:, 1]\n",
    "val_pr_auc_single = average_precision_score(y_val, y_val_prob_single)\n",
    "\n",
    "print(f\"   - Validation PR-AUC: {val_pr_auc_single:.4f}\")\n",
    "print(f\"   - ì¼ë°˜í™” ì„±ëŠ¥: {val_pr_auc_single - model_best_scores[best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Ensemble (ìƒìœ„ 3ê°œ ëª¨ë¸)\n",
    "top3_models = sorted(model_best_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "print(f\"\\nğŸ† Top 3 ëª¨ë¸ (Voting Ensemble í›„ë³´):\")\n",
    "for i, (name, score) in enumerate(top3_models, 1):\n",
    "    print(f\"   {i}. {name}: {score:.4f}\")\n",
    "\n",
    "# Voting Classifier ìƒì„±\n",
    "voting_estimators = [(name, best_models[name]) for name, _ in top3_models]\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=voting_estimators,\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train setìœ¼ë¡œ í•™ìŠµ\n",
    "print(f\"\\nğŸ”„ Voting Ensemble í•™ìŠµ ì¤‘...\")\n",
    "voting_clf.fit(X_train_processed, y_train)\n",
    "\n",
    "# Validation Set í‰ê°€\n",
    "y_val_prob_voting = voting_clf.predict_proba(X_val_processed)[:, 1]\n",
    "val_pr_auc_voting = average_precision_score(y_val, y_val_prob_voting)\n",
    "\n",
    "print(f\"âœ… Voting Ensemble ì™„ë£Œ\")\n",
    "print(f\"   - Validation PR-AUC: {val_pr_auc_voting:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Significance Test (Wilcoxon)\n",
    "print(f\"\\nğŸ“Š Statistical Significance Test (Wilcoxon)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train setì—ì„œ CV foldë³„ ì ìˆ˜ ë¹„êµ\n",
    "single_cv_scores = cross_val_score(\n",
    "    best_model, X_train_processed, y_train,\n",
    "    cv=5, scoring=pr_auc_scorer, n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_cv_scores = cross_val_score(\n",
    "    voting_clf, X_train_processed, y_train,\n",
    "    cv=5, scoring=pr_auc_scorer, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Wilcoxon test\n",
    "try:\n",
    "    statistic, pvalue = wilcoxon(voting_cv_scores, single_cv_scores)\n",
    "    print(f\"Single Model CV Scores: {single_cv_scores}\")\n",
    "    print(f\"Voting Model CV Scores: {voting_cv_scores}\")\n",
    "    print(f\"\\nWilcoxon p-value: {pvalue:.4f}\")\n",
    "    \n",
    "    if pvalue < 0.05:\n",
    "        print(f\"   âœ… ìœ ì˜ë¯¸í•œ ì°¨ì´ ìˆìŒ (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ ìœ ì˜ë¯¸í•œ ì°¨ì´ ì—†ìŒ (p >= 0.05)\")\n",
    "except:\n",
    "    print(\"   âš ï¸ Wilcoxon test ì‹¤íŒ¨ (ì ìˆ˜ ë™ì¼ ê°€ëŠ¥ì„±)\")\n",
    "    pvalue = 1.0\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ëª¨ë¸ ì„ íƒ (Validation ê¸°ë°˜)\n",
    "print(f\"\\nğŸ¯ ìµœì¢… ëª¨ë¸ ì„ íƒ (Validation Set ê¸°ë°˜)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Single Best Model:     PR-AUC = {val_pr_auc_single:.4f}\")\n",
    "print(f\"Voting Ensemble:       PR-AUC = {val_pr_auc_voting:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ì„ íƒ ë¡œì§\n",
    "improvement_threshold = 0.005  # 0.5% ì´ìƒ ì°¨ì´ ë‚˜ì•¼ ì˜ë¯¸ ìˆìŒ\n",
    "improvement = val_pr_auc_voting - val_pr_auc_single\n",
    "\n",
    "if improvement > improvement_threshold and pvalue < 0.1:\n",
    "    final_model = voting_clf\n",
    "    final_model_name = 'VotingEnsemble'\n",
    "    final_val_pr_auc = val_pr_auc_voting\n",
    "    decision_reason = f\"Votingì´ {improvement:.4f} ë” ìš°ìˆ˜ (p={pvalue:.4f} < 0.1)\"\n",
    "    print(f\"âœ… ì„ íƒ: Voting Ensemble\")\n",
    "    print(f\"   ì´ìœ : {decision_reason}\")\n",
    "else:\n",
    "    final_model = best_model\n",
    "    final_model_name = best_model_name\n",
    "    final_val_pr_auc = val_pr_auc_single\n",
    "    if improvement <= improvement_threshold:\n",
    "        decision_reason = f\"ì„±ëŠ¥ ì°¨ì´ ë¯¸ë¯¸ ({improvement:.4f} < {improvement_threshold}) + SHAP í•´ì„ë ¥ ìš°ì„ \"\n",
    "    else:\n",
    "        decision_reason = f\"í†µê³„ì  ìœ ì˜ì„± ë¶€ì¡± (p={pvalue:.4f} >= 0.1)\"\n",
    "    print(f\"âœ… ì„ íƒ: Single Model ({best_model_name})\")\n",
    "    print(f\"   ì´ìœ : {decision_reason}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ìµœì¢… ëª¨ë¸ ì •ë³´ ì €ì¥\n",
    "model_selection_info = {\n",
    "    'final_model_name': final_model_name,\n",
    "    'val_pr_auc': final_val_pr_auc,\n",
    "    'decision_reason': decision_reason,\n",
    "    'single_model_name': best_model_name,\n",
    "    'single_val_pr_auc': val_pr_auc_single,\n",
    "    'voting_val_pr_auc': val_pr_auc_voting,\n",
    "    'wilcoxon_pvalue': pvalue\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì„ê³„ê°’ ìµœì í™”: Validation Set ê¸°ë°˜ â­â­â­\n",
    "\n",
    "### 6.1 F2-Score ìµœì  ì„ê³„ê°’\n",
    "\n",
    "**ì¤‘ìš”:** Validation setìœ¼ë¡œë§Œ ì„ê³„ê°’ì„ ê²°ì •í•˜ê³ , Test setì—ëŠ” ì ìš©ë§Œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set í™•ë¥  ì˜ˆì¸¡\n",
    "y_val_prob = final_model.predict_proba(X_val_processed)[:, 1]\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precisions_val, recalls_val, thresholds_val = precision_recall_curve(y_val, y_val_prob)\n",
    "\n",
    "# F2-Score ê³„ì‚° (Recall ìš°ì„ )\n",
    "beta = 2\n",
    "f2_scores = (1 + beta**2) * (precisions_val[:-1] * recalls_val[:-1]) / \\\n",
    "            (beta**2 * precisions_val[:-1] + recalls_val[:-1] + 1e-10)\n",
    "\n",
    "# ìµœì  ì„ê³„ê°’\n",
    "optimal_idx = np.argmax(f2_scores)\n",
    "optimal_threshold_f2 = thresholds_val[optimal_idx]\n",
    "optimal_f2 = f2_scores[optimal_idx]\n",
    "optimal_precision = precisions_val[optimal_idx]\n",
    "optimal_recall = recalls_val[optimal_idx]\n",
    "\n",
    "print(f\"ğŸ“Š F2-Score ìµœì  ì„ê³„ê°’ (Validation Set ê¸°ë°˜)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ìµœì  ì„ê³„ê°’:  {optimal_threshold_f2:.4f}\")\n",
    "print(f\"F2-Score:     {optimal_f2:.4f}\")\n",
    "print(f\"Precision:    {optimal_precision:.2%}\")\n",
    "print(f\"Recall:       {optimal_recall:.2%}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall ëª©í‘œ ê¸°ë°˜ ì„ê³„ê°’\n",
    "target_recall = 0.80  # 80% Recall ëª©í‘œ\n",
    "\n",
    "# Recall >= 80% ì¸ ì„ê³„ê°’ ì¤‘ Precision ìµœëŒ€\n",
    "idx_recall_80 = np.where(recalls_val[:-1] >= target_recall)[0]\n",
    "\n",
    "if len(idx_recall_80) > 0:\n",
    "    best_idx = idx_recall_80[np.argmax(precisions_val[idx_recall_80])]\n",
    "    threshold_recall_80 = thresholds_val[best_idx]\n",
    "    recall_80_precision = precisions_val[best_idx]\n",
    "    recall_80_recall = recalls_val[best_idx]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Recall 80% ë³´ì¥ ì„ê³„ê°’ (Validation Set ê¸°ë°˜)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"ì„ê³„ê°’:       {threshold_recall_80:.4f}\")\n",
    "    print(f\"Precision:    {recall_80_precision:.2%}\")\n",
    "    print(f\"Recall:       {recall_80_recall:.2%}\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Recall {target_recall:.0%} ë‹¬ì„± ë¶ˆê°€ëŠ¥\")\n",
    "    threshold_recall_80 = optimal_threshold_f2\n",
    "    recall_80_precision = optimal_precision\n",
    "    recall_80_recall = optimal_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì„ íƒ (Recall ìš°ì„ )\n",
    "selected_threshold = threshold_recall_80  # Recall 80% ë³´ì¥ ì„ íƒ\n",
    "\n",
    "print(f\"\\nâœ… ìµœì¢… ì„ íƒ ì„ê³„ê°’: {selected_threshold:.4f}\")\n",
    "print(f\"   ì´ìœ : Recall {target_recall:.0%} ë³´ì¥ (ë¶€ë„ ë¯¸íƒì§€ ìµœì†Œí™”)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR Curve ì‹œê°í™” (Validation Set)\n",
    "fig = go.Figure()\n",
    "\n",
    "# PR Curve\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=recalls_val,\n",
    "    y=precisions_val,\n",
    "    mode='lines',\n",
    "    name=f'PR Curve (AUC={final_val_pr_auc:.4f})',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "\n",
    "# ìµœì  ì„ê³„ê°’ í‘œì‹œ\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[recall_80_recall],\n",
    "    y=[recall_80_precision],\n",
    "    mode='markers',\n",
    "    name=f'ì„ íƒ ì„ê³„ê°’ ({selected_threshold:.4f})',\n",
    "    marker=dict(size=15, color='red', symbol='star')\n",
    "))\n",
    "\n",
    "# Baseline\n",
    "baseline = y_val.mean()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1],\n",
    "    y=[baseline, baseline],\n",
    "    mode='lines',\n",
    "    name=f'Baseline ({baseline:.2%})',\n",
    "    line=dict(color='gray', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Precision-Recall Curve (Validation Set)',\n",
    "    xaxis_title='Recall',\n",
    "    yaxis_title='Precision',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Traffic Light ì‹œìŠ¤í…œ: ë°ì´í„° ê¸°ë°˜ ì„ê³„ê°’ â­\n",
    "\n",
    "### 7.1 ì„ê³„ê°’ ì„¤ê³„ (Validation Set ê¸°ë°˜)\n",
    "\n",
    "**ë…¼ë¦¬:**\n",
    "- ğŸ”´ Red: Recall 80% ë³´ì¥ ì„ê³„ê°’\n",
    "- ğŸŸ¡ Yellow: Recall 95% ë³´ì¥ ì„ê³„ê°’\n",
    "- ğŸŸ¢ Green: Red ë¯¸ë§Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red ì„ê³„ê°’ (Recall 80%)\n",
    "red_threshold = selected_threshold\n",
    "\n",
    "# Yellow ì„ê³„ê°’ (Recall 95%)\n",
    "target_recall_95 = 0.95\n",
    "idx_recall_95 = np.where(recalls_val[:-1] >= target_recall_95)[0]\n",
    "\n",
    "if len(idx_recall_95) > 0:\n",
    "    best_idx_95 = idx_recall_95[np.argmax(precisions_val[idx_recall_95])]\n",
    "    yellow_threshold = thresholds_val[best_idx_95]\n",
    "    yellow_precision = precisions_val[best_idx_95]\n",
    "    yellow_recall = recalls_val[best_idx_95]\n",
    "else:\n",
    "    # Recall 95% ë¶ˆê°€ëŠ¥í•˜ë©´ ìµœì†Œ ì„ê³„ê°’ ì‚¬ìš©\n",
    "    yellow_threshold = np.percentile(y_val_prob, 5)  # í•˜ìœ„ 5%\n",
    "    yellow_idx = np.argmin(np.abs(thresholds_val - yellow_threshold))\n",
    "    yellow_precision = precisions_val[yellow_idx]\n",
    "    yellow_recall = recalls_val[yellow_idx]\n",
    "\n",
    "print(f\"ğŸš¦ Traffic Light ì„ê³„ê°’ (Validation Set ê¸°ë°˜)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸ”´ Red Threshold:    {red_threshold:.4f}\")\n",
    "print(f\"   - ëª©í‘œ: Recall {target_recall:.0%} ë³´ì¥\")\n",
    "print(f\"   - Precision: {recall_80_precision:.2%}, Recall: {recall_80_recall:.2%}\")\n",
    "print(f\"\\nğŸŸ¡ Yellow Threshold: {yellow_threshold:.4f}\")\n",
    "print(f\"   - ëª©í‘œ: Recall {target_recall_95:.0%} ë³´ì¥\")\n",
    "print(f\"   - Precision: {yellow_precision:.2%}, Recall: {yellow_recall:.2%}\")\n",
    "print(f\"\\nğŸŸ¢ Green:            < {yellow_threshold:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Setì—ì„œ Traffic Light ì„±ëŠ¥ ê²€ì¦\n",
    "def assign_traffic_light(prob, red_th, yellow_th):\n",
    "    if prob >= red_th:\n",
    "        return 'Red'\n",
    "    elif prob >= yellow_th:\n",
    "        return 'Yellow'\n",
    "    else:\n",
    "        return 'Green'\n",
    "\n",
    "val_traffic_light = [assign_traffic_light(p, red_threshold, yellow_threshold) for p in y_val_prob]\n",
    "val_df = pd.DataFrame({\n",
    "    'actual': y_val.values,\n",
    "    'prob': y_val_prob,\n",
    "    'traffic_light': val_traffic_light\n",
    "})\n",
    "\n",
    "# ë“±ê¸‰ë³„ í†µê³„\n",
    "traffic_stats = val_df.groupby('traffic_light').agg({\n",
    "    'actual': ['count', 'sum', 'mean']\n",
    "}).round(4)\n",
    "\n",
    "traffic_stats.columns = ['ê¸°ì—… ìˆ˜', 'ì‹¤ì œ ë¶€ë„', 'ë¶€ë„ìœ¨']\n",
    "traffic_stats = traffic_stats.reindex(['Red', 'Yellow', 'Green'])\n",
    "\n",
    "print(f\"\\nğŸ“Š Traffic Light ì„±ëŠ¥ (Validation Set)\")\n",
    "print(\"=\"*70)\n",
    "print(traffic_stats)\n",
    "print(\"=\"*70)\n",
    "\n",
    "# í¬ì°©ë¥  ê³„ì‚°\n",
    "total_bankrupts = y_val.sum()\n",
    "red_yellow_bankrupts = val_df[val_df['traffic_light'].isin(['Red', 'Yellow'])]['actual'].sum()\n",
    "capture_rate = red_yellow_bankrupts / total_bankrupts\n",
    "\n",
    "print(f\"\\nâœ… ë¦¬ìŠ¤í¬ ë°©ì–´ìœ¨ (Red+Yellow): {capture_rate:.2%}\")\n",
    "print(f\"   - ì „ì²´ ë¶€ë„ {total_bankrupts}ê°œ ì¤‘ {red_yellow_bankrupts}ê°œ í¬ì°©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Test Set ìµœì¢… í‰ê°€ â­â­â­\n",
    "\n",
    "### 8.1 ì¤‘ìš” ê²½ê³ \n",
    "\n",
    "```\n",
    "âš ï¸âš ï¸âš ï¸ Test Set ì‚¬ìš© ê²½ê³  âš ï¸âš ï¸âš ï¸\n",
    "\n",
    "ì´ ì„¹ì…˜ì€ ë…¸íŠ¸ë¶ì—ì„œ ë‹¨ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
    "Test Setì€ ìµœì¢… ë³´ê³ ë¥¼ ìœ„í•œ í‰ê°€ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©ë˜ë©°,\n",
    "ì´ì „ ëª¨ë“  ì˜ì‚¬ê²°ì •(ëª¨ë¸ ì„ íƒ, ì„ê³„ê°’ ë“±)ì€\n",
    "Validation Setì—ì„œë§Œ ì´ë£¨ì–´ì¡ŒìŒì„ ë³´ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "Test Setì„ ë³´ê³  ë‹¤ì‹œ íŠœë‹í•˜ê±°ë‚˜ ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set ì „ì²˜ë¦¬ (Train setì— fití•œ preprocessor ì‚¬ìš©)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "X_test_processed = pd.DataFrame(X_test_processed, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Test Set ì˜ˆì¸¡\n",
    "y_test_prob = final_model.predict_proba(X_test_processed)[:, 1]\n",
    "y_test_pred = (y_test_prob >= selected_threshold).astype(int)\n",
    "\n",
    "print(f\"âœ… Test Set ì˜ˆì¸¡ ì™„ë£Œ\")\n",
    "print(f\"   - ì„ê³„ê°’: {selected_threshold:.4f} (Validationì—ì„œ ê²°ì •ë¨)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set ìµœì¢… í‰ê°€\n",
    "test_pr_auc = average_precision_score(y_test, y_test_prob)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "# F2-Score, Precision, Recall\n",
    "test_f2 = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Type II Error\n",
    "type_ii_error = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ğŸ¯ Test Set ìµœì¢… í‰ê°€ (ì„ê³„ê°’: {selected_threshold:.4f})\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"âš ï¸  ì´ ê²°ê³¼ëŠ” ìµœì¢… ë³´ê³ ìš©ì´ë©°, ì´ì „ ë‹¨ê³„ì—ì„œ Test Setì„\")\n",
    "print(f\"   ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ìŒì„ ë³´ì¥í•©ë‹ˆë‹¤.\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­:\")\n",
    "print(f\"   PR-AUC:              {test_pr_auc:.4f}\")\n",
    "print(f\"   ROC-AUC:             {test_roc_auc:.4f}\")\n",
    "print(f\"   F2-Score:            {test_f2:.4f}\")\n",
    "print(f\"   Precision:           {test_precision:.2%}\")\n",
    "print(f\"   Recall:              {test_recall:.2%}\")\n",
    "print(f\"   Type II Error:       {type_ii_error:.2%}\")\n",
    "print(f\"\\nğŸ“Š Confusion Matrix:\")\n",
    "print(f\"   TN: {tn:,}  |  FP: {fp:,}\")\n",
    "print(f\"   FN: {fn:,}    |  TP: {tp:,}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Validation vs Test ë¹„êµ\n",
    "print(f\"\\nğŸ“Š Validation vs Test ë¹„êµ (ì¼ë°˜í™” ì„±ëŠ¥ ê²€ì¦):\")\n",
    "print(f\"   Validation PR-AUC: {final_val_pr_auc:.4f}\")\n",
    "print(f\"   Test PR-AUC:       {test_pr_auc:.4f}\")\n",
    "print(f\"   ì°¨ì´:              {test_pr_auc - final_val_pr_auc:.4f}\")\n",
    "\n",
    "if abs(test_pr_auc - final_val_pr_auc) < 0.02:\n",
    "    print(f\"   âœ… ì¼ë°˜í™” ì„±ëŠ¥ ìš°ìˆ˜ (ì°¨ì´ < 2%)\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  ì¼ë°˜í™” ì„±ëŠ¥ ì£¼ì˜ (ì°¨ì´ >= 2%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Traffic Light\n",
    "test_traffic_light = [assign_traffic_light(p, red_threshold, yellow_threshold) for p in y_test_prob]\n",
    "test_df = pd.DataFrame({\n",
    "    'actual': y_test.values,\n",
    "    'prob': y_test_prob,\n",
    "    'traffic_light': test_traffic_light\n",
    "})\n",
    "\n",
    "# ë“±ê¸‰ë³„ í†µê³„\n",
    "test_traffic_stats = test_df.groupby('traffic_light').agg({\n",
    "    'actual': ['count', 'sum', 'mean']\n",
    "}).round(4)\n",
    "\n",
    "test_traffic_stats.columns = ['ê¸°ì—… ìˆ˜', 'ì‹¤ì œ ë¶€ë„', 'ë¶€ë„ìœ¨']\n",
    "test_traffic_stats = test_traffic_stats.reindex(['Red', 'Yellow', 'Green'])\n",
    "\n",
    "print(f\"\\nğŸš¦ Traffic Light ì‹œìŠ¤í…œ (Test Set ìµœì¢… í‰ê°€)\")\n",
    "print(\"=\"*70)\n",
    "print(test_traffic_stats)\n",
    "print(\"=\"*70)\n",
    "\n",
    "# í¬ì°©ë¥ \n",
    "test_total_bankrupts = y_test.sum()\n",
    "test_red_yellow_bankrupts = test_df[test_df['traffic_light'].isin(['Red', 'Yellow'])]['actual'].sum()\n",
    "test_capture_rate = test_red_yellow_bankrupts / test_total_bankrupts\n",
    "\n",
    "print(f\"\\nâœ… ë¦¬ìŠ¤í¬ ë°©ì–´ìœ¨ (Red+Yellow): {test_capture_rate:.2%}\")\n",
    "print(f\"   - ì „ì²´ ë¶€ë„ {test_total_bankrupts}ê°œ ì¤‘ {test_red_yellow_bankrupts}ê°œ í¬ì°©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR Curve & ROC Curve (Test Set)\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Precision-Recall Curve', 'ROC Curve')\n",
    ")\n",
    "\n",
    "# PR Curve\n",
    "precisions_test, recalls_test, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=recalls_test, y=precisions_test, mode='lines', name=f'PR (AUC={test_pr_auc:.4f})'),\n",
    "    row=1, col=1\n",
    ")\n",
    "baseline_test = y_test.mean()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[0, 1], y=[baseline_test, baseline_test], mode='lines', \n",
    "               name='Baseline', line=dict(dash='dash')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC={test_roc_auc:.4f})'),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Random', \n",
    "               line=dict(dash='dash'), showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Recall', row=1, col=1)\n",
    "fig.update_xaxes(title_text='FPR', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Precision', row=1, col=1)\n",
    "fig.update_yaxes(title_text='TPR', row=1, col=2)\n",
    "\n",
    "fig.update_layout(title_text='Test Set ì„±ëŠ¥ ê³¡ì„ ', height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance ë¶„ì„\n",
    "\n",
    "### 9.1 ëª¨ë¸ Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance ì¶”ì¶œ\n",
    "if final_model_name == 'VotingEnsemble':\n",
    "    # Votingì˜ ê²½ìš° ì²« ë²ˆì§¸ estimator ì‚¬ìš©\n",
    "    model_for_importance = final_model.estimators_[0]\n",
    "    print(f\"âš ï¸  Voting Ensembleì´ë¯€ë¡œ ì²« ë²ˆì§¸ ëª¨ë¸({top3_models[0][0]})ì˜ Feature Importance ì‚¬ìš©\")\n",
    "else:\n",
    "    model_for_importance = final_model\n",
    "\n",
    "# Feature Importance ê°€ì ¸ì˜¤ê¸°\n",
    "if hasattr(model_for_importance, 'feature_importances_'):\n",
    "    importances = model_for_importance.feature_importances_\n",
    "elif hasattr(model_for_importance, 'coef_'):\n",
    "    importances = np.abs(model_for_importance.coef_[0])\n",
    "else:\n",
    "    print(\"âš ï¸  Feature Importanceë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    importances = np.zeros(len(X_train.columns))\n",
    "\n",
    "# DataFrame ìƒì„±\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nğŸ“Š Feature Importance Top 15\")\n",
    "print(\"=\"*70)\n",
    "print(feature_importance_df.head(15).to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance ì‹œê°í™”\n",
    "fig = go.Figure()\n",
    "\n",
    "top15 = feature_importance_df.head(15)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=top15['importance'][::-1],\n",
    "    y=top15['feature'][::-1],\n",
    "    orientation='h',\n",
    "    marker_color='#3498db',\n",
    "    text=[f\"{v:.4f}\" for v in top15['importance'][::-1]],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Feature Importance Top 15 ({final_model_name})',\n",
    "    xaxis_title='Importance',\n",
    "    yaxis_title='Feature',\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„: Cumulative Gains Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Gains Curve (Test Set)\n",
    "# í™•ë¥  ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "test_sorted_idx = np.argsort(y_test_prob)[::-1]\n",
    "y_test_sorted = y_test.values[test_sorted_idx]\n",
    "\n",
    "# ëˆ„ì  ë¶€ë„ í¬ì°©ë¥ \n",
    "cumulative_bankrupts = np.cumsum(y_test_sorted)\n",
    "total_bankrupts = y_test.sum()\n",
    "cumulative_pct = cumulative_bankrupts / total_bankrupts * 100\n",
    "\n",
    "# ê²€í†  ë¹„ìœ¨ (ìƒìœ„ ëª‡ %)\n",
    "review_pct = np.arange(1, len(y_test) + 1) / len(y_test) * 100\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig = go.Figure()\n",
    "\n",
    "# Cumulative Gains\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=review_pct,\n",
    "    y=cumulative_pct,\n",
    "    mode='lines',\n",
    "    name='ëª¨ë¸ ì„±ëŠ¥',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "\n",
    "# Random Baseline\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 100],\n",
    "    y=[0, 100],\n",
    "    mode='lines',\n",
    "    name='Random',\n",
    "    line=dict(color='gray', dash='dash')\n",
    "))\n",
    "\n",
    "# ì£¼ìš” ì§€ì  í‘œì‹œ\n",
    "for review_threshold in [10, 20, 30]:\n",
    "    idx = int(len(y_test) * review_threshold / 100)\n",
    "    gain = cumulative_pct[idx-1]\n",
    "    fig.add_annotation(\n",
    "        x=review_threshold,\n",
    "        y=gain,\n",
    "        text=f\"ìƒìœ„ {review_threshold}%: {gain:.1f}% í¬ì°©\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cumulative Gains Curve (Test Set)',\n",
    "    xaxis_title='ê²€í† í•œ ê¸°ì—… ë¹„ìœ¨ (%)',\n",
    "    yaxis_title='í¬ì°©í•œ ë¶€ë„ ê¸°ì—… ë¹„ìœ¨ (%)',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# íš¨ìœ¨ì„± ë¶„ì„\n",
    "print(f\"\\nğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ìƒìœ„ 10% ê²€í†  ì‹œ: {cumulative_pct[int(len(y_test)*0.1)-1]:.1f}% ë¶€ë„ í¬ì°©\")\n",
    "print(f\"ìƒìœ„ 20% ê²€í†  ì‹œ: {cumulative_pct[int(len(y_test)*0.2)-1]:.1f}% ë¶€ë„ í¬ì°©\")\n",
    "print(f\"ìƒìœ„ 30% ê²€í†  ì‹œ: {cumulative_pct[int(len(y_test)*0.3)-1]:.1f}% ë¶€ë„ í¬ì°©\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ’¡ í•´ì„: ìƒìœ„ 20% ê¸°ì—…ë§Œ ê²€í† í•´ë„ ë¶€ë„ ê¸°ì—…ì˜ ì•½ {cumulative_pct[int(len(y_test)*0.2)-1]:.0f}%ë¥¼ ì‚¬ì „ í¬ì°© ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ëª¨ë¸ ì €ì¥ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### 10.1 ëª¨ë¸ ë° ë°ì´í„° ì €ì¥ (Part 4 SHAP ë¶„ì„ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥ ê²½ë¡œ\n",
    "model_prefix = 'Part3_v2'\n",
    "\n",
    "# 1. ìµœì¢… ëª¨ë¸\n",
    "final_model_path = os.path.join(PROCESSED_DIR, f'{model_prefix}_ìµœì¢…ëª¨ë¸.pkl')\n",
    "joblib.dump(final_model, final_model_path)\n",
    "print(f\"âœ… ìµœì¢… ëª¨ë¸ ì €ì¥: {final_model_path}\")\n",
    "\n",
    "# 2. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
    "preprocessor_path = os.path.join(PROCESSED_DIR, f'{model_prefix}_ì „ì²˜ë¦¬ê¸°.pkl')\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "print(f\"âœ… ì „ì²˜ë¦¬ê¸° ì €ì¥: {preprocessor_path}\")\n",
    "\n",
    "# 3. ì „ì²˜ë¦¬ëœ ë°ì´í„° (SHAP ë¶„ì„ìš©)\n",
    "X_train_processed.to_csv(os.path.join(PROCESSED_DIR, f'{model_prefix}_X_train_processed.csv'), \n",
    "                         index=False, encoding='utf-8-sig')\n",
    "X_val_processed.to_csv(os.path.join(PROCESSED_DIR, f'{model_prefix}_X_val_processed.csv'), \n",
    "                       index=False, encoding='utf-8-sig')\n",
    "X_test_processed.to_csv(os.path.join(PROCESSED_DIR, f'{model_prefix}_X_test_processed.csv'), \n",
    "                        index=False, encoding='utf-8-sig')\n",
    "print(f\"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ (Train/Val/Test)\")\n",
    "\n",
    "# 4. íƒ€ê²Ÿ ë³€ìˆ˜\n",
    "y_train.to_csv(os.path.join(PROCESSED_DIR, f'{model_prefix}_y_train.csv'), \n",
    "               index=False, encoding='utf-8-sig', header=['target'])\n",
    "y_val.to_csv(os.path.join(PROCESSED_DIR, f'{model_prefix}_y_val.csv'), \n",
    "             index=False, encoding='utf-8-sig', header=['target'])\n",
    "y_test.to_csv(os.path.join(PROCESSED_DIR, f'{model_prefix}_y_test.csv'), \n",
    "              index=False, encoding='utf-8-sig', header=['target'])\n",
    "print(f\"âœ… íƒ€ê²Ÿ ë³€ìˆ˜ ì €ì¥ (Train/Val/Test)\")\n",
    "\n",
    "# 5. ì„ê³„ê°’ ë° ë©”íƒ€ë°ì´í„°\n",
    "metadata = {\n",
    "    'final_model_name': final_model_name,\n",
    "    'selected_threshold': selected_threshold,\n",
    "    'red_threshold': red_threshold,\n",
    "    'yellow_threshold': yellow_threshold,\n",
    "    'val_pr_auc': final_val_pr_auc,\n",
    "    'test_pr_auc': test_pr_auc,\n",
    "    'test_f2': test_f2,\n",
    "    'test_precision': test_precision,\n",
    "    'test_recall': test_recall,\n",
    "    'test_type_ii_error': type_ii_error,\n",
    "    'model_selection_info': model_selection_info,\n",
    "    'feature_names': list(X_train.columns),\n",
    "    'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(PROCESSED_DIR, f'{model_prefix}_ë©”íƒ€ë°ì´í„°.pkl')\n",
    "joblib.dump(metadata, metadata_path)\n",
    "print(f\"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}\")\n",
    "\n",
    "# 6. Feature Importance\n",
    "feature_importance_df.to_csv(os.path.join(PROCESSED_DIR, f'{model_prefix}_feature_importance.csv'), \n",
    "                             index=False, encoding='utf-8-sig')\n",
    "print(f\"âœ… Feature Importance ì €ì¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥ëœ íŒŒì¼ ëª©ë¡\n",
    "print(f\"\\nğŸ“ ì €ì¥ëœ íŒŒì¼ ëª©ë¡:\")\n",
    "print(\"=\"*70)\n",
    "import glob\n",
    "saved_files = glob.glob(os.path.join(PROCESSED_DIR, f'{model_prefix}*'))\n",
    "for f in sorted(saved_files):\n",
    "    size = os.path.getsize(f) / 1024\n",
    "    print(f\"  - {os.path.basename(f)} ({size:.1f} KB)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 ìµœì¢… ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ğŸ‰ Part 3 v2 ëª¨ë¸ë§ ë° ìµœì í™” ì™„ë£Œ!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½:\")\n",
    "print(f\"\\n1. ë°ì´í„° ë¶„í• :\")\n",
    "print(f\"   - Train Set:      {len(X_train):,} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   - Validation Set: {len(X_val):,} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"   - Test Set:       {len(X_test):,} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n2. ë¦¬ìƒ˜í”Œë§ ì „ëµ:\")\n",
    "print(f\"   - ì„ íƒ: {selected_strategy}\")\n",
    "\n",
    "print(f\"\\n3. ìµœì¢… ëª¨ë¸:\")\n",
    "print(f\"   - ëª¨ë¸: {final_model_name}\")\n",
    "print(f\"   - Validation PR-AUC: {final_val_pr_auc:.4f}\")\n",
    "print(f\"   - Test PR-AUC:       {test_pr_auc:.4f}\")\n",
    "print(f\"   - ì„ íƒ ì´ìœ : {decision_reason}\")\n",
    "\n",
    "print(f\"\\n4. ì„ê³„ê°’:\")\n",
    "print(f\"   - ìµœì  ì„ê³„ê°’: {selected_threshold:.4f}\")\n",
    "print(f\"   - Red Threshold:    {red_threshold:.4f} (Recall 80% ë³´ì¥)\")\n",
    "print(f\"   - Yellow Threshold: {yellow_threshold:.4f} (Recall 95% ë³´ì¥)\")\n",
    "\n",
    "print(f\"\\n5. Test Set ìµœì¢… ì„±ëŠ¥:\")\n",
    "print(f\"   - PR-AUC:        {test_pr_auc:.4f}\")\n",
    "print(f\"   - ROC-AUC:       {test_roc_auc:.4f}\")\n",
    "print(f\"   - F2-Score:      {test_f2:.4f}\")\n",
    "print(f\"   - Precision:     {test_precision:.2%}\")\n",
    "print(f\"   - Recall:        {test_recall:.2%}\")\n",
    "print(f\"   - Type II Error: {type_ii_error:.2%}\")\n",
    "\n",
    "print(f\"\\n6. Traffic Light ì„±ëŠ¥ (Test Set):\")\n",
    "print(f\"   - ë¦¬ìŠ¤í¬ ë°©ì–´ìœ¨: {test_capture_rate:.2%}\")\n",
    "print(f\"   - Red ê¸°ì—… ë¶€ë„ìœ¨:    {test_traffic_stats.loc['Red', 'ë¶€ë„ìœ¨']*100:.2f}%\")\n",
    "print(f\"   - Yellow ê¸°ì—… ë¶€ë„ìœ¨: {test_traffic_stats.loc['Yellow', 'ë¶€ë„ìœ¨']*100:.2f}%\")\n",
    "print(f\"   - Green ê¸°ì—… ë¶€ë„ìœ¨:  {test_traffic_stats.loc['Green', 'ë¶€ë„ìœ¨']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n7. Data Leakage ë°©ì§€ í™•ì¸:\")\n",
    "print(f\"   âœ… Test setì€ ìµœì¢… í‰ê°€ì—ì„œë§Œ ë‹¨ í•œ ë²ˆ ì‚¬ìš©\")\n",
    "print(f\"   âœ… ëª¨ë“  ì˜ì‚¬ê²°ì •(ëª¨ë¸ ì„ íƒ, ì„ê³„ê°’)ì€ Validation set ê¸°ë°˜\")\n",
    "print(f\"   âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì€ Train set 5-Fold CVë§Œ ì‚¬ìš©\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"\\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„: Part 4 - SHAP ë¶„ì„ ë° ëª¨ë¸ í•´ì„\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Part 3 v2 ì™„ë£Œ\n",
    "\n",
    "**í•µì‹¬ ê°œì„  ì‚¬í•­:**\n",
    "1. âœ… **Data Leakage ì™„ì „ ì œê±°** - Test setì€ ìµœì¢… í‰ê°€ë§Œ\n",
    "2. âœ… **3-Way Split** - Train/Validation/Test ëª…í™•í•œ ë¶„ë¦¬\n",
    "3. âœ… **ë¦¬ìƒ˜í”Œë§ ì „ëµ ëŒ€ì¡° ì‹¤í—˜** - SMOTE vs Class Weight\n",
    "4. âœ… **Validation ê¸°ë°˜ ëª¨ë¸ ì„ íƒ** - Statistical Test í¬í•¨\n",
    "5. âœ… **Validation ê¸°ë°˜ ì„ê³„ê°’ ìµœì í™”** - F2-Score, Recall ìš°ì„ \n",
    "6. âœ… **ë°ì´í„° ê¸°ë°˜ Traffic Light** - Recall ë³´ì¥ ì„ê³„ê°’\n",
    "7. âœ… **Test Set ë‹¨ í•œ ë²ˆ í‰ê°€** - ì¼ë°˜í™” ì„±ëŠ¥ ê²€ì¦\n",
    "\n",
    "**í•™ìˆ ì  ì—„ë°€ì„±:**\n",
    "- âœ… ì¬í˜„ ê°€ëŠ¥ì„± (random_state ì„¤ì •)\n",
    "- âœ… Stratified Split (ë¶€ë„ìœ¨ ìœ ì§€)\n",
    "- âœ… Cross-Validation (5-Fold)\n",
    "- âœ… Statistical Significance Test (Wilcoxon)\n",
    "\n",
    "**ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜:**\n",
    "- âœ… F2-Score (Recall ìš°ì„ )\n",
    "- âœ… Traffic Light ì‹œìŠ¤í…œ (ì˜ì‚¬ê²°ì • ì§€ì›)\n",
    "- âœ… Cumulative Gains (íš¨ìœ¨ì„± ì…ì¦)\n",
    "- âœ… Type II Error ìµœì†Œí™”\n",
    "\n",
    "**Part 4 ì¤€ë¹„:**\n",
    "- âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ\n",
    "- âœ… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì €ì¥\n",
    "- âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ (SHAP ë¶„ì„ìš©)\n",
    "- âœ… Feature Importance ì €ì¥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}