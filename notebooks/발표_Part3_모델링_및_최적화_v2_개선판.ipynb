{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìó Î∞úÌëúÏö© Part 3: Î™®Îç∏ÎßÅ Î∞è ÏµúÏ†ÅÌôî v2 Í∞úÏÑ†Ìåê\n",
    "\n",
    "## üéØ v2 Í∞úÏÑ†Ìåê Ï£ºÏöî Î≥ÄÍ≤Ω ÏÇ¨Ìï≠\n",
    "\n",
    "### v2 ÎåÄÎπÑ Í∞úÏÑ† ÏÇ¨Ìï≠ (P0/P1 Î™®Îëê Î∞òÏòÅ)\n",
    "\n",
    "**P0 (ÌïÑÏàò ÏàòÏ†ï):**\n",
    "1. ‚úÖ **Pipeline Íµ¨Ï°∞ ÎèÑÏûÖ** - ImbPipeline ÏÇ¨Ïö©, Ï†ÑÏ≤òÎ¶¨+Î¶¨ÏÉòÌîåÎßÅ+Î™®Îç∏ ÌÜµÌï©\n",
    "2. ‚úÖ **RandomizedSearchCV n_iter=200** - ÌÉêÏÉâ ÏÑ±Îä• Ìñ•ÏÉÅ\n",
    "3. ‚úÖ **ÏïôÏÉÅÎ∏î Îã§ÏñëÏÑ± Ï≤¥ÌÅ¨** - Top 3Í∞Ä Î™®Îëê GBMÏù¥Î©¥ Ïù¥Ï¢Ö Î™®Îç∏ Í∞ïÏ†ú Ìè¨Ìï®\n",
    "\n",
    "**P1 (Í∂åÏû• Í∞úÏÑ†):**\n",
    "4. ‚úÖ **CV Í∏∞Î∞ò ÏûÑÍ≥ÑÍ∞í ÏµúÏ†ÅÌôî** - Validation + CV ÌèâÍ∑† ÏÇ¨Ïö©\n",
    "5. ‚úÖ **Winsorizer Ïã§Ìóò** - ÏûàÏùå/ÏóÜÏùå ÏÑ±Îä• ÎπÑÍµê\n",
    "6. ‚úÖ **Traffic Light Yellow Î°úÏßÅ ÏùºÍ¥ÄÏÑ±** - Recall Í∏∞Ï§Ä ÏùºÍ¥Ä ÏÇ¨Ïö©\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Part 3 Î™©Ìëú Î∞è Ïù¥Ï†Ñ Part ÏöîÏïΩ\n",
    "\n",
    "### Ïù¥Ï†Ñ Part ÏôÑÎ£å ÏÇ¨Ìï≠\n",
    "\n",
    "**Part 1: Î¨∏Ï†ú Ï†ïÏùò Î∞è ÌïµÏã¨ Î∞úÍ≤¨**\n",
    "- 50,105Í∞ú ÌïúÍµ≠ Í∏∞ÏóÖ, Î∂ÄÎèÑÏú® 1.51% (1:66 Î∂àÍ∑†Ìòï)\n",
    "- **ÌïµÏã¨ Î∞úÍ≤¨**: Ïú†ÎèôÏÑ±Ïù¥ Í∞ÄÏû• Í∞ïÎ†•Ìïú ÏòàÏ∏° Î≥ÄÏàò\n",
    "- ÏóÖÏ¢ÖÎ≥Ñ Î∂ÄÎèÑÏú® 2Î∞∞ Ï∞®Ïù¥ (Ï†úÏ°∞ÏóÖ vs ÏÑúÎπÑÏä§ÏóÖ)\n",
    "\n",
    "**Part 2: ÎèÑÎ©îÏù∏ ÌäπÏÑ± Í≥µÌïô**\n",
    "- 52Í∞ú ÎèÑÎ©îÏù∏ Í∏∞Î∞ò ÌäπÏÑ± ÏÉùÏÑ±\n",
    "- VIF/IV/AUC Í∏∞Î∞ò ÌäπÏÑ± ÏÑ†ÌÉù ‚Üí **27Í∞ú ÏµúÏ¢Ö ÌäπÏÑ±**\n",
    "- 7Í∞ú Ïπ¥ÌÖåÍ≥†Î¶¨: Ïú†ÎèôÏÑ±, ÏßÄÍ∏âÎ∂àÎä•, Ïû¨Î¨¥Ï°∞Ïûë, ÌïúÍµ≠ÏãúÏû•, Ïù¥Ìï¥Í¥ÄÍ≥ÑÏûê, Î≥µÌï©Î¶¨Ïä§ÌÅ¨, ÏÉÅÌò∏ÏûëÏö©\n",
    "\n",
    "### Part 3 v2 Î™©Ìëú (Data Leakage ÏôÑÏ†Ñ Ï†úÍ±∞)\n",
    "\n",
    "**üö® ÌïµÏã¨ Í∞úÏÑ†: Data Leakage ÏôÑÏ†Ñ Ï†úÍ±∞**\n",
    "\n",
    "```\n",
    "‚úÖ v2 Ìï¥Í≤∞Ï±Ö:\n",
    "- 3-Way Split (Train/Validation/Test)\n",
    "- Test setÏùÄ ÏµúÏ¢Ö ÌèâÍ∞Ä ÏßÅÏ†Ñ Îã® Ìïú Î≤àÎßå\n",
    "- Î™®Îì† ÏùòÏÇ¨Í≤∞Ï†ïÏùÄ Validation set Í∏∞Î∞ò\n",
    "- Pipeline Íµ¨Ï°∞Î°ú Ï†ÑÏ≤òÎ¶¨/Î¶¨ÏÉòÌîåÎßÅ ÎàÑÎùΩ Î∞©ÏßÄ\n",
    "```\n",
    "\n",
    "**Ï£ºÏöî Í∞úÏÑ† ÏÇ¨Ìï≠:**\n",
    "1. **3-Way Data Split** (Train 60% / Validation 20% / Test 20%)\n",
    "2. **Pipeline Í∏∞Î∞ò Î¶¨ÏÉòÌîåÎßÅ Ï†ÑÎûµ** (SMOTE vs Class Weight)\n",
    "3. **Validation Í∏∞Î∞ò Î™®Îç∏ ÏÑ†ÌÉù** + Statistical Test + Ensemble Diversity\n",
    "4. **CV+Validation ÏûÑÍ≥ÑÍ∞í ÏµúÏ†ÅÌôî** (F2-Score, Recall Ïö∞ÏÑ†)\n",
    "5. **Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò Traffic Light** (Recall 80%/95% Î≥¥Ïû•)\n",
    "6. **Test SetÏùÄ ÎßàÏßÄÎßâ ÌèâÍ∞ÄÎßå** (Ï†àÎåÄ ÏùòÏÇ¨Í≤∞Ï†ïÏóê ÏÇ¨Ïö© Ïïà Ìï®)\n",
    "\n",
    "**Î™©Ìëú ÏÑ±Îä•:**\n",
    "- PR-AUC: 0.15~0.20 (Î∂àÍ∑†Ìòï Îç∞Ïù¥ÌÑ∞ Í≥†Î†§)\n",
    "- F2-Score: 0.35~0.50 (Recall Ïö∞ÏÑ†)\n",
    "- Recall: 60~80%\n",
    "- Type II Error: 20~40% (Î∂ÄÎèÑ ÎØ∏ÌÉêÏßÄ ÏµúÏÜåÌôî)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ÌôòÍ≤Ω ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í∏∞Î≥∏ ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import platform\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î®∏Ïã†Îü¨Îãù - Ï†ÑÏ≤òÎ¶¨\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Î®∏Ïã†Îü¨Îãù - Î™®Îç∏\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î®∏Ïã†Îü¨Îãù - ÌäúÎãù (‚≠ê Pipeline ÏÇ¨Ïö©)\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # ‚≠ê Imbalanced Pipeline\n",
    "\n",
    "# Î∂àÍ∑†Ìòï Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌèâÍ∞Ä Î©îÌä∏Î¶≠\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, roc_curve,\n",
    "    make_scorer, fbeta_score, recall_score, precision_score\n",
    ")\n",
    "\n",
    "# ÌÜµÍ≥Ñ Í≤ÄÏ†ï\n",
    "from scipy.stats import wilcoxon, ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≤ΩÍ≥† Î¨¥Ïãú\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ÌïúÍ∏Ä Ìè∞Ìä∏ ÏÑ§Ï†ï (CLAUDE.md Ï§ÄÏàò)\n",
    "if platform.system() == 'Darwin':\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "else:\n",
    "    plt.rc('font', family='NanumGothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî ÏÑ§Ï†ï\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# ÎûúÎç§ ÏãúÎìú (Ïû¨ÌòÑÏÑ±)\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn, catboost Î≤ÑÏ†Ñ ÏûÑÌè¨Ìä∏\n",
    "import sklearn\n",
    "import catboost\n",
    "\n",
    "print(\"‚úÖ ÌôòÍ≤Ω ÏÑ§Ï†ï ÏôÑÎ£å\")\n",
    "print(f\"   - NumPy: {np.__version__}\")\n",
    "print(f\"   - Pandas: {pd.__version__}\")\n",
    "print(f\"   - Scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"   - LightGBM: {lgb.__version__}\")\n",
    "print(f\"   - XGBoost: {xgb.__version__}\")\n",
    "print(f\"   - CatBoost: {catboost.__version__}\")\n",
    "print(f\"   - Platform: {platform.system()}\")\n",
    "print(f\"   - Random State: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Îç∞Ïù¥ÌÑ∞ Î°úÎî© Î∞è 3-Way Split ‚≠ê\n",
    "\n",
    "### 1.1 Îç∞Ïù¥ÌÑ∞ Î°úÎî©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú (ÌïòÎìúÏΩîÎî© Í∏àÏßÄ)\n",
    "DATA_DIR = '../data'\n",
    "FEATURES_FILE = os.path.join(DATA_DIR, 'features', 'domain_based_features_ÏôÑÏ†ÑÌåê.csv')\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "\n",
    "# ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎî©\n",
    "print(f\"üìÇ Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ë: {FEATURES_FILE}\")\n",
    "df = pd.read_csv(FEATURES_FILE, encoding='utf-8')\n",
    "\n",
    "print(f\"‚úÖ Îç∞Ïù¥ÌÑ∞ Î°úÎî© ÏôÑÎ£å\")\n",
    "print(f\"   - Ï†ÑÏ≤¥ Í∏∞ÏóÖ Ïàò: {len(df):,}\")\n",
    "print(f\"   - Ï†ÑÏ≤¥ Î≥ÄÏàò Ïàò: {len(df.columns)}\")\n",
    "print(f\"   - Î©îÎ™®Î¶¨ ÏÇ¨Ïö©: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÎØ∏Î¶¨Î≥¥Í∏∞\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌÉÄÍ≤ü Î≥ÄÏàò ÌôïÏù∏\n",
    "TARGET_COL = 'Î™®ÌòïÍ∞úÎ∞úÏö©Performance(Ìñ•ÌõÑ1ÎÖÑÎÇ¥Î∂ÄÎèÑÏó¨Î∂Ä)'\n",
    "\n",
    "print(f\"üéØ ÌÉÄÍ≤ü Î≥ÄÏàò: {TARGET_COL}\")\n",
    "print(f\"\\nÎ∂ÄÎèÑ Î∂ÑÌè¨:\")\n",
    "print(df[TARGET_COL].value_counts())\n",
    "print(f\"\\nÎ∂ÄÎèÑÏú®: {df[TARGET_COL].mean():.4%}\")\n",
    "print(f\"Î∂àÍ∑†Ìòï ÎπÑÏú®: 1:{int(1/df[TARGET_COL].mean())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ÌäπÏÑ± Î∞è ÌÉÄÍ≤ü Î∂ÑÎ¶¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌäπÏÑ±(X)Í≥º ÌÉÄÍ≤ü(y) Î∂ÑÎ¶¨\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "print(f\"‚úÖ ÌäπÏÑ± Î∞è ÌÉÄÍ≤ü Î∂ÑÎ¶¨ ÏôÑÎ£å\")\n",
    "print(f\"   - X shape: {X.shape}\")\n",
    "print(f\"   - y shape: {y.shape}\")\n",
    "print(f\"   - ÌäπÏÑ± Î™©Î°ù (27Í∞ú):\")\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f\"      {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 3-Way Split: Train / Validation / Test ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "**üö® Data Leakage Î∞©ÏßÄÎ•º ÏúÑÌïú ÌïµÏã¨ ÏÑ§Í≥Ñ:**\n",
    "\n",
    "```\n",
    "Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ (50,105)\n",
    "‚îú‚îÄ Train Set (60%, ~30,063): Î™®Îç∏ ÌïôÏäµ + CV ÌäúÎãù\n",
    "‚îú‚îÄ Validation Set (20%, ~10,021): Î™®Îç∏ ÏÑ†ÌÉù, ÏûÑÍ≥ÑÍ∞í ÏµúÏ†ÅÌôî, ÏùòÏÇ¨Í≤∞Ï†ï\n",
    "‚îî‚îÄ Test Set (20%, ~10,021): ÏµúÏ¢Ö ÌèâÍ∞ÄÎßå (Ï†àÎåÄ Í±¥ÎìúÎ¶¨ÏßÄ ÏïäÏùå!)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ï∞® Î∂ÑÌï†: Train+Val (80%) vs Test (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 2Ï∞® Î∂ÑÌï†: Train (60%) vs Validation (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=0.25, \n",
    "    stratify=y_temp, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ 3-Way Split ÏôÑÎ£å\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train Set:      {len(X_train):,} ({len(X_train)/len(X)*100:.1f}%, Î∂ÄÎèÑÏú®: {y_train.mean():.4%})\")\n",
    "print(f\"Validation Set: {len(X_val):,} ({len(X_val)/len(X)*100:.1f}%, Î∂ÄÎèÑÏú®: {y_val.mean():.4%})\")\n",
    "print(f\"Test Set:       {len(X_test):,} ({len(X_test)/len(X)*100:.1f}%, Î∂ÄÎèÑÏú®: {y_test.mean():.4%})\")\n",
    "print(\"=\"*70)\n",
    "print(\"‚ö†Ô∏è  Test SetÏùÄ ÏµúÏ¢Ö ÌèâÍ∞Ä Ï†ÑÍπåÏßÄ Ï†àÎåÄ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏùå!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î∂àÍ∑†Ìòï ÎπÑÏú® Í≥ÑÏÇ∞ (Class WeightÏö©)\n",
    "n_pos = y_train.sum()\n",
    "n_neg = len(y_train) - n_pos\n",
    "imbalance_ratio = n_neg / n_pos\n",
    "\n",
    "print(f\"üìä Train Set Î∂àÍ∑†Ìòï Î∂ÑÏÑù\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"Î∂ÄÎèÑ Í∏∞ÏóÖ (Positive):  {n_pos:,} ({n_pos/len(y_train)*100:.2f}%)\")\n",
    "print(f\"Ï†ïÏÉÅ Í∏∞ÏóÖ (Negative):  {n_neg:,} ({n_neg/len(y_train)*100:.2f}%)\")\n",
    "print(f\"Î∂àÍ∑†Ìòï ÎπÑÏú®:           1:{imbalance_ratio:.1f}\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"\\nClass Weight Í≥ÑÏÇ∞:\")\n",
    "print(f\"  - sqrt(neg/pos) = {np.sqrt(imbalance_ratio):.2f}\")\n",
    "print(f\"  - neg/pos = {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ï†ÑÏ≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ Ï†ïÏùò\n",
    "\n",
    "### 2.1 Custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformer 1: Î¨¥ÌïúÎåÄ Í∞í Ï≤òÎ¶¨\n",
    "class InfiniteHandler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Î¨¥ÌïúÎåÄ Í∞íÏùÑ 0ÏúºÎ°ú ÎåÄÏ≤¥\"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X = X.replace([np.inf, -np.inf], 0)\n",
    "        return X\n",
    "\n",
    "print(\"‚úÖ InfiniteHandler Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformer 2: Winsorizer (Ïù¥ÏÉÅÏπò Ï†úÌïú)\n",
    "class Winsorizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Ïù¥ÏÉÅÏπòÎ•º percentile Î≤îÏúÑÎ°ú Ï†úÌïú\"\"\"\n",
    "    \n",
    "    def __init__(self, lower=0.005, upper=0.995):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.lower_bounds_ = None\n",
    "        self.upper_bounds_ = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.lower_bounds_ = np.percentile(X, self.lower * 100, axis=0)\n",
    "        self.upper_bounds_ = np.percentile(X, self.upper * 100, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X = np.clip(X, self.lower_bounds_, self.upper_bounds_)\n",
    "        return X\n",
    "\n",
    "print(\"‚úÖ Winsorizer Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ÌååÏù¥ÌîÑÎùºÏù∏ ÏÉùÏÑ± Ìï®Ïàò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessing_pipeline(use_winsorizer=False):\n",
    "    \"\"\"\n",
    "    Ï†ÑÏ≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ ÏÉùÏÑ±\n",
    "    \n",
    "    ÏàúÏÑú: InfiniteHandler ‚Üí Imputer ‚Üí Winsorizer(ÏÑ†ÌÉù) ‚Üí Scaler\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    use_winsorizer : bool, default=False\n",
    "        Winsorizer Ï†ÅÏö© Ïó¨Î∂Ä\n",
    "    \"\"\"\n",
    "    steps = [\n",
    "        ('inf_handler', InfiniteHandler()),\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "    ]\n",
    "    \n",
    "    if use_winsorizer:\n",
    "        steps.append(('winsorizer', Winsorizer(0.005, 0.995)))\n",
    "    \n",
    "    steps.append(('scaler', RobustScaler()))\n",
    "    \n",
    "    return Pipeline(steps)\n",
    "\n",
    "print(\"‚úÖ Ï†ÑÏ≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ ÏÉùÏÑ± Ìï®Ïàò Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 P1 Í∞úÏÑ†: Winsorizer Ïã§Ìóò ‚≠ê\n",
    "\n",
    "**Î™©Ï†Å:** Tree Î™®Îç∏ÏùÄ Ïù¥ÏÉÅÏπòÏóê Í∞ïÍ±¥ÌïòÏßÄÎßå, Î∂ÄÎèÑ Îç∞Ïù¥ÌÑ∞Ïùò Í∑πÎã®Í∞íÏù¥ Ï§ëÏöî ÏãúÍ∑∏ÎÑêÏùº Ïàò ÏûàÏùå\n",
    "\n",
    "**Ïã§Ìóò:** Winsorizer ÏûàÏùå vs ÏóÜÏùå ÏÑ±Îä• ÎπÑÍµê (Validation Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorizer Ïã§Ìóò (LightGBM Îπ†Î•∏ ÌÖåÏä§Ìä∏)\n",
    "print(\"üìä Winsorizer Ïã§Ìóò (Validation Set Í∏∞Î∞ò)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "winsorizer_results = {}\n",
    "\n",
    "for use_wins in [False, True]:\n",
    "    label = \"Winsorizer ÏûàÏùå\" if use_wins else \"Winsorizer ÏóÜÏùå\"\n",
    "    \n",
    "    # Ï†ÑÏ≤òÎ¶¨\n",
    "    prep = create_preprocessing_pipeline(use_winsorizer=use_wins)\n",
    "    X_train_prep = prep.fit_transform(X_train)\n",
    "    X_val_prep = prep.transform(X_val)\n",
    "    \n",
    "    # LightGBM ÌïôÏäµ\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        scale_pos_weight=np.sqrt(imbalance_ratio),\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    model.fit(X_train_prep, y_train)\n",
    "    \n",
    "    # Validation ÌèâÍ∞Ä\n",
    "    y_val_prob = model.predict_proba(X_val_prep)[:, 1]\n",
    "    pr_auc = average_precision_score(y_val, y_val_prob)\n",
    "    \n",
    "    winsorizer_results[label] = pr_auc\n",
    "    print(f\"{label:20s} | Validation PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ÏÑ†ÌÉù\n",
    "if winsorizer_results[\"Winsorizer ÏûàÏùå\"] > winsorizer_results[\"Winsorizer ÏóÜÏùå\"]:\n",
    "    use_winsorizer_final = True\n",
    "    diff = winsorizer_results[\"Winsorizer ÏûàÏùå\"] - winsorizer_results[\"Winsorizer ÏóÜÏùå\"]\n",
    "    print(f\"‚úÖ ÏÑ†ÌÉù: Winsorizer ÏÇ¨Ïö© (PR-AUC +{diff:.4f})\")\n",
    "else:\n",
    "    use_winsorizer_final = False\n",
    "    diff = winsorizer_results[\"Winsorizer ÏóÜÏùå\"] - winsorizer_results[\"Winsorizer ÏûàÏùå\"]\n",
    "    print(f\"‚úÖ ÏÑ†ÌÉù: Winsorizer ÎØ∏ÏÇ¨Ïö© (PR-AUC +{diff:.4f})\")\n",
    "    print(f\"   Ïù¥Ïú†: Tree Î™®Îç∏ÏùÄ Ïù¥ÏÉÅÏπòÏóê Í∞ïÍ±¥, Í∑πÎã®Í∞íÏù¥ Î∂ÄÎèÑ ÏãúÍ∑∏ÎÑêÏùº Ïàò ÏûàÏùå\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. P0 Í∞úÏÑ†: Pipeline Í∏∞Î∞ò Î¶¨ÏÉòÌîåÎßÅ Ï†ÑÎûµ ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "### 3.1 Í∞úÏÑ† ÏÇ¨Ìï≠\n",
    "\n",
    "**v2 Î¨∏Ï†úÏ†ê:**\n",
    "- Ï†ÑÏ≤òÎ¶¨ÏôÄ Î™®Îç∏Ïù¥ Î∂ÑÎ¶¨ ‚Üí Ïû¨ÏÇ¨Ïö© Ïãú Ïò§Î•ò ÏúÑÌóò\n",
    "- Î¶¨ÏÉòÌîåÎßÅÏùÑ PipelineÏóê ÌÜµÌï©ÌïòÏßÄ ÏïäÏùå\n",
    "\n",
    "**v2 Í∞úÏÑ†Ìåê Ìï¥Í≤∞Ï±Ö:**\n",
    "- ‚úÖ **ImbPipeline** ÏÇ¨Ïö©: Ï†ÑÏ≤òÎ¶¨ + Î¶¨ÏÉòÌîåÎßÅ + Î™®Îç∏ ÌÜµÌï©\n",
    "- ‚úÖ Raw Îç∞Ïù¥ÌÑ∞Î°ú AutoML (Ï†ÑÏ≤òÎ¶¨ ÎàÑÎùΩ Î∞©ÏßÄ)\n",
    "- ‚úÖ Best practice Ï§ÄÏàò\n",
    "\n",
    "### 3.2 Pipeline ÏÉùÏÑ± Ìï®Ïàò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_pipeline(classifier, resampler='passthrough', use_winsorizer=False):\n",
    "    \"\"\"\n",
    "    Ï†ÑÏ≤¥ Î™®Îç∏ ÌååÏù¥ÌîÑÎùºÏù∏ ÏÉùÏÑ± (Ï†ÑÏ≤òÎ¶¨ + Î¶¨ÏÉòÌîåÎßÅ + Î™®Îç∏)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    classifier : estimator\n",
    "        Î∂ÑÎ•ò Î™®Îç∏\n",
    "    resampler : 'passthrough' or sampler object\n",
    "        Î¶¨ÏÉòÌîåÎßÅ Î∞©Î≤ï (passthrough=ÏóÜÏùå)\n",
    "    use_winsorizer : bool\n",
    "        Winsorizer ÏÇ¨Ïö© Ïó¨Î∂Ä\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pipeline : ImbPipeline\n",
    "    \"\"\"\n",
    "    # Ï†ÑÏ≤òÎ¶¨ Îã®Í≥Ñ\n",
    "    steps = [\n",
    "        ('inf_handler', InfiniteHandler()),\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "    ]\n",
    "    \n",
    "    if use_winsorizer:\n",
    "        steps.append(('winsorizer', Winsorizer(0.005, 0.995)))\n",
    "    \n",
    "    steps.append(('scaler', RobustScaler()))\n",
    "    \n",
    "    # Î¶¨ÏÉòÌîåÎßÅ + Î™®Îç∏\n",
    "    steps.append(('resampler', resampler))\n",
    "    steps.append(('classifier', classifier))\n",
    "    \n",
    "    return ImbPipeline(steps)\n",
    "\n",
    "print(\"‚úÖ Pipeline ÏÉùÏÑ± Ìï®Ïàò Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Î¶¨ÏÉòÌîåÎßÅ Ï†ÑÎûµ ÎåÄÏ°∞ Ïã§Ìóò (Pipeline Í∏∞Î∞ò)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Î¶¨ÏÉòÌîåÎßÅ Ï†ÑÎûµ ÎåÄÏ°∞ Ïã§Ìóò (Pipeline Í∏∞Î∞ò)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Strategy A: SMOTE Í≥ÑÏó¥ (Class Weight ÏóÜÏùå)\")\n",
    "print(\"Strategy B: Class Weight Only (Î¶¨ÏÉòÌîåÎßÅ ÏóÜÏùå)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy A: SMOTE Í≥ÑÏó¥\n",
    "print(\"\\nüîµ Strategy A: SMOTE Í≥ÑÏó¥\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "smote_methods = {\n",
    "    'SMOTE': SMOTE(sampling_strategy=0.2, random_state=RANDOM_STATE),\n",
    "    'BorderlineSMOTE': BorderlineSMOTE(sampling_strategy=0.2, random_state=RANDOM_STATE),\n",
    "    'SMOTETomek': SMOTETomek(sampling_strategy=0.2, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "strategy_a_results = {}\n",
    "\n",
    "for name, sampler in smote_methods.items():\n",
    "    # Pipeline ÏÉùÏÑ± (Class Weight ÏóÜÏùå)\n",
    "    pipeline = create_model_pipeline(\n",
    "        classifier=lgb.LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            scale_pos_weight=1,  # Class Weight ÏóÜÏùå\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        ),\n",
    "        resampler=sampler,\n",
    "        use_winsorizer=use_winsorizer_final\n",
    "    )\n",
    "    \n",
    "    # ‚≠ê Raw Îç∞Ïù¥ÌÑ∞Î°ú ÌïôÏäµ (Ï†ÑÏ≤òÎ¶¨Îäî Pipeline ÎÇ¥Î∂ÄÏóêÏÑú)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation ÌèâÍ∞Ä\n",
    "    y_val_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "    pr_auc = average_precision_score(y_val, y_val_prob)\n",
    "    \n",
    "    strategy_a_results[name] = pr_auc\n",
    "    print(f\"{name:20s} | Validation PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy B: Class Weight Only\n",
    "print(\"\\nüü¢ Strategy B: Class Weight Only\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "class_weight_methods = {\n",
    "    'No Weight': 1,\n",
    "    'Sqrt Weight': np.sqrt(imbalance_ratio),\n",
    "    'Full Weight': imbalance_ratio\n",
    "}\n",
    "\n",
    "strategy_b_results = {}\n",
    "\n",
    "for name, weight in class_weight_methods.items():\n",
    "    # Pipeline ÏÉùÏÑ± (Î¶¨ÏÉòÌîåÎßÅ ÏóÜÏùå)\n",
    "    pipeline = create_model_pipeline(\n",
    "        classifier=lgb.LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            scale_pos_weight=weight,  # Class Weight ÏÇ¨Ïö©\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        ),\n",
    "        resampler='passthrough',  # Î¶¨ÏÉòÌîåÎßÅ ÏóÜÏùå\n",
    "        use_winsorizer=use_winsorizer_final\n",
    "    )\n",
    "    \n",
    "    # Raw Îç∞Ïù¥ÌÑ∞Î°ú ÌïôÏäµ\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation ÌèâÍ∞Ä\n",
    "    y_val_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "    pr_auc = average_precision_score(y_val, y_val_prob)\n",
    "    \n",
    "    strategy_b_results[name] = pr_auc\n",
    "    print(f\"{name:20s} | Validation PR-AUC: {pr_auc:.4f} (weight={weight:.2f})\")\n",
    "\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÑÎûµ ÏÑ†ÌÉù\n",
    "best_a_name = max(strategy_a_results, key=strategy_a_results.get)\n",
    "best_a_pr_auc = strategy_a_results[best_a_name]\n",
    "\n",
    "best_b_name = max(strategy_b_results, key=strategy_b_results.get)\n",
    "best_b_pr_auc = strategy_b_results[best_b_name]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä Î¶¨ÏÉòÌîåÎßÅ Ï†ÑÎûµ ÎπÑÍµê Í≤∞Í≥º (Validation Set Í∏∞Î∞ò)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Strategy A (SMOTE Í≥ÑÏó¥) ÏµúÍ≥†:  {best_a_name:20s} | PR-AUC = {best_a_pr_auc:.4f}\")\n",
    "print(f\"Strategy B (Class Weight) ÏµúÍ≥†: {best_b_name:20s} | PR-AUC = {best_b_pr_auc:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if best_b_pr_auc > best_a_pr_auc:\n",
    "    diff = best_b_pr_auc - best_a_pr_auc\n",
    "    pct = diff / best_a_pr_auc * 100\n",
    "    selected_strategy = 'Class Weight'\n",
    "    selected_weight = class_weight_methods[best_b_name]\n",
    "    selected_resampler = 'passthrough'\n",
    "    print(f\"‚úÖ ÏÑ†ÌÉù: Strategy B (Class Weight)\")\n",
    "    print(f\"   - Ïù¥Ïú†: {diff:.4f} ({pct:.2f}%) Îçî Ïö∞Ïàò\")\n",
    "    print(f\"   - scale_pos_weight: {selected_weight:.2f}\")\n",
    "else:\n",
    "    diff = best_a_pr_auc - best_b_pr_auc\n",
    "    pct = diff / best_b_pr_auc * 100\n",
    "    selected_strategy = 'SMOTE'\n",
    "    selected_weight = 1\n",
    "    selected_resampler = smote_methods[best_a_name]\n",
    "    print(f\"‚úÖ ÏÑ†ÌÉù: Strategy A (SMOTE Í≥ÑÏó¥)\")\n",
    "    print(f\"   - Ïù¥Ïú†: {diff:.4f} ({pct:.2f}%) Îçî Ïö∞Ïàò\")\n",
    "    print(f\"   - Î∞©Î≤ï: {best_a_name}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. P0 Í∞úÏÑ†: AutoML ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù (n_iter=200) ‚≠ê\n",
    "\n",
    "### 4.1 Í∞úÏÑ† ÏÇ¨Ìï≠\n",
    "\n",
    "**v2 Î¨∏Ï†úÏ†ê:**\n",
    "- n_iter=50~100 ‚Üí ÌÉêÏÉâ Í≥µÍ∞Ñ ÎåÄÎπÑ 1% ÎØ∏Îßå\n",
    "\n",
    "**v2 Í∞úÏÑ†Ìåê:**\n",
    "- ‚úÖ **n_iter=200** (Î™®Îç∏Î≥Ñ)\n",
    "- ‚úÖ Pipeline Í∏∞Î∞ò AutoML\n",
    "- ‚úÖ Raw Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïö©\n",
    "\n",
    "### 4.2 Scorer Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR-AUC Scorer (Ï£ºÏöî ÏßÄÌëú)\n",
    "pr_auc_scorer = make_scorer(average_precision_score, needs_proba=True)\n",
    "\n",
    "print(\"‚úÖ Scorer Ï†ïÏùò ÏôÑÎ£å\")\n",
    "print(\"   - PR-AUC: Î∂àÍ∑†Ìòï Îç∞Ïù¥ÌÑ∞ ÌïµÏã¨ ÏßÄÌëú\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î¶¨Îìú Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏÑ†ÌÉùÎêú Ï†ÑÎûµÏóê Îî∞Î•∏ ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "if selected_strategy == 'Class Weight':\n",
    "    # Strategy B: Class WeightÎßå ÏÇ¨Ïö©\n",
    "    resampler_options = ['passthrough']\n",
    "    scale_pos_weight_options = [selected_weight]\n",
    "    print(f\"‚úÖ ÏÑ†ÌÉùÎêú Ï†ÑÎûµ: Class Weight (scale_pos_weight={selected_weight:.2f})\")\n",
    "else:\n",
    "    # Strategy A: SMOTE ÏÇ¨Ïö©\n",
    "    resampler_options = [selected_resampler]\n",
    "    scale_pos_weight_options = [1]\n",
    "    print(f\"‚úÖ ÏÑ†ÌÉùÎêú Ï†ÑÎûµ: SMOTE ({best_a_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î¶¨Îìú\n",
    "lgbm_param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7, 10, -1],\n",
    "    'classifier__num_leaves': [15, 31, 63, 127],\n",
    "    'classifier__min_child_samples': [10, 20, 30, 50],\n",
    "    'classifier__subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "    'classifier__reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'classifier__reg_lambda': [0, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "# XGBoost ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î¶¨Îìú\n",
    "xgb_param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7, 10],\n",
    "    'classifier__min_child_weight': [1, 3, 5, 7],\n",
    "    'classifier__subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "    'classifier__gamma': [0, 0.1, 0.2, 0.5],\n",
    "    'classifier__reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'classifier__reg_lambda': [0, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "# CatBoost ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î¶¨Îìú\n",
    "catboost_param_grid = {\n",
    "    'classifier__iterations': [50, 100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'classifier__depth': [3, 5, 7, 10],\n",
    "    'classifier__l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "}\n",
    "\n",
    "# Logistic Regression ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î¶¨Îìú\n",
    "lr_param_grid = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga'],\n",
    "    'classifier__max_iter': [1000],\n",
    "}\n",
    "\n",
    "# Random Forest ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î¶¨Îìú\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300],\n",
    "    'classifier__max_depth': [5, 10, 15, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "print(\"‚úÖ ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î¶¨Îìú Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Î™®Îç∏ Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î™®Îç∏ Ï†ïÏùò (PipelineÏúºÎ°ú wrapping)\n",
    "models_to_tune = {\n",
    "    'LightGBM': {\n",
    "        'pipeline': create_model_pipeline(\n",
    "            lgb.LGBMClassifier(\n",
    "                scale_pos_weight=selected_weight,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1,\n",
    "                verbose=-1\n",
    "            ),\n",
    "            resampler=selected_resampler if selected_strategy == 'SMOTE' else 'passthrough',\n",
    "            use_winsorizer=use_winsorizer_final\n",
    "        ),\n",
    "        'param_grid': lgbm_param_grid,\n",
    "        'n_iter': 200\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'pipeline': create_model_pipeline(\n",
    "            xgb.XGBClassifier(\n",
    "                scale_pos_weight=selected_weight,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1,\n",
    "                verbosity=0,\n",
    "                tree_method='hist'\n",
    "            ),\n",
    "            resampler=selected_resampler if selected_strategy == 'SMOTE' else 'passthrough',\n",
    "            use_winsorizer=use_winsorizer_final\n",
    "        ),\n",
    "        'param_grid': xgb_param_grid,\n",
    "        'n_iter': 200\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'pipeline': create_model_pipeline(\n",
    "            CatBoostClassifier(\n",
    "                scale_pos_weight=selected_weight,\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=0\n",
    "            ),\n",
    "            resampler=selected_resampler if selected_strategy == 'SMOTE' else 'passthrough',\n",
    "            use_winsorizer=use_winsorizer_final\n",
    "        ),\n",
    "        'param_grid': catboost_param_grid,\n",
    "        'n_iter': 150  # CatBoostÎäî ÎäêÎ¶¨ÎØÄÎ°ú 150\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'pipeline': create_model_pipeline(\n",
    "            LogisticRegression(\n",
    "                class_weight='balanced' if selected_strategy == 'Class Weight' else None,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            resampler=selected_resampler if selected_strategy == 'SMOTE' else 'passthrough',\n",
    "            use_winsorizer=use_winsorizer_final\n",
    "        ),\n",
    "        'param_grid': lr_param_grid,\n",
    "        'n_iter': 50\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'pipeline': create_model_pipeline(\n",
    "            RandomForestClassifier(\n",
    "                class_weight='balanced' if selected_strategy == 'Class Weight' else None,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            resampler=selected_resampler if selected_strategy == 'SMOTE' else 'passthrough',\n",
    "            use_winsorizer=use_winsorizer_final\n",
    "        ),\n",
    "        'param_grid': rf_param_grid,\n",
    "        'n_iter': 100\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Î™®Îç∏ Pipeline ÏÉùÏÑ± ÏôÑÎ£å\")\n",
    "print(f\"   - Ï†ÑÏ≤¥ Î™®Îç∏ Ïàò: {len(models_to_tune)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 RandomizedSearchCV Ïã§Ìñâ (‚≠ê n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ AutoML ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù ÏãúÏûë (n_iter=200)\")\n",
    "print(\"=\"*70)\n",
    "print(\"‚ö†Ô∏è  Train Set + 5-Fold CVÎßå ÏÇ¨Ïö© (Validation/Test ÎØ∏ÏÇ¨Ïö©)\")\n",
    "print(\"‚ö†Ô∏è  Raw Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïö© (Ï†ÑÏ≤òÎ¶¨Îäî Pipeline ÎÇ¥Î∂ÄÏóêÏÑú)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "search_results = {}\n",
    "best_models = {}\n",
    "\n",
    "for model_name, config in models_to_tune.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìä {model_name} ÌäúÎãù Ï§ë... (n_iter={config['n_iter']})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # RandomizedSearchCV\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=config['pipeline'],\n",
    "        param_distributions=config['param_grid'],\n",
    "        n_iter=config['n_iter'],\n",
    "        scoring=pr_auc_scorer,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=2,  # ‚≠ê ÏßÑÌñâ ÏÉÅÌô© ÌëúÏãú\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    # ‚≠ê Raw Îç∞Ïù¥ÌÑ∞Î°ú ÌïôÏäµ\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    # Í≤∞Í≥º Ï†ÄÏû•\n",
    "    search_results[model_name] = search\n",
    "    best_models[model_name] = search.best_estimator_\n",
    "    \n",
    "    print(f\"\\n‚úÖ {model_name} ÏôÑÎ£å\")\n",
    "    print(f\"   - Best CV PR-AUC: {search.best_score_:.4f}\")\n",
    "    print(f\"   - Best Params: {search.best_params_}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ Î™®Îì† Î™®Îç∏ ÌäúÎãù ÏôÑÎ£å!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Í≤∞Í≥º Î∂ÑÏÑù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î™®Îç∏Î≥Ñ ÏµúÍ≥† ÏÑ±Îä•\n",
    "model_best_scores = {name: search.best_score_ for name, search in search_results.items()}\n",
    "\n",
    "# Ï†ïÎ†¨\n",
    "sorted_models = sorted(model_best_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"üèÜ Î™®Îç∏Î≥Ñ ÏµúÍ≥† CV ÏÑ±Îä• (Train Set 5-Fold)\")\n",
    "print(\"=\"*70)\n",
    "for rank, (name, score) in enumerate(sorted_models, 1):\n",
    "    print(f\"{rank}. {name:20s} | PR-AUC: {score:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≥ºÏ†ÅÌï© Ï≤¥ÌÅ¨\n",
    "print(\"\\nüìä Í≥ºÏ†ÅÌï© Ï≤¥ÌÅ¨ (Train Score - CV Score)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, search in search_results.items():\n",
    "    train_score = search.cv_results_['mean_train_score'][search.best_index_]\n",
    "    cv_score = search.best_score_\n",
    "    gap = train_score - cv_score\n",
    "    \n",
    "    status = \"‚ö†Ô∏è Í≥ºÏ†ÅÌï© Ïö∞Î†§\" if gap > 0.1 else \"‚úÖ Ï†ïÏÉÅ\"\n",
    "    \n",
    "    print(f\"{model_name:20s} | Train: {train_score:.4f} | CV: {cv_score:.4f} | \"\n",
    "          f\"Gap: {gap:.4f} | {status}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}