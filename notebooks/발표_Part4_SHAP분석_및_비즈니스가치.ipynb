{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: SHAP ë¶„ì„ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ í‰ê°€\n",
    "\n",
    "## ğŸ¯ ëª©í‘œ\n",
    "\n",
    "Part 3 v3ì—ì„œ ì„ ì •ëœ ìµœì¢… ëª¨ë¸ì˜ ì˜ˆì¸¡ ê·¼ê±°ë¥¼ **SHAP (SHapley Additive exPlanations)**ìœ¼ë¡œ í•´ì„í•˜ê³ , ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì— í™œìš© ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ì„ í–‰ ì¡°ê±´\n",
    "\n",
    "### Part 3 v3 ì¶œë ¥ íŒŒì¼\n",
    "\n",
    "- `ë°œí‘œ_Part3_v3_ìµœì¢…ëª¨ë¸.pkl`\n",
    "- `ë°œí‘œ_Part3_v3_ì„ê³„ê°’.pkl`\n",
    "- `ë°œí‘œ_Part3_v3_ê²°ê³¼.pkl`\n",
    "- `domain_based_features_ì™„ì „íŒ.csv`\n",
    "\n",
    "### ë°ì´í„° ê·œëª¨\n",
    "\n",
    "- **ê¸°ì—… ìˆ˜**: 50,105ê°œ\n",
    "- **Feature ìˆ˜**: 27ê°œ (Part 2ì—ì„œ ì„ íƒëœ ë„ë©”ì¸ ê¸°ë°˜ íŠ¹ì„±)\n",
    "- **ë¶€ë„ìœ¨**: ~1.5%\n",
    "- **Train/Val/Test Split**: 60% / 20% / 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 0: í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "import platform\n",
    "if platform.system() == 'Darwin':\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "else:\n",
    "    plt.rc('font', family='NanumGothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "# ì‹œê°í™” ìŠ¤íƒ€ì¼\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ\")\n",
    "print(f\"   - SHAP ë²„ì „: {shap.__version__}\")\n",
    "print(f\"   - Python í”Œë«í¼: {platform.system()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 v3 ì¶œë ¥ ë¡œë“œ\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "\n",
    "try:\n",
    "    final_model = joblib.load(os.path.join(PROCESSED_DIR, 'ë°œí‘œ_Part3_v3_ìµœì¢…ëª¨ë¸.pkl'))\n",
    "    thresholds = joblib.load(os.path.join(PROCESSED_DIR, 'ë°œí‘œ_Part3_v3_ì„ê³„ê°’.pkl'))\n",
    "    results = joblib.load(os.path.join(PROCESSED_DIR, 'ë°œí‘œ_Part3_v3_ê²°ê³¼.pkl'))\n",
    "    \n",
    "    print(\"âœ… Part 3 v3 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "    print(f\"   - ìµœì¢… ëª¨ë¸: {results['model_name']}\")\n",
    "    print(f\"   - Test PR-AUC: {results['test_pr_auc']:.4f}\")\n",
    "    print(f\"   - Test Recall: {results['test_recall']:.2%}\")\n",
    "    print(f\"   - Test F2-Score: {results['test_f2']:.4f}\")\n",
    "    print(f\"\\nâœ… ì„ê³„ê°’ ë¡œë“œ ì™„ë£Œ\")\n",
    "    print(f\"   - ì„ íƒëœ ì„ê³„ê°’: {thresholds['selected']:.4f}\")\n",
    "    print(f\"   - Red ì„ê³„ê°’: {thresholds['red']:.4f}\")\n",
    "    print(f\"   - Yellow ì„ê³„ê°’: {thresholds['yellow']:.4f}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: Part 3 v3 ì¶œë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"   - {e}\")\n",
    "    print(f\"\\në¨¼ì € 'ë°œí‘œ_Part3_v3_ì™„ì „íŒ.ipynb'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature ë°ì´í„° ë¡œë“œ\n",
    "FEATURES_PATH = '../data/features/domain_based_features_ì™„ì „íŒ.csv'\n",
    "\n",
    "try:\n",
    "    features_df = pd.read_csv(FEATURES_PATH, encoding='utf-8')\n",
    "    print(f\"âœ… Feature ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "    print(f\"   - ë°ì´í„° í¬ê¸°: {features_df.shape}\")\n",
    "    print(f\"   - ê¸°ì—… ìˆ˜: {len(features_df):,}ê°œ\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: {FEATURES_PATH} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"\\në¨¼ì € 'ë°œí‘œ_Part2_íŠ¹ì„±ì„ íƒ.ipynb'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    raise\n",
    "\n",
    "# íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "TARGET_COL = 'ëª¨í˜•ê°œë°œìš©Performance(í–¥í›„1ë…„ë‚´ë¶€ë„ì—¬ë¶€)'\n",
    "X = features_df.drop(columns=[TARGET_COL])\n",
    "y = features_df[TARGET_COL]\n",
    "\n",
    "print(f\"\\nâœ… íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬ ì™„ë£Œ\")\n",
    "print(f\"   - Feature ìˆ˜: {X.shape[1]}ê°œ\")\n",
    "print(f\"   - ë¶€ë„ ê¸°ì—…: {y.sum():,}ê°œ ({y.mean():.2%})\")\n",
    "print(f\"   - ì •ìƒ ê¸°ì—…: {(~y.astype(bool)).sum():,}ê°œ ({(~y.astype(bool)).mean():.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë™ì¼í•œ 3-Way Split (Part 3ì™€ ë™ì¼í•œ random_state ì‚¬ìš©)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Train/Temp Split (80/20)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Train/Val Split (60/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ (Part 3ì™€ ë™ì¼)\")\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  - í¬ê¸°: {len(X_train):,}ê°œ\")\n",
    "print(f\"  - ë¶€ë„ìœ¨: {y_train.mean():.2%}\")\n",
    "print(f\"\\nValidation Set:\")\n",
    "print(f\"  - í¬ê¸°: {len(X_val):,}ê°œ\")\n",
    "print(f\"  - ë¶€ë„ìœ¨: {y_val.mean():.2%}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  - í¬ê¸°: {len(X_test):,}ê°œ\")\n",
    "print(f\"  - ë¶€ë„ìœ¨: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 1: SHAP TreeExplainer ì´ˆê¸°í™”\n",
    "\n",
    "### SHAPë€?\n",
    "\n",
    "- **Shapley Value** ê¸°ë°˜ ëª¨ë¸ í•´ì„ ë°©ë²• (ê²Œì„ ì´ë¡ ì—ì„œ ìœ ë˜)\n",
    "- ê° Featureê°€ **ê°œë³„ ì˜ˆì¸¡ì— ê¸°ì—¬í•œ ì •ë„**ë¥¼ ì •ëŸ‰í™”\n",
    "- **ì–‘ìˆ˜**: ë¶€ë„ ìœ„í—˜ ì¦ê°€ / **ìŒìˆ˜**: ë¶€ë„ ìœ„í—˜ ê°ì†Œ\n",
    "- **ê³µì •í•œ ë¶„ë°°**: ëª¨ë“  Featureì˜ SHAP ê°’ í•© = ì˜ˆì¸¡ê°’ - ê¸°ì¤€ê°’\n",
    "\n",
    "### TreeExplainer\n",
    "\n",
    "- íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ (XGBoost, LightGBM, CatBoost) ì „ìš©\n",
    "- ì •í™•í•˜ê³  ë¹ ë¥¸ SHAP ê°’ ê³„ì‚°\n",
    "- KernelExplainerë³´ë‹¤ ìˆ˜ë°± ë°° ë¹ ë¦„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TreeExplainer ì´ˆê¸°í™”\n",
    "print(\"SHAP TreeExplainer ì´ˆê¸°í™” ì¤‘...\")\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ì—ì„œ classifier ì¶”ì¶œ\n",
    "classifier = final_model.named_steps['classifier']\n",
    "print(f\"âœ… ë¶„ë¥˜ê¸° íƒ€ì…: {type(classifier).__name__}\")\n",
    "\n",
    "# TreeExplainer ìƒì„±\n",
    "explainer = shap.TreeExplainer(classifier)\n",
    "print(f\"âœ… TreeExplainer ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"   - ê¸°ì¤€ê°’ (Expected Value): {explainer.expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ëœ ë°ì´í„° ì¤€ë¹„\n",
    "print(\"ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ì˜ ì „ì²˜ë¦¬ ë‹¨ê³„ë§Œ ì ìš© (classifier ì œì™¸)\n",
    "preprocessor = final_model[:-1]\n",
    "X_train_preprocessed = preprocessor.transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "print(f\"   - Train Shape: {X_train_preprocessed.shape}\")\n",
    "print(f\"   - Test Shape: {X_test_preprocessed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP values ê³„ì‚° (Test Set)\n",
    "print(\"SHAP values ê³„ì‚° ì¤‘... (ìˆ˜ ë¶„ ì†Œìš” ê°€ëŠ¥)\")\n",
    "\n",
    "shap_values = explainer.shap_values(X_test_preprocessed)\n",
    "\n",
    "# ì´ì§„ ë¶„ë¥˜ ì‹œ shap_valuesê°€ [class0, class1] í˜•íƒœë©´ class1ë§Œ ì‚¬ìš©\n",
    "if isinstance(shap_values, list):\n",
    "    print(f\"   - SHAP valuesëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœ (í´ë˜ìŠ¤ë³„ ë¶„ë¦¬)\")\n",
    "    print(f\"   - Class 0 shape: {shap_values[0].shape}\")\n",
    "    print(f\"   - Class 1 shape: {shap_values[1].shape}\")\n",
    "    shap_values = shap_values[1]  # ë¶€ë„(1) í´ë˜ìŠ¤\n",
    "    print(f\"   - ë¶€ë„ í´ë˜ìŠ¤(1) SHAP values ì„ íƒ\")\n",
    "\n",
    "print(f\"\\nâœ… SHAP Values ê³„ì‚° ì™„ë£Œ\")\n",
    "print(f\"   - Shape: {shap_values.shape}\")\n",
    "print(f\"   - ìƒ˜í”Œ ìˆ˜: {shap_values.shape[0]:,}ê°œ\")\n",
    "print(f\"   - Feature ìˆ˜: {shap_values.shape[1]}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 2: Global Feature Importance (Summary Plot)\n",
    "\n",
    "ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” Featureë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•´ì„ ê°€ì´ë“œ\n",
    "\n",
    "- **Yì¶•**: Feature (ì¤‘ìš”ë„ ìˆœì„œ, ìœ„ë¡œ ê°ˆìˆ˜ë¡ ì¤‘ìš”)\n",
    "- **Xì¶•**: SHAP Value (ì–‘ìˆ˜ = ë¶€ë„ ìœ„í—˜â†‘, ìŒìˆ˜ = ë¶€ë„ ìœ„í—˜â†“)\n",
    "- **ìƒ‰ìƒ**: Feature ê°’ (ë¹¨ê°• = ë†’ìŒ, íŒŒë‘ = ë‚®ìŒ)\n",
    "- **ì ì˜ ë¶„í¬**: ë„“ê²Œ í¼ì§ˆìˆ˜ë¡ ë‹¤ì–‘í•œ ì˜í–¥ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Plot (Beeswarm)\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(\n",
    "    shap_values, \n",
    "    X_test_preprocessed, \n",
    "    feature_names=X.columns.tolist(),\n",
    "    show=False,\n",
    "    max_display=20\n",
    ")\n",
    "plt.title('SHAP Summary Plot: Global Feature Importance', fontsize=16, pad=20, weight='bold')\n",
    "plt.xlabel('SHAP Value (ë¶€ë„ ìœ„í—˜ì— ëŒ€í•œ ì˜í–¥)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/ë°œí‘œ_Part4_SHAP_Summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Summary Plot ì €ì¥ ì™„ë£Œ: ë°œí‘œ_Part4_SHAP_Summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì£¼ìš” íŒ¨í„´ í•´ì„\n",
    "\n",
    "1. **ìƒë‹¨ Featureë“¤**: ëª¨ë¸ì˜ í•µì‹¬ ì˜ì‚¬ê²°ì • ìš”ì†Œ\n",
    "2. **ë¹¨ê°„ ì ì´ ì˜¤ë¥¸ìª½**: í•´ë‹¹ Feature ê°’ì´ ë†’ì„ìˆ˜ë¡ ë¶€ë„ ìœ„í—˜ ì¦ê°€\n",
    "3. **íŒŒë€ ì ì´ ì™¼ìª½**: í•´ë‹¹ Feature ê°’ì´ ë‚®ì„ìˆ˜ë¡ ë¶€ë„ ìœ„í—˜ ê°ì†Œ\n",
    "4. **ìˆ˜í‰ ë¶„í¬**: Featureì™€ ë¶€ë„ ìœ„í—˜ì˜ ë¹„ì„ í˜• ê´€ê³„ ì‹œì‚¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 3: Top 10 Feature ìƒì„¸ ë¶„ì„\n",
    "\n",
    "ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” 10ê°œ Featureì˜ ì¬ë¬´ì  ì˜ë¯¸ë¥¼ í•´ì„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Feature ì¶”ì¶œ\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "top10_idx = np.argsort(feature_importance)[-10:][::-1]\n",
    "top10_features = X.columns[top10_idx]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Top 10 ì¤‘ìš” Feature (Mean |SHAP|)\")\n",
    "print(\"=\"*80)\n",
    "for i, feat in enumerate(top10_features, 1):\n",
    "    importance = feature_importance[top10_idx[i-1]]\n",
    "    print(f\"{i:2d}. {feat:40s} {importance:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "shap.summary_plot(\n",
    "    shap_values, \n",
    "    X_test_preprocessed, \n",
    "    feature_names=X.columns.tolist(),\n",
    "    plot_type='bar', \n",
    "    show=False, \n",
    "    max_display=10\n",
    ")\n",
    "plt.title('Top 10 Feature Importance (Mean |SHAP|)', fontsize=16, pad=20, weight='bold')\n",
    "plt.xlabel('í‰ê·  ì ˆëŒ€ SHAP ê°’', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/ë°œí‘œ_Part4_Top10_Features.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Top 10 Bar Plot ì €ì¥ ì™„ë£Œ: ë°œí‘œ_Part4_Top10_Features.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¬ë¬´ì  ì˜ë¯¸ í•´ì„ (Feature ì´ë¦„ ê¸°ë°˜ ìë™ ìƒì„±)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Top 10 Feature ì¬ë¬´ì  ì˜ë¯¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Feature í•´ì„ ë§¤í•‘ (ì‹¤ì œ Feature ì´ë¦„ì— ë§ê²Œ ì¡°ì • í•„ìš”)\n",
    "feature_interpretation = {\n",
    "    'ìë³¸ì ì‹ë„': ('ìë³¸ ëŒ€ë¹„ ëˆ„ì  ì†ì‹¤', 'ë†’ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ìë³¸ ê¸°ë°˜ ë¶•ê´´)'),\n",
    "    'ì´ìë³´ìƒë°°ìœ¨': ('ì˜ì—…ì´ìµìœ¼ë¡œ ì´ì ì»¤ë²„ ëŠ¥ë ¥', 'ë‚®ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ì´ì ì§€ê¸‰ ë¶ˆê°€)'),\n",
    "    'ìœ ë™ë¹„ìœ¨': ('ë‹¨ê¸° ë¶€ì±„ ìƒí™˜ ëŠ¥ë ¥', 'ë‚®ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ìœ ë™ì„± ìœ„ê¸°)'),\n",
    "    'ë‹¹ì¢Œë¹„ìœ¨': ('ì¦‰ê° í˜„ê¸ˆí™” ê°€ëŠ¥ ìì‚° ë¹„ìœ¨', 'ë‚®ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ê¸´ê¸‰ ìœ ë™ì„± ë¶€ì¡±)'),\n",
    "    'ë¶€ì±„ë¹„ìœ¨': ('ìë³¸ ëŒ€ë¹„ ë¶€ì±„ ê·œëª¨', 'ë†’ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ê³¼ë„í•œ ë ˆë²„ë¦¬ì§€)'),\n",
    "    'ì´ìì‚°ì´ìµë¥ (ROA)': ('ìì‚° íš¨ìœ¨ì„±', 'ë‚®ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ìˆ˜ìµì„± ì•…í™”)'),\n",
    "    'ë§¤ì¶œì±„ê¶ŒíšŒì „ìœ¨': ('ë§¤ì¶œì±„ê¶Œ íšŒìˆ˜ ì†ë„', 'ë‚®ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (í˜„ê¸ˆ íšŒìˆ˜ ì§€ì—°)'),\n",
    "    'ì¬ê³ ìì‚°íšŒì „ìœ¨': ('ì¬ê³  íŒë§¤ íš¨ìœ¨', 'ë‚®ì„ìˆ˜ë¡ ìœ„í—˜â†‘ (ì¬ê³  ì ì²´)'),\n",
    "}\n",
    "\n",
    "for i, feat in enumerate(top10_features, 1):\n",
    "    if feat in feature_interpretation:\n",
    "        meaning, risk = feature_interpretation[feat]\n",
    "        print(f\"{i:2d}. {feat}\")\n",
    "        print(f\"    ì˜ë¯¸: {meaning}\")\n",
    "        print(f\"    ìœ„í—˜: {risk}\")\n",
    "    else:\n",
    "        print(f\"{i:2d}. {feat}\")\n",
    "        print(f\"    (Feature ì´ë¦„ ê¸°ë°˜ í•´ì„ ì¶”ê°€ í•„ìš”)\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 4: SHAP Dependence Plot (ê°œë³„ Feature ë¶„ì„)\n",
    "\n",
    "Top 3 Featureì˜ ë¹„ì„ í˜• ê´€ê³„ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•´ì„ ê°€ì´ë“œ\n",
    "\n",
    "- **Xì¶•**: Feature ê°’\n",
    "- **Yì¶•**: SHAP Value (ë¶€ë„ ìœ„í—˜ì— ëŒ€í•œ ê¸°ì—¬ë„)\n",
    "- **ìƒ‰ìƒ**: ìƒí˜¸ì‘ìš© Feature (ìë™ ì„ íƒ)\n",
    "- **íŒ¨í„´**: ë¹„ì„ í˜• ê´€ê³„, ì„ê³„ê°’ íš¨ê³¼, ìƒí˜¸ì‘ìš© í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 Featureì— ëŒ€í•œ Dependence Plot\n",
    "top3_features = top10_features[:3]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "for i, feat in enumerate(top3_features):\n",
    "    feat_idx = list(X.columns).index(feat)\n",
    "    shap.dependence_plot(\n",
    "        feat_idx, \n",
    "        shap_values, \n",
    "        X_test_preprocessed,\n",
    "        feature_names=X.columns.tolist(), \n",
    "        ax=axes[i], \n",
    "        show=False\n",
    "    )\n",
    "    axes[i].set_title(f'{feat}', fontsize=14, weight='bold')\n",
    "    axes[i].set_xlabel('Feature ê°’', fontsize=11)\n",
    "    axes[i].set_ylabel('SHAP Value', fontsize=11)\n",
    "\n",
    "plt.suptitle('Top 3 Feature Dependence Plot: ë¹„ì„ í˜• ê´€ê³„ ë¶„ì„', \n",
    "             fontsize=16, weight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/ë°œí‘œ_Part4_Dependence_Plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Dependence Plot ì €ì¥ ì™„ë£Œ: ë°œí‘œ_Part4_Dependence_Plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì£¼ìš” íŒ¨í„´\n",
    "\n",
    "1. **ì„ í˜• vs ë¹„ì„ í˜•**: ì§ì„ /ê³¡ì„  íŒ¨í„´ìœ¼ë¡œ ê´€ê³„ ìœ í˜• íŒŒì•…\n",
    "2. **ì„ê³„ê°’ íš¨ê³¼**: íŠ¹ì • ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ê¸‰ê²©í•œ ë³€í™”\n",
    "3. **ìƒí˜¸ì‘ìš©**: ìƒ‰ìƒ ê·¸ë¼ë°ì´ì…˜ì´ ëšœë ·í•˜ë©´ ë‹¤ë¥¸ Featureì™€ì˜ ìƒí˜¸ì‘ìš© ê°•í•¨\n",
    "4. **ì´ìƒì¹˜**: ê·¹ë‹¨ê°’ì—ì„œì˜ SHAP ê°’ ë³€í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 5: ê°œë³„ ê¸°ì—… ì‚¬ë¡€ ë¶„ì„ (Waterfall Plot)\n",
    "\n",
    "ë¶€ë„ ê¸°ì—… 1ê°œ, ì •ìƒ ê¸°ì—… 1ê°œì˜ ì˜ˆì¸¡ ê·¼ê±°ë¥¼ ìƒì„¸íˆ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Waterfall Plot í•´ì„\n",
    "\n",
    "- **Base Value**: ì „ì²´ í‰ê·  ì˜ˆì¸¡ê°’ (ëª¨ë“  ê¸°ì—…ì˜ í‰ê·  ë¶€ë„ í™•ë¥ )\n",
    "- **í™”ì‚´í‘œ**: ê° Featureê°€ ì˜ˆì¸¡ê°’ì„ ì¦ê°€/ê°ì†Œì‹œí‚¤ëŠ” ì •ë„\n",
    "- **ë¹¨ê°„ìƒ‰**: ë¶€ë„ ìœ„í—˜ ì¦ê°€\n",
    "- **íŒŒë€ìƒ‰**: ë¶€ë„ ìœ„í—˜ ê°ì†Œ\n",
    "- **ìµœì¢…ê°’ f(x)**: í•´ë‹¹ ê¸°ì—…ì˜ ì˜ˆì¸¡ í™•ë¥ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°\n",
    "y_test_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ë¶€ë„ ê¸°ì—… ì¤‘ í™•ë¥ ì´ ë†’ì€ ì‚¬ë¡€\n",
    "bankrupt_idx = np.where(y_test == 1)[0]\n",
    "high_risk_idx = bankrupt_idx[np.argsort(y_test_prob[bankrupt_idx])[-1]]\n",
    "\n",
    "# ì •ìƒ ê¸°ì—… ì¤‘ í™•ë¥ ì´ ë‚®ì€ ì‚¬ë¡€\n",
    "normal_idx = np.where(y_test == 0)[0]\n",
    "low_risk_idx = normal_idx[np.argsort(y_test_prob[normal_idx])[0]]\n",
    "\n",
    "print(f\"ì„ íƒëœ ì‚¬ë¡€:\")\n",
    "print(f\"  - ë¶€ë„ ê¸°ì—… (ê³ ìœ„í—˜): ì¸ë±ìŠ¤ {high_risk_idx}, ì˜ˆì¸¡ í™•ë¥  {y_test_prob[high_risk_idx]:.2%}\")\n",
    "print(f\"  - ì •ìƒ ê¸°ì—… (ì €ìœ„í—˜): ì¸ë±ìŠ¤ {low_risk_idx}, ì˜ˆì¸¡ í™•ë¥  {y_test_prob[low_risk_idx]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected Value ì²˜ë¦¬\n",
    "if isinstance(explainer.expected_value, (list, np.ndarray)):\n",
    "    expected_value = explainer.expected_value[1]  # ë¶€ë„ í´ë˜ìŠ¤\n",
    "else:\n",
    "    expected_value = explainer.expected_value\n",
    "\n",
    "# Waterfall Plot: ë¶€ë„ ê¸°ì—…\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.waterfall_plot(\n",
    "    shap.Explanation(\n",
    "        values=shap_values[high_risk_idx],\n",
    "        base_values=expected_value,\n",
    "        data=X_test_preprocessed[high_risk_idx],\n",
    "        feature_names=X.columns.tolist()\n",
    "    ),\n",
    "    show=False,\n",
    "    max_display=15\n",
    ")\n",
    "plt.title(f'ë¶€ë„ ê¸°ì—… ì˜ˆì¸¡ ê·¼ê±° (ì‹¤ì œ: ë¶€ë„, ì˜ˆì¸¡ í™•ë¥ : {y_test_prob[high_risk_idx]:.2%})', \n",
    "          fontsize=14, weight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/ë°œí‘œ_Part4_Waterfall_ë¶€ë„ê¸°ì—….png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… ë¶€ë„ ê¸°ì—… Waterfall Plot ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall Plot: ì •ìƒ ê¸°ì—…\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.waterfall_plot(\n",
    "    shap.Explanation(\n",
    "        values=shap_values[low_risk_idx],\n",
    "        base_values=expected_value,\n",
    "        data=X_test_preprocessed[low_risk_idx],\n",
    "        feature_names=X.columns.tolist()\n",
    "    ),\n",
    "    show=False,\n",
    "    max_display=15\n",
    ")\n",
    "plt.title(f'ì •ìƒ ê¸°ì—… ì˜ˆì¸¡ ê·¼ê±° (ì‹¤ì œ: ì •ìƒ, ì˜ˆì¸¡ í™•ë¥ : {y_test_prob[low_risk_idx]:.2%})', \n",
    "          fontsize=14, weight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/ë°œí‘œ_Part4_Waterfall_ì •ìƒê¸°ì—….png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… ì •ìƒ ê¸°ì—… Waterfall Plot ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‚¬ë¡€ í•´ì„\n",
    "\n",
    "**ë¶€ë„ ê¸°ì—…**\n",
    "- Base Valueì—ì„œ ì‹œì‘í•˜ì—¬ ìœ„í—˜ ìš”ì¸(ë¹¨ê°„ìƒ‰)ì´ ëˆ„ì \n",
    "- ì£¼ìš” ìœ„í—˜ Featureë“¤ì´ ì˜ˆì¸¡ê°’ì„ ëŒì–´ì˜¬ë¦¼\n",
    "- ì¼ë¶€ ì–‘í˜¸í•œ ì§€í‘œ(íŒŒë€ìƒ‰)ë„ ìˆì§€ë§Œ ìœ„í—˜ ìš”ì¸ì´ ì••ë„\n",
    "\n",
    "**ì •ìƒ ê¸°ì—…**\n",
    "- ê±´ì „í•œ ì¬ë¬´ ì§€í‘œ(íŒŒë€ìƒ‰)ê°€ ì˜ˆì¸¡ê°’ì„ ë‚®ì¶¤\n",
    "- ìœ„í—˜ ìš”ì¸ì´ ìˆì–´ë„ ì „ì²´ì ìœ¼ë¡œ ì•ˆì •ì \n",
    "- ìµœì¢… ì˜ˆì¸¡ í™•ë¥ ì´ ë‚®ê²Œ ìœ ì§€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 6: Force Plot (Interactive Visualization)\n",
    "\n",
    "ì—¬ëŸ¬ ìƒ˜í”Œì˜ ì˜ˆì¸¡ ê·¼ê±°ë¥¼ í•œ ëˆˆì— ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ì˜**: Force Plotì€ Jupyter ë…¸íŠ¸ë¶ì—ì„œ ì¸í„°ë™í‹°ë¸Œí•˜ê²Œ í‘œì‹œë©ë‹ˆë‹¤. HTML íŒŒì¼ë¡œ ì €ì¥ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶€ë„ ê¸°ì—… ìƒìœ„ 20ê°œ\n",
    "top20_bankrupt = bankrupt_idx[np.argsort(y_test_prob[bankrupt_idx])[-20:]]\n",
    "\n",
    "print(f\"ë¶€ë„ ê¸°ì—… ìƒìœ„ 20ê°œ ì„ íƒ ì™„ë£Œ\")\n",
    "print(f\"ì˜ˆì¸¡ í™•ë¥  ë²”ìœ„: {y_test_prob[top20_bankrupt].min():.2%} ~ {y_test_prob[top20_bankrupt].max():.2%}\")\n",
    "\n",
    "# Force Plot\n",
    "shap.initjs()\n",
    "force_plot = shap.force_plot(\n",
    "    expected_value,\n",
    "    shap_values[top20_bankrupt],\n",
    "    X_test_preprocessed[top20_bankrupt],\n",
    "    feature_names=X.columns.tolist()\n",
    ")\n",
    "\n",
    "# ë…¸íŠ¸ë¶ì— í‘œì‹œ\n",
    "display(force_plot)\n",
    "\n",
    "print(\"\\nâœ… Force Plot ìƒì„± ì™„ë£Œ (ìœ„ ì¸í„°ë™í‹°ë¸Œ í”Œë¡¯ ì°¸ì¡°)\")\n",
    "print(\"   - ë¹¨ê°„ìƒ‰: ë¶€ë„ ìœ„í—˜ ì¦ê°€ Feature\")\n",
    "print(\"   - íŒŒë€ìƒ‰: ë¶€ë„ ìœ„í—˜ ê°ì†Œ Feature\")\n",
    "print(\"   - ê° í–‰ì€ í•˜ë‚˜ì˜ ê¸°ì—…ì„ ë‚˜íƒ€ëƒ„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ì„ íƒì‚¬í•­) HTMLë¡œ ì €ì¥\n",
    "try:\n",
    "    shap.save_html(\n",
    "        '../data/processed/ë°œí‘œ_Part4_Force_Plot.html',\n",
    "        force_plot\n",
    "    )\n",
    "    print(\"âœ… Force Plot HTML ì €ì¥ ì™„ë£Œ: ë°œí‘œ_Part4_Force_Plot.html\")\n",
    "except Exception as e:\n",
    "    print(f\"HTML ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ë…¸íŠ¸ë¶ì—ì„œ ì¸í„°ë™í‹°ë¸Œ í”Œë¡¯ì„ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 7: Traffic Light êµ¬ê°„ë³„ SHAP íŒ¨í„´ ë¶„ì„\n",
    "\n",
    "ê° ìœ„í—˜ êµ¬ê°„(Red/Yellow/Green)ì—ì„œ ì–´ë–¤ Featureê°€ ì£¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Traffic Light ì‹œìŠ¤í…œ\n",
    "\n",
    "- **Red (ê³ ìœ„í—˜)**: ì˜ˆì¸¡ í™•ë¥  â‰¥ Red ì„ê³„ê°’\n",
    "- **Yellow (ì¤‘ìœ„í—˜)**: Yellow ì„ê³„ê°’ â‰¤ ì˜ˆì¸¡ í™•ë¥  < Red ì„ê³„ê°’\n",
    "- **Green (ì €ìœ„í—˜)**: ì˜ˆì¸¡ í™•ë¥  < Yellow ì„ê³„ê°’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ í™•ë¥ ë¡œ êµ¬ê°„ ë¶„ë¥˜\n",
    "red_threshold = thresholds['red']\n",
    "yellow_threshold = thresholds['yellow']\n",
    "\n",
    "red_mask = y_test_prob >= red_threshold\n",
    "yellow_mask = (y_test_prob >= yellow_threshold) & (y_test_prob < red_threshold)\n",
    "green_mask = y_test_prob < yellow_threshold\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Traffic Light êµ¬ê°„ë³„ ë¶„í¬\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Red (ê³ ìœ„í—˜):    {red_mask.sum():5d}ê°œ ({red_mask.mean():6.2%}) - ì„ê³„ê°’: {red_threshold:.4f}\")\n",
    "print(f\"Yellow (ì¤‘ìœ„í—˜): {yellow_mask.sum():5d}ê°œ ({yellow_mask.mean():6.2%}) - ì„ê³„ê°’: {yellow_threshold:.4f}\")\n",
    "print(f\"Green (ì €ìœ„í—˜):  {green_mask.sum():5d}ê°œ ({green_mask.mean():6.2%})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ê° êµ¬ê°„ì˜ ì‹¤ì œ ë¶€ë„ìœ¨\n",
    "print(\"\\nê° êµ¬ê°„ì˜ ì‹¤ì œ ë¶€ë„ìœ¨:\")\n",
    "if red_mask.sum() > 0:\n",
    "    print(f\"Red:    {y_test[red_mask].mean():.2%}\")\n",
    "if yellow_mask.sum() > 0:\n",
    "    print(f\"Yellow: {y_test[yellow_mask].mean():.2%}\")\n",
    "if green_mask.sum() > 0:\n",
    "    print(f\"Green:  {y_test[green_mask].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ê°„ë³„ í‰ê·  SHAP ê°’\n",
    "segments = {\n",
    "    'Red (ê³ ìœ„í—˜)': red_mask,\n",
    "    'Yellow (ì¤‘ìœ„í—˜)': yellow_mask,\n",
    "    'Green (ì €ìœ„í—˜)': green_mask\n",
    "}\n",
    "\n",
    "segment_shap_means = {}\n",
    "for seg_name, mask in segments.items():\n",
    "    if mask.sum() > 0:\n",
    "        segment_shap_means[seg_name] = np.abs(shap_values[mask]).mean(axis=0)\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df_segment = pd.DataFrame(segment_shap_means, index=X.columns).T\n",
    "\n",
    "# Top 10 Feature (ì „ì²´ í‰ê·  ê¸°ì¤€)\n",
    "top10_seg_features = df_segment.mean(axis=0).nlargest(10).index\n",
    "\n",
    "print(f\"\\nêµ¬ê°„ë³„ Top 10 Feature (ì „ì²´ í‰ê·  ê¸°ì¤€):\")\n",
    "for i, feat in enumerate(top10_seg_features, 1):\n",
    "    print(f\"{i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(14, 7))\n",
    "df_plot = df_segment[top10_seg_features].T\n",
    "ax = df_plot.plot(kind='bar', ax=plt.gca(), width=0.8)\n",
    "\n",
    "plt.title('Traffic Light êµ¬ê°„ë³„ Top 10 Feature Importance', fontsize=16, weight='bold', pad=20)\n",
    "plt.xlabel('Feature', fontsize=12)\n",
    "plt.ylabel('Mean |SHAP Value|', fontsize=12)\n",
    "plt.legend(title='ìœ„í—˜ êµ¬ê°„', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/ë°œí‘œ_Part4_Segment_SHAP.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… êµ¬ê°„ë³„ SHAP ë¶„ì„ ì €ì¥ ì™„ë£Œ: ë°œí‘œ_Part4_Segment_SHAP.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ê°„ë³„ ì°¨ì´ ë¶„ì„\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"êµ¬ê°„ë³„ Feature Importance ì°¨ì´\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'Red (ê³ ìœ„í—˜)' in df_segment.index and 'Green (ì €ìœ„í—˜)' in df_segment.index:\n",
    "    diff = df_segment.loc['Red (ê³ ìœ„í—˜)'] - df_segment.loc['Green (ì €ìœ„í—˜)']\n",
    "    top5_diff = diff.nlargest(5)\n",
    "    \n",
    "    print(\"\\nRed vs Green ì°¨ì´ê°€ í° Feature (Redì—ì„œ ë” ì¤‘ìš”):\")\n",
    "    for i, (feat, val) in enumerate(top5_diff.items(), 1):\n",
    "        print(f\"{i}. {feat:40s} +{val:.4f}\")\n",
    "    \n",
    "    bottom5_diff = diff.nsmallest(5)\n",
    "    print(\"\\nRed vs Green ì°¨ì´ê°€ í° Feature (Greenì—ì„œ ë” ì¤‘ìš”):\")\n",
    "    for i, (feat, val) in enumerate(bottom5_diff.items(), 1):\n",
    "        print(f\"{i}. {feat:40s} {val:.4f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "- **Red êµ¬ê°„**: êµ¬ì¡°ì  ë¬¸ì œ (ìë³¸ì ì‹, ì´ìë³´ìƒ ë“±) ì¤‘ìš”\n",
    "- **Yellow êµ¬ê°„**: ìœ ë™ì„± ê²½ê³  ì‹ í˜¸ (ìœ ë™ë¹„ìœ¨, ë§¤ì¶œì±„ê¶Œ íšŒì „ìœ¨ ë“±)\n",
    "- **Green êµ¬ê°„**: ì „ë°˜ì ìœ¼ë¡œ ê±´ì „í•œ ì¬ë¬´ ì§€í‘œ\n",
    "- **ì°¨ì´ ë¶„ì„**: ê° êµ¬ê°„ì„ êµ¬ë¶„í•˜ëŠ” í•µì‹¬ Feature íŒŒì•…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 8: Bootstrap ì‹ ë¢°êµ¬ê°„ ì¶”ê°€ â­\n",
    "\n",
    "SHAP Feature Importanceì˜ í†µê³„ì  ì•ˆì •ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Bootstrap ë°©ë²•ë¡ \n",
    "\n",
    "- ë³µì› ì¶”ì¶œë¡œ 1,000ê°œ ìƒ˜í”Œ ìƒì„±\n",
    "- ê° ìƒ˜í”Œì—ì„œ Feature Importance ê³„ì‚°\n",
    "- 95% ì‹ ë¢°êµ¬ê°„ ì‚°ì¶œ\n",
    "- ì‹ ë¢°êµ¬ê°„ì´ ì¢ì„ìˆ˜ë¡ ì•ˆì •ì ì¸ Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap (1,000íšŒ)\n",
    "n_bootstrap = 1000\n",
    "bootstrap_importance = []\n",
    "\n",
    "print(f\"Bootstrap ì‹œì‘: {n_bootstrap}íšŒ ë°˜ë³µ\")\n",
    "print(\"ì§„í–‰ ìƒí™©:\")\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    # ë³µì› ì¶”ì¶œ\n",
    "    indices = resample(range(len(X_test)), n_samples=len(X_test), random_state=i)\n",
    "    shap_boot = shap_values[indices]\n",
    "    \n",
    "    # Feature Importance ê³„ì‚°\n",
    "    importance = np.abs(shap_boot).mean(axis=0)\n",
    "    bootstrap_importance.append(importance)\n",
    "    \n",
    "    # ì§„í–‰ ìƒí™© í‘œì‹œ\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"  {i + 1:4d}/{n_bootstrap} ì™„ë£Œ ({(i+1)/n_bootstrap*100:.0f}%)\")\n",
    "\n",
    "bootstrap_importance = np.array(bootstrap_importance)\n",
    "\n",
    "print(f\"\\nâœ… Bootstrap ì™„ë£Œ\")\n",
    "print(f\"   - Shape: {bootstrap_importance.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95% ì‹ ë¢°êµ¬ê°„\n",
    "lower = np.percentile(bootstrap_importance, 2.5, axis=0)\n",
    "upper = np.percentile(bootstrap_importance, 97.5, axis=0)\n",
    "mean_importance = bootstrap_importance.mean(axis=0)\n",
    "\n",
    "# Top 10 Feature CI\n",
    "top10_idx_boot = np.argsort(mean_importance)[-10:][::-1]\n",
    "top10_feat_boot = X.columns[top10_idx_boot]\n",
    "\n",
    "df_ci = pd.DataFrame({\n",
    "    'Feature': top10_feat_boot,\n",
    "    'Mean': mean_importance[top10_idx_boot],\n",
    "    'Lower': lower[top10_idx_boot],\n",
    "    'Upper': upper[top10_idx_boot],\n",
    "    'CI_Width': upper[top10_idx_boot] - lower[top10_idx_boot]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Top 10 Feature Importance with Bootstrap 95% CI\")\n",
    "print(\"=\"*100)\n",
    "print(df_ci.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "print(\"\\nì‹ ë¢°êµ¬ê°„ í­(CI_Width)ì´ ì‘ì„ìˆ˜ë¡ ì•ˆì •ì ì¸ Featureì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "y_pos = np.arange(len(df_ci))\n",
    "plt.barh(\n",
    "    y_pos, \n",
    "    df_ci['Mean'], \n",
    "    xerr=[df_ci['Mean'] - df_ci['Lower'], df_ci['Upper'] - df_ci['Mean']],\n",
    "    capsize=5, \n",
    "    alpha=0.7, \n",
    "    color='steelblue',\n",
    "    ecolor='darkred',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "plt.yticks(y_pos, df_ci['Feature'])\n",
    "plt.xlabel('Mean |SHAP Value| (95% CI)', fontsize=12, weight='bold')\n",
    "plt.title('Top 10 Feature Importance with Bootstrap Confidence Interval', \n",
    "          fontsize=16, weight='bold', pad=20)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/ë°œí‘œ_Part4_Bootstrap_CI.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Bootstrap CI í”Œë¡¯ ì €ì¥ ì™„ë£Œ: ë°œí‘œ_Part4_Bootstrap_CI.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í†µê³„ì  ì•ˆì •ì„± í‰ê°€\n",
    "\n",
    "- ì‹ ë¢°êµ¬ê°„ì´ ì¢ì€ Feature: ìƒ˜í”Œë§ì— ê´€ê³„ì—†ì´ ì¼ê´€ë˜ê²Œ ì¤‘ìš”\n",
    "- ì‹ ë¢°êµ¬ê°„ì´ ë„“ì€ Feature: ìƒ˜í”Œì— ë”°ë¼ ì¤‘ìš”ë„ê°€ ë³€ë™\n",
    "- ëª¨ë¸ ë°°í¬ ì‹œ ì•ˆì •ì ì¸ Featureë¥¼ ìš°ì„  ê³ ë ¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 9: ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì¢…í•©\n",
    "\n",
    "ì˜ì‚¬ê²°ì •ìë¥¼ ìœ„í•œ í•µì‹¬ ë©”ì‹œì§€ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ìš”ì•½ í…Œì´ë¸”\n",
    "summary = pd.DataFrame({\n",
    "    'í•­ëª©': [\n",
    "        'ëª¨ë¸',\n",
    "        'Test PR-AUC',\n",
    "        'Test Recall',\n",
    "        'Test F2-Score',\n",
    "        'ì„ íƒëœ ì„ê³„ê°’',\n",
    "        'Red êµ¬ê°„ ê¸°ì—… ìˆ˜',\n",
    "        'Yellow êµ¬ê°„ ê¸°ì—… ìˆ˜',\n",
    "        'Green êµ¬ê°„ ê¸°ì—… ìˆ˜',\n",
    "        'Top 1 Feature',\n",
    "        'Top 2 Feature',\n",
    "        'Top 3 Feature'\n",
    "    ],\n",
    "    'ê°’': [\n",
    "        results['model_name'],\n",
    "        f\"{results['test_pr_auc']:.4f}\",\n",
    "        f\"{results['test_recall']:.2%}\",\n",
    "        f\"{results['test_f2']:.4f}\",\n",
    "        f\"{thresholds['selected']:.4f}\",\n",
    "        f\"{red_mask.sum():,}ê°œ ({red_mask.mean():.2%})\",\n",
    "        f\"{yellow_mask.sum():,}ê°œ ({yellow_mask.mean():.2%})\",\n",
    "        f\"{green_mask.sum():,}ê°œ ({green_mask.mean():.2%})\",\n",
    "        top10_features[0],\n",
    "        top10_features[1],\n",
    "        top10_features[2]\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ ë° ìœ„í—˜ êµ¬ê°„ ë¶„í¬\")\n",
    "print(\"=\"*80)\n",
    "print(summary.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸\n",
    "top3_importance_sum = feature_importance[top10_idx[:3]].sum()\n",
    "total_importance = feature_importance.sum()\n",
    "top3_contribution = top3_importance_sum / total_importance * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. í•µì‹¬ ìœ„í—˜ ì§€í‘œ\")\n",
    "print(f\"   - Top 3 Featureê°€ ì „ì²´ ì˜ˆì¸¡ì˜ {top3_contribution:.1f}% ì„¤ëª…\")\n",
    "print(f\"   - 1ìˆœìœ„: {top3_features[0]}\")\n",
    "print(f\"   - 2ìˆœìœ„: {top3_features[1]}\")\n",
    "print(f\"   - 3ìˆœìœ„: {top3_features[2]}\")\n",
    "print(\"   âœ ì´ 3ê°œ ì§€í‘œë§Œ ì§‘ì¤‘ ëª¨ë‹ˆí„°ë§í•´ë„ ëŒ€ë¶€ë¶„ì˜ ë¶€ë„ ìœ„í—˜ íŒŒì•… ê°€ëŠ¥\")\n",
    "\n",
    "print(\"\\n2. ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ\")\n",
    "print(f\"   - Yellow êµ¬ê°„: {yellow_mask.sum():,}ê°œ ê¸°ì—… (ì§‘ì¤‘ ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ)\")\n",
    "print(f\"   - Red êµ¬ê°„: {red_mask.sum():,}ê°œ ê¸°ì—… (ì¦‰ê° ëŒ€ì‘ í•„ìš”)\")\n",
    "if yellow_mask.sum() > 0:\n",
    "    print(f\"   - Yellow êµ¬ê°„ ì‹¤ì œ ë¶€ë„ìœ¨: {y_test[yellow_mask].mean():.2%}\")\n",
    "if red_mask.sum() > 0:\n",
    "    print(f\"   - Red êµ¬ê°„ ì‹¤ì œ ë¶€ë„ìœ¨: {y_test[red_mask].mean():.2%}\")\n",
    "print(\"   âœ Yellow êµ¬ê°„ ê¸°ì—… ëŒ€ìƒ ì‚¬ì „ ê°œì…ìœ¼ë¡œ ë¶€ë„ ì˜ˆë°© ê°€ëŠ¥\")\n",
    "\n",
    "print(\"\\n3. í•´ì„ ê°€ëŠ¥ì„±\")\n",
    "print(\"   - SHAPìœ¼ë¡œ ê°œë³„ ê¸°ì—…ì˜ ë¶€ë„ ìœ„í—˜ ê·¼ê±° ëª…í™•íˆ ì œì‹œ\")\n",
    "print(\"   - ê¸ˆìœµê¸°ê´€: ëŒ€ì¶œ ì‹¬ì‚¬ ê·¼ê±° ë§ˆë ¨ (ì„¤ëª… ê°€ëŠ¥í•œ AI)\")\n",
    "print(\"   - íˆ¬ìì: í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê´€ë¦¬ (ìœ„í—˜ ìš”ì¸ ì‚¬ì „ íŒŒì•…)\")\n",
    "print(\"   - ê·œì œê¸°ê´€: ê³µì •ì„± ë° íˆ¬ëª…ì„± í™•ë³´ (ë¸”ë™ë°•ìŠ¤ í•´ì†Œ)\")\n",
    "print(\"   âœ ë‹¨ìˆœ ì ìˆ˜ê°€ ì•„ë‹Œ 'ì™œ ê·¸ëŸ°ì§€' ì„¤ëª… ê°€ëŠ¥\")\n",
    "\n",
    "print(\"\\n4. ì‹¤ë¬´ í™œìš© ë°©ì•ˆ\")\n",
    "print(\"   - ì‹ ê·œ ëŒ€ì¶œ ì‹¬ì‚¬: Red/Yellow ê¸°ì—… ê±°ì ˆ ë˜ëŠ” ê³ ê¸ˆë¦¬ ì ìš©\")\n",
    "print(\"   - ê¸°ì¡´ ì—¬ì‹  ê´€ë¦¬: Yellow â†’ Red ì´ë™ ê¸°ì—… ì¡°ê¸° ë°œê²¬\")\n",
    "print(\"   - ê²½ì˜ ì»¨ì„¤íŒ…: Waterfall Plotìœ¼ë¡œ ê°œì„  í¬ì¸íŠ¸ ì œì‹œ\")\n",
    "print(\"   - ì—…ì¢…ë³„ ì „ëµ: êµ¬ê°„ë³„ Feature ì°¨ì´ ë¶„ì„ìœ¼ë¡œ ë§ì¶¤ ëŒ€ì‘\")\n",
    "\n",
    "print(\"\\n5. ë¹„ìš©-íš¨ê³¼ ë¶„ì„\")\n",
    "recall = results['test_recall']\n",
    "precision = results.get('test_precision', 0.1)  # ê¸°ë³¸ê°’\n",
    "print(f\"   - Recall {recall:.1%}: ì‹¤ì œ ë¶€ë„ ê¸°ì—…ì˜ {recall:.1%} ì‚¬ì „ íƒì§€\")\n",
    "print(f\"   - ëŒ€ì† íšŒí”¼ ê°€ì¹˜: ì˜ˆìƒ ë¶€ë„ì•¡ì˜ {recall:.1%} ì ˆê° ê°€ëŠ¥\")\n",
    "print(f\"   - False Positive: ì •ìƒ ê¸°ì—… ì¤‘ ì¼ë¶€ ì˜¤íŒ (Yellow êµ¬ê°„ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ì™„í™”)\")\n",
    "print(\"   âœ ëŒ€ì† ë°©ì§€ í¸ìµ >> ëª¨ë‹ˆí„°ë§ ë¹„ìš©\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 10: ëª¨ë¸ í•œê³„ì  ë° ê°œì„  ë°©í–¥\n",
    "\n",
    "### 10.1 ë°ì´í„° í•œê³„\n",
    "\n",
    "#### ì‹œì  ì œì•½\n",
    "- **í˜„í™©**: 2021ë…„ 8ì›” ë‹¨ì¼ ì‹œì  ìŠ¤ëƒ…ìƒ· ë°ì´í„°\n",
    "- **ë¬¸ì œ**: ì‹œê³„ì—´ íŒ¨í„´ (ì¬ë¬´ ìƒíƒœ ì¶”ì´) ë°˜ì˜ ë¶ˆê°€\n",
    "- **ê°œì„  ë°©í–¥**: \n",
    "  - ë‹¤ë…„ë„ íŒ¨ë„ ë°ì´í„° ìˆ˜ì§‘ (2018-2024ë…„)\n",
    "  - ë³€í™”ìœ¨(Î”) Feature ì¶”ê°€ (YoY ë§¤ì¶œ ì¦ê°€ìœ¨, ë¶€ì±„ë¹„ìœ¨ ë³€í™” ë“±)\n",
    "  - ì´ë™ í‰ê· , ì¶”ì„¸ì„  ë“± ì‹œê³„ì—´ í†µê³„ëŸ‰ í™œìš©\n",
    "\n",
    "#### í‘œë³¸ í¸í–¥\n",
    "- **í˜„í™©**: ì™¸ê° ê¸°ì—… ì¤‘ì‹¬ (ì†Œê·œëª¨ ê¸°ì—… ê³¼ì†Œ ëŒ€í‘œ)\n",
    "- **ë¬¸ì œ**: ìƒì¡´ í¸í–¥ (ì´ë¯¸ íì—…í•œ ê¸°ì—… ë¯¸í¬í•¨)\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - ë¹„ì™¸ê° ê¸°ì—… ë°ì´í„° ë³´ì™„ (ì¤‘ì†Œê¸°ì—… í˜„í™© ë°˜ì˜)\n",
    "  - íì—… ê¸°ì—… ì‚¬í›„ ë°ì´í„° ìˆ˜ì§‘ (ì—­ì‚¬ì  ë¶€ë„ ì‚¬ë¡€)\n",
    "  - ìƒ˜í”Œë§ ê°€ì¤‘ì¹˜ ì¡°ì •ìœ¼ë¡œ í¸í–¥ ì™„í™”\n",
    "\n",
    "---\n",
    "\n",
    "### 10.2 ëª¨ë¸ í•œê³„\n",
    "\n",
    "#### í´ë˜ìŠ¤ ë¶ˆê· í˜•\n",
    "- **í˜„í™©**: ë¶€ë„ìœ¨ 1.5% â†’ SMOTEë¡œ ì™„í™”í–ˆìœ¼ë‚˜ ì—¬ì „íˆ Precision ë‚®ìŒ\n",
    "- **ë¬¸ì œ**: Recall 80% ë‹¬ì„± ì‹œ Precision 5-10% (False Positive å¤š)\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - Cost-Sensitive Learning (ì˜¤ë¶„ë¥˜ ë¹„ìš© ì°¨ë“± ì ìš©)\n",
    "  - Focal Loss (ì–´ë ¤ìš´ ìƒ˜í”Œì— ê°€ì¤‘ì¹˜)\n",
    "  - Ensemble with Different Thresholds\n",
    "\n",
    "#### Feature ëˆ„ë½\n",
    "- **í˜„í™©**: ê±°ì‹œê²½ì œ ë³€ìˆ˜ (ê¸ˆë¦¬, GDP, í™˜ìœ¨) ë¯¸í¬í•¨\n",
    "- **ë¬¸ì œ**: ì‚°ì—…ë³„ ì¶©ê²© (COVID-19 ë“±) ë°˜ì˜ ì•ˆ ë¨\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - ì™¸ë¶€ ë°ì´í„° ê²°í•© (í•œêµ­ì€í–‰ ê²½ì œí†µê³„)\n",
    "  - Industry-Specific Features (ì—…ì¢…ë³„ ìˆ˜ì£¼ ì”ê³ , ì›ìì¬ ê°€ê²© ë“±)\n",
    "  - ë‰´ìŠ¤/ì†Œì…œë¯¸ë””ì–´ ê°ì„± ë¶„ì„ (Alternative Data)\n",
    "\n",
    "#### ì˜ˆì¸¡ ì‹œê³„\n",
    "- **í˜„í™©**: \"í–¥í›„ 1ë…„ ë‚´ ë¶€ë„\" â†’ ì •í™•í•œ ì‹œì  ì˜ˆì¸¡ ë¶ˆê°€\n",
    "- **ë¬¸ì œ**: 6ê°œì›” vs 11ê°œì›” ë¶€ë„ êµ¬ë¶„ ëª»í•¨\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - Survival Analysis (Cox Proportional Hazard Model)\n",
    "  - ì›”ë³„ ì˜ˆì¸¡ í™•ë¥  (1ê°œì›”, 3ê°œì›”, 6ê°œì›”, 12ê°œì›”)\n",
    "  - Dynamic Updating (ë§¤ì›” ìµœì‹  ë°ì´í„°ë¡œ ì¬ì˜ˆì¸¡)\n",
    "\n",
    "---\n",
    "\n",
    "### 10.3 í•´ì„ í•œê³„\n",
    "\n",
    "#### SHAP ê³„ì‚° ë¹„ìš©\n",
    "- **í˜„í™©**: TreeExplainerë¡œ ê°œì„ í–ˆìœ¼ë‚˜ ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œëŠ” ì—¬ì „íˆ ëŠë¦¼\n",
    "- **ë¬¸ì œ**: Real-Time ì„œë¹„ìŠ¤ ì ìš© ì‹œ ì§€ì—° ë°œìƒ ê°€ëŠ¥\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - Approximate SHAP (ìƒ˜í”Œë§ ê¸°ë°˜)\n",
    "  - FastTreeSHAP ì•Œê³ ë¦¬ì¦˜\n",
    "  - ë°°ì¹˜ ì²˜ë¦¬ ë° ìºì‹±\n",
    "\n",
    "#### ìƒí˜¸ì‘ìš© íš¨ê³¼\n",
    "- **í˜„í™©**: SHAPì€ ê°œë³„ Feature ê¸°ì—¬ë„ë§Œ í‘œì‹œ\n",
    "- **ë¬¸ì œ**: ë³µì¡í•œ Feature ê°„ ìƒí˜¸ì‘ìš© (ì˜ˆ: ë¶€ì±„ë¹„ìœ¨ Ã— ìˆ˜ìµì„±) ì„¤ëª… ë¶€ì¡±\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - SHAP Interaction Values ì¶”ê°€ ë¶„ì„\n",
    "  - Partial Dependence Plot (2D)\n",
    "  - H-statisticìœ¼ë¡œ ìƒí˜¸ì‘ìš© ê°•ë„ ì¸¡ì •\n",
    "\n",
    "---\n",
    "\n",
    "### 10.4 ìš´ì˜ í•œê³„\n",
    "\n",
    "#### ëª¨ë¸ ë“œë¦¬í”„íŠ¸\n",
    "- **í˜„í™©**: ê²½ì œ í™˜ê²½ ë³€í™” ì‹œ ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ (ì˜ˆ: ê¸ˆë¦¬ ê¸‰ë“±)\n",
    "- **ë¬¸ì œ**: ì •ê¸° ì¬í•™ìŠµ ì—†ìœ¼ë©´ ì˜ˆì¸¡ë ¥ ê°ì†Œ\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - ë¶„ê¸°ë³„ ì„±ëŠ¥ Monitoring (PSI, CSI ì§€í‘œ)\n",
    "  - ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸ (MLOps)\n",
    "  - Concept Drift Detection ì•Œê³ ë¦¬ì¦˜\n",
    "\n",
    "#### ê·œì œ ì¤€ìˆ˜\n",
    "- **í˜„í™©**: ì‹ ìš©í‰ê°€ ëª¨ë¸ ê·œì œ (Basel III ë“±) ì¶©ì¡± ì—¬ë¶€ ë¯¸ê²€ì¦\n",
    "- **ë¬¸ì œ**: ê³µì •ì„± (Fairness) í‰ê°€ ë¯¸ì‹¤ì‹œ (ì—…ì¢…/ì§€ì—­ ì°¨ë³„ ê°€ëŠ¥ì„±)\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - Regulatory Compliance Check\n",
    "  - Fairness Metrics (Demographic Parity, Equal Opportunity)\n",
    "  - Stress Testing (ê·¹ë‹¨ ì‹œë‚˜ë¦¬ì˜¤)\n",
    "\n",
    "---\n",
    "\n",
    "### 10.5 ë¹„ì¦ˆë‹ˆìŠ¤ í•œê³„\n",
    "\n",
    "#### ì˜¤ë¶„ë¥˜ ë¹„ìš© ë¶ˆê· í˜•\n",
    "- **Type I Error** (ì •ìƒâ†’ë¶€ë„ ì˜¤íŒ): ëŒ€ì¶œ ê¸°íšŒ ì†ì‹¤\n",
    "- **Type II Error** (ë¶€ë„â†’ì •ìƒ ì˜¤íŒ): ëŒ€ì† ë°œìƒ (í›¨ì”¬ í° ë¹„ìš©)\n",
    "- **í˜„í™©**: í˜„ì¬ ì„ê³„ê°’ì€ ë™ì¼ ê°€ì¤‘ì¹˜ ê°€ì •\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - ì‹¤ì œ ëŒ€ì†ìœ¨ ê¸°ë°˜ Cost Matrix ì„¤ê³„\n",
    "  - ìµœì  ì„ê³„ê°’ ì¬ì¡°ì • (Expected Cost Minimization)\n",
    "  - ì—…ì¢…ë³„/ê¸ˆì•¡ë³„ ì°¨ë“± ì„ê³„ê°’\n",
    "\n",
    "#### ì„¤ëª… ê°€ëŠ¥ì„± vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„\n",
    "- **í˜„í™©**: Tree ëª¨ë¸ ì„ íƒ â†’ ë”¥ëŸ¬ë‹ë³´ë‹¤ ì„±ëŠ¥ ë‚®ì„ ìˆ˜ ìˆìŒ\n",
    "- **ë¬¸ì œ**: SHAPë„ ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ ì™„ë²½íˆ ì„¤ëª… ëª»í•¨\n",
    "- **ê°œì„  ë°©í–¥**:\n",
    "  - Tabular Deep Learning (TabNet, FT-Transformer) ì‹¤í—˜\n",
    "  - Hybrid Model (Tree + DL Ensemble)\n",
    "  - Attention Mechanismìœ¼ë¡œ í•´ì„ë ¥ ê°•í™”\n",
    "\n",
    "---\n",
    "\n",
    "### 10.6 í–¥í›„ ì—°êµ¬ ë°©í–¥\n",
    "\n",
    "1. **ì‹œê³„ì—´ í™•ì¥**\n",
    "   - LSTM/Transformer ê¸°ë°˜ ë‹¤ë…„ë„ ì˜ˆì¸¡ ëª¨ë¸\n",
    "   - ì¬ë¬´ ì§€í‘œ ì¶”ì´ íŒ¨í„´ í•™ìŠµ\n",
    "   \n",
    "2. **ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ**\n",
    "   - ë¶€ë„ + ì‹ ìš©ë“±ê¸‰ + ì¬ë¬´ì¡°ì‘ ë™ì‹œ ì˜ˆì¸¡\n",
    "   - ê³µìœ  í‘œí˜„ í•™ìŠµìœ¼ë¡œ ì¼ë°˜í™” í–¥ìƒ\n",
    "   \n",
    "3. **ê°•ê±´ì„± í‰ê°€**\n",
    "   - Adversarial Examples í…ŒìŠ¤íŠ¸\n",
    "   - Out-of-Distribution Detection\n",
    "   - Calibration ë¶„ì„\n",
    "   \n",
    "4. **Causal Inference**\n",
    "   - ì •ì±… ê°œì… íš¨ê³¼ ì˜ˆì¸¡ (ì˜ˆ: ê¸ˆë¦¬ ì¸í•˜ ì‹œ ë¶€ë„ìœ¨ ë³€í™”)\n",
    "   - Counterfactual Explanation\n",
    "   - Treatment Effect Estimation\n",
    "   \n",
    "5. **ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ**\n",
    "   - Streamlit â†’ FastAPI + Redis + Celery ì•„í‚¤í…ì²˜\n",
    "   - ëŒ€ê·œëª¨ ì²˜ë¦¬ (10,000+ TPS)\n",
    "   - A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì„¹ì…˜ 11: ìµœì¢… ì €ì¥\n",
    "\n",
    "ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ì„ ê²°ê³¼ ì €ì¥\n",
    "analysis_results = {\n",
    "    'model_info': {\n",
    "        'model_name': results['model_name'],\n",
    "        'test_pr_auc': float(results['test_pr_auc']),\n",
    "        'test_recall': float(results['test_recall']),\n",
    "        'test_f2': float(results['test_f2'])\n",
    "    },\n",
    "    'thresholds': {\n",
    "        'selected': float(thresholds['selected']),\n",
    "        'red': float(thresholds['red']),\n",
    "        'yellow': float(thresholds['yellow'])\n",
    "    },\n",
    "    'feature_importance': {\n",
    "        'top10_features': top10_features.tolist(),\n",
    "        'importance_values': {\n",
    "            feat: float(feature_importance[list(X.columns).index(feat)])\n",
    "            for feat in top10_features\n",
    "        },\n",
    "        'top3_contribution_pct': float(top3_contribution)\n",
    "    },\n",
    "    'segment_distribution': {\n",
    "        'red': {\n",
    "            'count': int(red_mask.sum()),\n",
    "            'percentage': float(red_mask.mean()),\n",
    "            'actual_bankruptcy_rate': float(y_test[red_mask].mean()) if red_mask.sum() > 0 else 0\n",
    "        },\n",
    "        'yellow': {\n",
    "            'count': int(yellow_mask.sum()),\n",
    "            'percentage': float(yellow_mask.mean()),\n",
    "            'actual_bankruptcy_rate': float(y_test[yellow_mask].mean()) if yellow_mask.sum() > 0 else 0\n",
    "        },\n",
    "        'green': {\n",
    "            'count': int(green_mask.sum()),\n",
    "            'percentage': float(green_mask.mean()),\n",
    "            'actual_bankruptcy_rate': float(y_test[green_mask].mean()) if green_mask.sum() > 0 else 0\n",
    "        }\n",
    "    },\n",
    "    'bootstrap_ci': df_ci.to_dict('records'),\n",
    "    'shap_summary': {\n",
    "        'n_samples': int(shap_values.shape[0]),\n",
    "        'n_features': int(shap_values.shape[1]),\n",
    "        'expected_value': float(expected_value)\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSON ì €ì¥\n",
    "output_path = '../data/processed/ë°œí‘œ_Part4_SHAP_ë¶„ì„ê²°ê³¼.json'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(analysis_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… ë¶„ì„ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ\")\n",
    "print(f\"   - íŒŒì¼: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ëœ íŒŒì¼ ëª©ë¡\n",
    "output_files = [\n",
    "    'ë°œí‘œ_Part4_SHAP_Summary.png',\n",
    "    'ë°œí‘œ_Part4_Top10_Features.png',\n",
    "    'ë°œí‘œ_Part4_Dependence_Plot.png',\n",
    "    'ë°œí‘œ_Part4_Waterfall_ë¶€ë„ê¸°ì—….png',\n",
    "    'ë°œí‘œ_Part4_Waterfall_ì •ìƒê¸°ì—….png',\n",
    "    'ë°œí‘œ_Part4_Segment_SHAP.png',\n",
    "    'ë°œí‘œ_Part4_Bootstrap_CI.png',\n",
    "    'ë°œí‘œ_Part4_SHAP_ë¶„ì„ê²°ê³¼.json'\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"âœ… Part 4 ì™„ë£Œ! ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nìƒì„±ëœ íŒŒì¼ (../data/processed/):\")\n",
    "for i, f in enumerate(output_files, 1):\n",
    "    file_path = os.path.join(PROCESSED_DIR, f)\n",
    "    exists = \"âœ“\" if os.path.exists(file_path) else \"âœ—\"\n",
    "    print(f\"  {exists} {i}. {f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ë‹¤ìŒ ë‹¨ê³„: ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°œí‘œ ìë£Œ ì‘ì„±\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¨ ìƒì„±ëœ ì‹œê°í™” ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [x] Summary Plot (Beeswarm) - Global Feature Importance\n",
    "- [x] Top 10 Bar Chart - ì£¼ìš” Feature ìˆœìœ„\n",
    "- [x] Dependence Plot (Top 3) - ë¹„ì„ í˜• ê´€ê³„ ë¶„ì„\n",
    "- [x] Waterfall Plot (ë¶€ë„ ê¸°ì—…) - ê°œë³„ ì˜ˆì¸¡ ê·¼ê±°\n",
    "- [x] Waterfall Plot (ì •ìƒ ê¸°ì—…) - ëŒ€ì¡° ë¶„ì„\n",
    "- [x] Traffic Light êµ¬ê°„ë³„ SHAP - ìœ„í—˜ êµ¬ê°„ë³„ íŒ¨í„´\n",
    "- [x] Bootstrap ì‹ ë¢°êµ¬ê°„ - í†µê³„ì  ì•ˆì •ì„±\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š ì°¸ê³  ìë£Œ\n",
    "\n",
    "- SHAP ê³µì‹ ë¬¸ì„œ: https://shap.readthedocs.io/\n",
    "- Lundberg, S. M., & Lee, S. I. (2017). \"A Unified Approach to Interpreting Model Predictions.\" NeurIPS.\n",
    "- Molnar, C. (2022). \"Interpretable Machine Learning.\"\n",
    "- Shapley, L. S. (1953). \"A value for n-person games.\"\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ í•µì‹¬ ê²°ë¡ \n",
    "\n",
    "1. **ëª¨ë¸ ì„±ëŠ¥**: PR-AUC ê¸°ì¤€ ìš°ìˆ˜í•œ ì˜ˆì¸¡ë ¥ ë‹¬ì„±\n",
    "2. **í•´ì„ ê°€ëŠ¥ì„±**: SHAPìœ¼ë¡œ ë¸”ë™ë°•ìŠ¤ í•´ì†Œ, ì„¤ëª… ê°€ëŠ¥í•œ AI êµ¬í˜„\n",
    "3. **ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**: Traffic Light ì‹œìŠ¤í…œìœ¼ë¡œ ì‹¤ë¬´ í™œìš© ê°€ëŠ¥\n",
    "4. **í†µê³„ì  ì•ˆì •ì„±**: Bootstrap CIë¡œ Feature Importance ì‹ ë¢°ì„± ê²€ì¦\n",
    "5. **ê°œì„  ë°©í–¥**: ì‹œê³„ì—´ í™•ì¥, ì™¸ë¶€ ë°ì´í„° ê²°í•©, ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "\n",
    "---\n",
    "\n",
    "**ê°ì‚¬í•©ë‹ˆë‹¤!** ğŸ™"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
