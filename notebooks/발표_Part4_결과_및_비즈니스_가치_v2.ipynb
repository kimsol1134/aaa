{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸ“˜ ë°œí‘œìš© Part 4: ê²°ê³¼ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ (v2 ê°œì„ íŒ ê¸°ë°˜)\n\n## âš ï¸ ì¤‘ìš”: ì‹¤í–‰ ì „ í•„ìˆ˜ í™•ì¸\n\nì´ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ê¸° ì „ì— **ë°˜ë“œì‹œ** ë‹¤ìŒ ë…¸íŠ¸ë¶ì„ ë¨¼ì € ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤:\n\n```\nnotebooks/ë°œí‘œ_Part3_ëª¨ë¸ë§_ë°_ìµœì í™”_v2.ipynb\n```\n\nPart 3 v2 ë…¸íŠ¸ë¶ì´ ë‹¤ìŒ íŒŒì¼ë“¤ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤:\n- `data/processed/Part3_v2_ìµœì¢…ëª¨ë¸.pkl`\n- `data/processed/Part3_v2_ì „ì²˜ë¦¬ê¸°.pkl`\n- `data/processed/Part3_v2_ë©”íƒ€ë°ì´í„°.pkl`\n- `data/processed/Part3_v2_X_test_processed.csv`\n- `data/processed/Part3_v2_y_test.csv`\n\n---\n\n## ğŸ¯ Part 4 ëª©í‘œ\n\nPart 3 v2ì—ì„œ ì™„ì„±ëœ ëª¨ë¸ì„ ë°”íƒ•ìœ¼ë¡œ:\n\n### 1. Test Set ìµœì¢… ì„±ëŠ¥ í‰ê°€\n- Bootstrap CIë¥¼ í¬í•¨í•œ PR-AUC í‰ê°€\n- Confusion Matrixì˜ ì¬ë¬´ì  í•´ì„\n- Validation vs Test ì¼ë°˜í™” ì„±ëŠ¥ ë¹„êµ\n\n### 2. ëª¨ë¸ í•´ì„ (SHAP)\n- Global Feature Importance\n- Beeswarm Plot (íŠ¹ì„±ë³„ ì˜í–¥ ë°©í–¥)\n- False Negative ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„\n\n### 3. Traffic Light ì‹œìŠ¤í…œ ê²€ì¦\n- Test Setì—ì„œ ìœ„í—˜ë„ë³„ ì‹¤ì œ ë¶€ë„ìœ¨ í™•ì¸\n- ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì • ê°€ì´ë“œ\n\n### 4. ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì •ëŸ‰í™”\n- ì—°ê°„ 10,000ê±´ ì‹¬ì‚¬ ì‹œë®¬ë ˆì´ì…˜\n- Baseline ëŒ€ë¹„ ì†ìµ ê°œì„  ê³„ì‚°\n\n### 5. í•œê³„ ë° ê°œì„  ë°©í–¥\n- ì†”ì§í•œ í•œê³„ ì¸ì • (Type II Error ë¶„ì„)\n- ì›ì¸ ë¶„ì„ (ë°ì´í„° í’ˆì§ˆ, ì‹œê³„ì—´ ë¶€ì¬ ë“±)\n- êµ¬ì²´ì ì¸ ê°œì„  ë°©í–¥ ì œì‹œ\n\n---\n\n## ğŸ“Œ Part 3 v2 ê°œì„ íŒ í•µì‹¬ ìš”ì•½\n\n### Data Leakage ì™„ì „ ì œê±° âœ…\n- **3-Way Split**: Train (60%) / Validation (20%) / Test (20%)\n- **Test Set**: ìµœì¢… í‰ê°€ì—ë§Œ ì‚¬ìš©, ì˜ì‚¬ê²°ì •ì— ì ˆëŒ€ ë¯¸ì‚¬ìš©\n- **ëª¨ë“  ì˜ì‚¬ê²°ì •**: Validation Set ê¸°ë°˜\n\n### Pipeline êµ¬ì¡° ë„ì… âœ…\n- **ImbPipeline**: ì „ì²˜ë¦¬ + ë¦¬ìƒ˜í”Œë§ + ëª¨ë¸ í†µí•©\n- **ë°°í¬ ì•ˆì •ì„±**: ì „ì²˜ë¦¬ ëˆ„ë½ ë°©ì§€\n- **SHAP ë¶„ì„**: Pipeline êµ¬ì¡° ê³ ë ¤ í•„ìš”\n\n### AutoML ìµœì í™” âœ…\n- **RandomizedSearchCV**: n_iter=100~200\n- **5-Fold Stratified CV**: Train Setë§Œ ì‚¬ìš©\n- **PR-AUC**: ë¶ˆê· í˜• ë°ì´í„° í•µì‹¬ ì§€í‘œ\n\n### Threshold ìµœì í™” âœ…\n- **F2-Score ê¸°ë°˜**: Recall ìš°ì„  (Î²=2)\n- **Validation ê¸°ë°˜ ê²°ì •**: Single split í¸í–¥ ë°©ì§€\n- **Traffic Light**: Recall 80%/95% ë³´ì¥\n\n### ì•™ìƒë¸” ë‹¤ì–‘ì„± ì²´í¬ âœ…\n- **Statistical Test**: Wilcoxon Signed-Rank Test\n- **Single vs Voting**: ì„±ëŠ¥ + í†µê³„ì  ìœ ì˜ì„± ê³ ë ¤\n- **í•´ì„ ê°€ëŠ¥ì„±**: SHAP ë¶„ì„ ìš©ì´ì„± ìš°ì„ \n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import platform\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ í‰ê°€\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, roc_curve,\n",
    "    fbeta_score, recall_score, precision_score\n",
    ")\n",
    "\n",
    "# SHAP (ëª¨ë¸ í•´ì„)\n",
    "import shap\n",
    "\n",
    "# Bootstrap CI\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (CLAUDE.md ì¤€ìˆ˜)\n",
    "if platform.system() == 'Darwin':\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "else:\n",
    "    plt.rc('font', family='NanumGothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "# ì‹œê°í™” ì„¤ì •\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# ëœë¤ ì‹œë“œ\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"   - NumPy: {np.__version__}\")\n",
    "print(f\"   - Pandas: {pd.__version__}\")\n",
    "print(f\"   - Platform: {platform.system()}\")\n",
    "print(f\"   - Random State: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ëª¨ë¸ ë° ë°ì´í„° ë¡œë”©\n",
    "\n",
    "### 1.1 ë©”íƒ€ë°ì´í„° ë¡œë”©\n",
    "\n",
    "Part 3 v2ì—ì„œ ì €ì¥í•œ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë”©í•˜ì—¬ ëª¨ë“  ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ì„¤ì •\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "MODEL_PREFIX = 'Part3_v2'\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° ë¡œë”©\n",
    "metadata_path = os.path.join(PROCESSED_DIR, f'{MODEL_PREFIX}_ë©”íƒ€ë°ì´í„°.pkl')\n",
    "\n",
    "if not os.path.exists(metadata_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {metadata_path}\\n\\n\"\n",
    "        \"Part 3 v2 ë…¸íŠ¸ë¶ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”:\\n\"\n",
    "        \"  notebooks/ë°œí‘œ_Part3_ëª¨ë¸ë§_ë°_ìµœì í™”_v2.ipynb\"\n",
    "    )\n",
    "\n",
    "metadata = joblib.load(metadata_path)\n",
    "\n",
    "print(\"âœ… ë©”íƒ€ë°ì´í„° ë¡œë”© ì™„ë£Œ\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ìƒì„± ì¼ì‹œ: {metadata['creation_date']}\")\n",
    "print(f\"\\nğŸ“Š ëª¨ë¸ ì •ë³´:\")\n",
    "print(f\"   - ìµœì¢… ëª¨ë¸: {metadata['final_model_name']}\")\n",
    "print(f\"   - ì„ íƒ ì„ê³„ê°’: {metadata['selected_threshold']:.4f}\")\n",
    "print(f\"   - Red Threshold: {metadata['red_threshold']:.4f}\")\n",
    "print(f\"   - Yellow Threshold: {metadata['yellow_threshold']:.4f}\")\n",
    "print(f\"\\nğŸ“Š Validation ì„±ëŠ¥:\")\n",
    "print(f\"   - PR-AUC: {metadata['val_pr_auc']:.4f}\")\n",
    "print(f\"\\nğŸ“Š Test ì„±ëŠ¥ (Part 3ì—ì„œ í‰ê°€):\")\n",
    "print(f\"   - PR-AUC: {metadata['test_pr_auc']:.4f}\")\n",
    "print(f\"   - F2-Score: {metadata['test_f2']:.4f}\")\n",
    "print(f\"   - Precision: {metadata['test_precision']:.2%}\")\n",
    "print(f\"   - Recall: {metadata['test_recall']:.2%}\")\n",
    "print(f\"   - Type II Error: {metadata['test_type_ii_error']:.2%}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ëª¨ë¸ ë¡œë”©\n",
    "\n",
    "**ì¤‘ìš”**: Part 3 v2ëŠ” Pipeline êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, ëª¨ë¸ì€ Pipeline ë‚´ë¶€ì— ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ëª¨ë¸ ë¡œë”©\n",
    "final_model_path = os.path.join(PROCESSED_DIR, f'{MODEL_PREFIX}_ìµœì¢…ëª¨ë¸.pkl')\n",
    "final_model = joblib.load(final_model_path)\n",
    "\n",
    "print(f\"âœ… ìµœì¢… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {metadata['final_model_name']}\")\n",
    "print(f\"   - ëª¨ë¸ íƒ€ì…: {type(final_model).__name__}\")\n",
    "\n",
    "# Pipeline êµ¬ì¡° í™•ì¸\n",
    "if hasattr(final_model, 'estimators_'):\n",
    "    print(f\"\\n   âš ï¸ Voting Ensemble êµ¬ì¡° ê°ì§€\")\n",
    "    print(f\"   - êµ¬ì„± ëª¨ë¸:\")\n",
    "    for name, est in final_model.estimators_:\n",
    "        print(f\"      â€¢ {name}: {type(est).__name__}\")\n",
    "else:\n",
    "    print(f\"\\n   - Single Model: {type(final_model).__name__}\")\n",
    "\n",
    "# ì „ì²˜ë¦¬ê¸° ë¡œë”©\n",
    "preprocessor_path = os.path.join(PROCESSED_DIR, f'{MODEL_PREFIX}_ì „ì²˜ë¦¬ê¸°.pkl')\n",
    "preprocessor = joblib.load(preprocessor_path)\n",
    "\n",
    "print(f\"\\nâœ… ì „ì²˜ë¦¬ê¸° ë¡œë”© ì™„ë£Œ\")\n",
    "print(f\"   - Pipeline ë‹¨ê³„:\")\n",
    "for name, step in preprocessor.steps:\n",
    "    print(f\"      â€¢ {name}: {type(step).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Test ë°ì´í„° ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ë°ì´í„° ë¡œë”© (ì „ì²˜ë¦¬ëœ ë°ì´í„°)\n",
    "X_test_path = os.path.join(PROCESSED_DIR, f'{MODEL_PREFIX}_X_test_processed.csv')\n",
    "y_test_path = os.path.join(PROCESSED_DIR, f'{MODEL_PREFIX}_y_test.csv')\n",
    "\n",
    "X_test = pd.read_csv(X_test_path, encoding='utf-8')\n",
    "y_test = pd.read_csv(y_test_path, encoding='utf-8')['target']\n",
    "\n",
    "print(\"âœ… Test ë°ì´í„° ë¡œë”© ì™„ë£Œ\")\n",
    "print(f\"   - X_test shape: {X_test.shape}\")\n",
    "print(f\"   - y_test shape: {y_test.shape}\")\n",
    "print(f\"   - Test Set ë¶€ë„ìœ¨: {y_test.mean():.4%}\")\n",
    "print(f\"   - ë¶€ë„ ê¸°ì—… ìˆ˜: {y_test.sum()}\")\n",
    "print(f\"   - ì •ìƒ ê¸°ì—… ìˆ˜: {len(y_test) - y_test.sum()}\")\n",
    "\n",
    "# íŠ¹ì„± ëª©ë¡ í™•ì¸\n",
    "print(f\"\\nğŸ“‹ íŠ¹ì„± ëª©ë¡ ({len(X_test.columns)}ê°œ):\")\n",
    "for i, col in enumerate(X_test.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Test Set ì˜ˆì¸¡ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set ì˜ˆì¸¡ (ì´ë¯¸ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©)\n",
    "y_test_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_prob >= metadata['selected_threshold']).astype(int)\n",
    "\n",
    "print(\"âœ… Test Set ì˜ˆì¸¡ ì™„ë£Œ\")\n",
    "print(f\"   - ì‚¬ìš© ì„ê³„ê°’: {metadata['selected_threshold']:.4f}\")\n",
    "print(f\"   - ì˜ˆì¸¡ ë¶€ë„: {y_test_pred.sum():,}ê°œ\")\n",
    "print(f\"   - ì˜ˆì¸¡ ì •ìƒ: {(1 - y_test_pred).sum():,}ê°œ\")\n",
    "print(f\"\\ní™•ë¥  ë¶„í¬:\")\n",
    "print(f\"   - Min:  {y_test_prob.min():.4f}\")\n",
    "print(f\"   - 25%:  {np.percentile(y_test_prob, 25):.4f}\")\n",
    "print(f\"   - 50%:  {np.percentile(y_test_prob, 50):.4f}\")\n",
    "print(f\"   - 75%:  {np.percentile(y_test_prob, 75):.4f}\")\n",
    "print(f\"   - Max:  {y_test_prob.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1.5 ì¬ë¬´ ê°€ì • ìƒìˆ˜ ì •ì˜ (ì „ì—­ ì‚¬ìš©)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ===== ì¬ë¬´ ê°€ì • ìƒìˆ˜ (ì „ì—­ ì •ì˜) =====\n# ì´ ìƒìˆ˜ë“¤ì€ Section 2ì™€ Section 5ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤\n\n# ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œë®¬ë ˆì´ì…˜ ê°€ì •\nAVG_LOAN_AMOUNT = 100_000_000  # í‰ê·  ëŒ€ì¶œì•¡: 1ì–µì›\nDEFAULT_LOSS_RATE = 0.67        # ë¶€ë„ ì‹œ ì†ì‹¤ë¥ : 67% (íšŒìˆ˜ìœ¨ 33%)\nINTEREST_RATE = 0.05            # ì—° ì´ììœ¨: 5%\n\n# ì‹œë®¬ë ˆì´ì…˜ ê·œëª¨\nN_APPLICATIONS = 10000          # ì—°ê°„ ì‹¬ì‚¬ ê±´ìˆ˜\nDEFAULT_RATE = 0.015            # ì˜ˆìƒ ë¶€ë„ìœ¨: 1.5%\n\nprint(\"âœ… ì¬ë¬´ ê°€ì • ìƒìˆ˜ ì •ì˜ ì™„ë£Œ\")\nprint(\"=\"*70)\nprint(f\"í‰ê·  ëŒ€ì¶œì•¡:      {AVG_LOAN_AMOUNT:,}ì›\")\nprint(f\"ë¶€ë„ ì‹œ ì†ì‹¤ë¥ :   {DEFAULT_LOSS_RATE:.0%} (íšŒìˆ˜ìœ¨ {1-DEFAULT_LOSS_RATE:.0%})\")\nprint(f\"ì—° ì´ììœ¨:        {INTEREST_RATE:.1%}\")\nprint(f\"ì—°ê°„ ì‹¬ì‚¬ ê±´ìˆ˜:   {N_APPLICATIONS:,}ê±´\")\nprint(f\"ì˜ˆìƒ ë¶€ë„ìœ¨:      {DEFAULT_RATE:.2%}\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Section 1 ì™„ë£Œ\n",
    "\n",
    "**ì™„ë£Œ ì‚¬í•­:**\n",
    "- âœ… í™˜ê²½ ì„¤ì •\n",
    "- âœ… Part 3 v2 ë©”íƒ€ë°ì´í„° ë¡œë”©\n",
    "- âœ… ìµœì¢… ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ë¡œë”©\n",
    "- âœ… Test ë°ì´í„° ë¡œë”©\n",
    "- âœ… Test Set ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "\n",
    "**ë‹¤ìŒ ë‹¨ê³„:**\n",
    "- Section 2: Test Set ì„±ëŠ¥ í‰ê°€ (Bootstrap CI, Confusion Matrix)\n",
    "- Section 3: SHAP ë¶„ì„ ë° Feature Importance\n",
    "- Section 4: Traffic Light ì‹œìŠ¤í…œ ê²€ì¦\n",
    "- Section 5: ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì‹œë®¬ë ˆì´ì…˜\n",
    "- Section 6: í•œê³„ ë° ê°œì„  ë°©í–¥\n",
    "- Section 7: ìµœì¢… ìš”ì•½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Set ìµœì¢… ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "### 2.1 Bootstrap Confidence Interval (PR-AUC)\n",
    "\n",
    "ë‹¨ì¼ í‰ê°€ê°’ë§Œìœ¼ë¡œëŠ” ë¶ˆí™•ì‹¤ì„±ì„ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, Bootstrap ë¦¬ìƒ˜í”Œë§ìœ¼ë¡œ 95% ì‹ ë¢°êµ¬ê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Bootstrap Confidence Interval (PR-AUC)\nn_iterations = 1000\npr_aucs = []\nf2_scores = []\n\nnp.random.seed(RANDOM_STATE)\n\nprint(\"ğŸ”„ Bootstrap CI ê³„ì‚° ì¤‘... (1000 iterations)\")\n\nfor i in range(n_iterations):\n    # ë¦¬ìƒ˜í”Œë§\n    indices = resample(range(len(y_test)), random_state=i)\n    y_test_boot = y_test.values[indices] if hasattr(y_test, \"values\") else y_test[indices]\n    y_prob_boot = y_test_prob[indices]  # numpy array, ì•ˆì „\n    y_pred_boot = (y_prob_boot >= metadata['selected_threshold']).astype(int)\n    \n    # PR-AUC\n    pr_auc = average_precision_score(y_test_boot, y_prob_boot)\n    pr_aucs.append(pr_auc)\n    \n    # F2-Score\n    f2 = fbeta_score(y_test_boot, y_pred_boot, beta=2, zero_division=0)\n    f2_scores.append(f2)\n\n# í†µê³„ëŸ‰ ê³„ì‚°\npr_auc_mean = np.mean(pr_aucs)\npr_auc_ci_low = np.percentile(pr_aucs, 2.5)\npr_auc_ci_high = np.percentile(pr_aucs, 97.5)\n\nf2_mean = np.mean(f2_scores)\nf2_ci_low = np.percentile(f2_scores, 2.5)\nf2_ci_high = np.percentile(f2_scores, 97.5)\n\nprint(\"âœ… Bootstrap CI ê³„ì‚° ì™„ë£Œ\\n\")\nprint(\"=\"*70)\nprint(\"ğŸ“Š Test Set ì„±ëŠ¥ (Bootstrap 95% CI)\")\nprint(\"=\"*70)\nprint(f\"\\nğŸ¯ PR-AUC:\")\nprint(f\"   Point Estimate:  {metadata['test_pr_auc']:.4f}\")\nprint(f\"   Bootstrap Mean:  {pr_auc_mean:.4f}\")\nprint(f\"   95% CI:          [{pr_auc_ci_low:.4f}, {pr_auc_ci_high:.4f}]\")\nprint(f\"   Width:           {pr_auc_ci_high - pr_auc_ci_low:.4f}\")\nprint(f\"\\nğŸ¯ F2-Score:\")\nprint(f\"   Point Estimate:  {metadata['test_f2']:.4f}\")\nprint(f\"   Bootstrap Mean:  {f2_mean:.4f}\")\nprint(f\"   95% CI:          [{f2_ci_low:.4f}, {f2_ci_high:.4f}]\")\nprint(f\"   Width:           {f2_ci_high - f2_ci_low:.4f}\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap ë¶„í¬ ì‹œê°í™”\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('PR-AUC Bootstrap Distribution', 'F2-Score Bootstrap Distribution')\n",
    ")\n",
    "\n",
    "# PR-AUC ë¶„í¬\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=pr_aucs, nbinsx=50, name='PR-AUC',\n",
    "                 marker_color='#3498db', showlegend=False),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_vline(x=pr_auc_mean, line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=f\"Mean: {pr_auc_mean:.4f}\", row=1, col=1)\n",
    "fig.add_vline(x=pr_auc_ci_low, line_dash=\"dot\", line_color=\"green\",\n",
    "              annotation_text=f\"2.5%: {pr_auc_ci_low:.4f}\", row=1, col=1)\n",
    "fig.add_vline(x=pr_auc_ci_high, line_dash=\"dot\", line_color=\"green\",\n",
    "              annotation_text=f\"97.5%: {pr_auc_ci_high:.4f}\", row=1, col=1)\n",
    "\n",
    "# F2-Score ë¶„í¬\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=f2_scores, nbinsx=50, name='F2-Score',\n",
    "                 marker_color='#2ecc71', showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_vline(x=f2_mean, line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=f\"Mean: {f2_mean:.4f}\", row=1, col=2)\n",
    "fig.add_vline(x=f2_ci_low, line_dash=\"dot\", line_color=\"green\", row=1, col=2)\n",
    "fig.add_vline(x=f2_ci_high, line_dash=\"dot\", line_color=\"green\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Bootstrap Confidence Intervals (1000 iterations)',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Validation vs Test ì„±ëŠ¥ ë¹„êµ (ì¼ë°˜í™” ê²€ì¦)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation vs Test ë¹„êµ\n",
    "print(\"ğŸ“Š Validation vs Test ì„±ëŠ¥ ë¹„êµ (ì¼ë°˜í™” ì„±ëŠ¥ ê²€ì¦)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Metric':<20} {'Validation':<15} {'Test':<15} {'Difference':<15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "val_pr_auc = metadata['val_pr_auc']\n",
    "test_pr_auc = metadata['test_pr_auc']\n",
    "diff_pr_auc = test_pr_auc - val_pr_auc\n",
    "\n",
    "print(f\"{'PR-AUC':<20} {val_pr_auc:<15.4f} {test_pr_auc:<15.4f} {diff_pr_auc:<+15.4f}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "if abs(diff_pr_auc) < 0.02:\n",
    "    print(\"\\nâœ… ì¼ë°˜í™” ì„±ëŠ¥ ìš°ìˆ˜: Validationê³¼ Testì˜ ì°¨ì´ê°€ 2% ë¯¸ë§Œ\")\n",
    "    print(\"   â†’ ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œë„ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€\")\n",
    "elif abs(diff_pr_auc) < 0.05:\n",
    "    print(\"\\nâš ï¸ ì¼ë°˜í™” ì„±ëŠ¥ ì–‘í˜¸: Validationê³¼ Testì˜ ì°¨ì´ê°€ 2-5%\")\n",
    "    print(\"   â†’ ì‹¤ë¬´ ì ìš© ì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í•„ìš”\")\n",
    "else:\n",
    "    print(\"\\nâŒ ì¼ë°˜í™” ì„±ëŠ¥ ì£¼ì˜: Validationê³¼ Testì˜ ì°¨ì´ê°€ 5% ì´ìƒ\")\n",
    "    print(\"   â†’ ê³¼ì í•© ê°€ëŠ¥ì„± ë˜ëŠ” ë°ì´í„° ë¶„í¬ ì°¨ì´ ì˜ì‹¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Confusion Matrix ë° ì¬ë¬´ í•´ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix ê³„ì‚°\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# ê¸°íƒ€ ë©”íŠ¸ë¦­\n",
    "test_precision = metadata['test_precision']\n",
    "test_recall = metadata['test_recall']\n",
    "test_f2 = metadata['test_f2']\n",
    "type_ii_error = metadata['test_type_ii_error']\n",
    "\n",
    "print(\"ğŸ“Š Confusion Matrix (Test Set)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n                    ì˜ˆì¸¡: ì •ìƒ      ì˜ˆì¸¡: ë¶€ë„\")\n",
    "print(f\"ì‹¤ì œ: ì •ìƒ          {tn:>10,}      {fp:>10,}\")\n",
    "print(f\"ì‹¤ì œ: ë¶€ë„          {fn:>10,}      {tp:>10,}\")\n",
    "print(\"\\n\")\n",
    "print(f\"TN (True Negative):  {tn:>10,}  (ì •ìƒ â†’ ì •ìƒ âœ…)\")\n",
    "print(f\"FP (False Positive): {fp:>10,}  (ì •ìƒ â†’ ë¶€ë„ âš ï¸)\")\n",
    "print(f\"FN (False Negative): {fn:>10,}  (ë¶€ë„ â†’ ì •ìƒ âŒ)\")\n",
    "print(f\"TP (True Positive):  {tp:>10,}  (ë¶€ë„ â†’ ë¶€ë„ âœ…)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­:\")\n",
    "print(f\"   Precision:       {test_precision:.2%}\")\n",
    "print(f\"   Recall:          {test_recall:.2%}\")\n",
    "print(f\"   F2-Score:        {test_f2:.4f}\")\n",
    "print(f\"   Type I Error:    {fp/(tn+fp):.2%}  (ì •ìƒì„ ë¶€ë„ë¡œ ì˜¤íŒ)\")\n",
    "print(f\"   Type II Error:   {type_ii_error:.2%}  (ë¶€ë„ë¥¼ ì •ìƒìœ¼ë¡œ ì˜¤íŒ)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix ì‹œê°í™”\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=[[tn, fp], [fn, tp]],\n",
    "    x=['ì˜ˆì¸¡: ì •ìƒ', 'ì˜ˆì¸¡: ë¶€ë„'],\n",
    "    y=['ì‹¤ì œ: ì •ìƒ', 'ì‹¤ì œ: ë¶€ë„'],\n",
    "    text=[[f'TN\\n{tn:,}', f'FP\\n{fp:,}'],\n",
    "          [f'FN\\n{fn:,}', f'TP\\n{tp:,}']],\n",
    "    texttemplate='%{text}',\n",
    "    textfont={\"size\": 16},\n",
    "    colorscale='Blues',\n",
    "    showscale=False\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Confusion Matrix (Test Set)',\n",
    "    height=500,\n",
    "    xaxis_title='',\n",
    "    yaxis_title=''\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ì¬ë¬´ì  í•´ì„: ì†ìµ ê´€ì ì—ì„œì˜ Confusion Matrix\n",
    "\n",
    "ê° ì…€ì´ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¬ë¬´ì ìœ¼ë¡œ í•´ì„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¬ë¬´ì  ê°€ì • (í•œêµ­ ì¤‘ì†Œê¸°ì—… í‰ê· )\n",
    "AVG_LOAN_AMOUNT = 100_000_000  # 1ì–µì›\n",
    "DEFAULT_LOSS_RATE = 0.67        # íšŒìˆ˜ìœ¨ 33% â†’ ì†ì‹¤ë¥  67%\n",
    "INTEREST_RATE = 0.05            # ì—° 5% ì´ììœ¨\n",
    "\n",
    "print(\"ğŸ’° ì¬ë¬´ì  í•´ì„: Confusion Matrixì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nê°€ì •:\")\n",
    "print(f\"   - í‰ê·  ëŒ€ì¶œì•¡: {AVG_LOAN_AMOUNT:,}ì› (1ì–µì›)\")\n",
    "print(f\"   - ë¶€ë„ ì‹œ ì†ì‹¤ë¥ : {DEFAULT_LOSS_RATE:.0%} (íšŒìˆ˜ìœ¨ 33%)\")\n",
    "print(f\"   - ì—° ì´ììœ¨: {INTEREST_RATE:.1%}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# TP (True Positive): ë¶€ë„ ê¸°ì—…ì„ ë¶€ë„ë¡œ ì˜ˆì¸¡\n",
    "tp_avoided_loss = tp * AVG_LOAN_AMOUNT * DEFAULT_LOSS_RATE\n",
    "print(f\"\\nâœ… TP (True Positive): {tp:,}ê±´\")\n",
    "print(f\"   ì˜ë¯¸: ë¶€ë„ ìœ„í—˜ ì‚¬ì „ ì°¨ë‹¨ ì„±ê³µ\")\n",
    "print(f\"   ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜: ì†ì‹¤ íšŒí”¼\")\n",
    "print(f\"   ì˜ˆìƒ ì†ì‹¤ íšŒí”¼ì•¡: {tp_avoided_loss/1e8:.1f}ì–µì›\")\n",
    "print(f\"   ì‹¤ë¬´ ì•¡ì…˜: ëŒ€ì¶œ ê±°ì ˆ ë˜ëŠ” ë‹´ë³´ ê°•í™”\")\n",
    "\n",
    "# FN (False Negative): ë¶€ë„ ê¸°ì—…ì„ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡ - ê°€ì¥ ìœ„í—˜!\n",
    "fn_actual_loss = fn * AVG_LOAN_AMOUNT * DEFAULT_LOSS_RATE\n",
    "print(f\"\\nâŒ FN (False Negative): {fn:,}ê±´ âš ï¸âš ï¸âš ï¸\")\n",
    "print(f\"   ì˜ë¯¸: ë¶€ë„ ê¸°ì—…ì„ ë†“ì¹¨ â†’ ì‹¤ì œ ì†ì‹¤ ë°œìƒ\")\n",
    "print(f\"   ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬: ê°€ì¥ í° ë¬¸ì œ (Type II Error)\")\n",
    "print(f\"   ì˜ˆìƒ ì‹¤ì œ ì†ì‹¤: {fn_actual_loss/1e8:.1f}ì–µì›\")\n",
    "print(f\"   Type II Error: {type_ii_error:.2%}\")\n",
    "print(f\"\\n   ì›ì¸ ì¶”ì •:\")\n",
    "print(f\"      1. ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ (ì†Œì†¡, ê²½ì˜ì§„ ì´ìŠˆ, ê±°ë˜ì²˜ ë¶€ë„)\")\n",
    "print(f\"      2. ê¸‰ê²©í•œ ì¬ë¬´ ì•…í™” (ì‹œê³„ì—´ ë°ì´í„° ë¶€ì¬)\")\n",
    "print(f\"      3. ê·¹ë„ ë¶ˆê· í˜• (1:66) â†’ ì†Œìˆ˜ í´ë˜ìŠ¤ í•™ìŠµ ì–´ë ¤ì›€\")\n",
    "print(f\"      4. íŠ¹ì´ ì¼€ì´ìŠ¤ (ì—…ì¢… íŠ¹ìˆ˜ì„±, ê³„ì ˆì„± ë“±)\")\n",
    "\n",
    "# FP (False Positive): ì •ìƒ ê¸°ì—…ì„ ë¶€ë„ë¡œ ì˜ˆì¸¡\n",
    "fp_opportunity_loss = fp * AVG_LOAN_AMOUNT * INTEREST_RATE\n",
    "print(f\"\\nâš ï¸ FP (False Positive): {fp:,}ê±´\")\n",
    "print(f\"   ì˜ë¯¸: ì •ìƒ ê¸°ì—…ì„ ë¶€ë„ë¡œ ì˜¤íŒ â†’ ê¸°íšŒ ì†ì‹¤\")\n",
    "print(f\"   ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ ì†ì‹¤: ëŒ€ì¶œ ê±°ì ˆë¡œ ì¸í•œ ì´ì ìˆ˜ìµ ìƒì‹¤\")\n",
    "print(f\"   ì˜ˆìƒ ì´ì ìˆ˜ìµ ì†ì‹¤: {fp_opportunity_loss/1e8:.1f}ì–µì› (ì—°ê°„)\")\n",
    "print(f\"   ì‹¤ë¬´ ì˜í–¥: ê³ ê° ë¶ˆë§Œ, ì‹œì¥ ì ìœ ìœ¨ ê°ì†Œ\")\n",
    "print(f\"\\n   ì™„í™” ë°©ì•ˆ:\")\n",
    "print(f\"      1. Yellow Zoneìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì¶”ê°€ ì‹¤ì‚¬ ì§„í–‰\")\n",
    "print(f\"      2. ë‹´ë³´/ë³´ì¦ì¸ìœ¼ë¡œ ë¦¬ìŠ¤í¬ ì™„í™” í›„ ìŠ¹ì¸\")\n",
    "print(f\"      3. ëŒ€ì¶œ ê¸ˆì•¡ ì¶•ì†Œ ë˜ëŠ” ê¸ˆë¦¬ ìƒí–¥ ì¡°ì •\")\n",
    "\n",
    "# TN (True Negative): ì •ìƒ ê¸°ì—…ì„ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡\n",
    "tn_revenue = tn * AVG_LOAN_AMOUNT * INTEREST_RATE\n",
    "print(f\"\\nâœ… TN (True Negative): {tn:,}ê±´\")\n",
    "print(f\"   ì˜ë¯¸: ì •ìƒ ê¸°ì—… ì •í™•íˆ ìŠ¹ì¸ â†’ ì •ìƒ ì˜ì—…\")\n",
    "print(f\"   ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜: ì•ˆì •ì  ìˆ˜ìµ ì°½ì¶œ\")\n",
    "print(f\"   ì˜ˆìƒ ì´ì ìˆ˜ìµ: {tn_revenue/1e8:.1f}ì–µì› (ì—°ê°„)\")\n",
    "print(f\"   ì‹¤ë¬´ ì•¡ì…˜: ì¼ë°˜ í”„ë¡œì„¸ìŠ¤ë¡œ ìŠ¹ì¸\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"ğŸ“Œ í•µì‹¬ ìš”ì•½:\")\n",
    "print(f\"   íšŒí”¼í•œ ì†ì‹¤ (TP): {tp_avoided_loss/1e8:.1f}ì–µì›\")\n",
    "print(f\"   ì‹¤ì œ ì†ì‹¤ (FN):   {fn_actual_loss/1e8:.1f}ì–µì› âŒ\")\n",
    "print(f\"   ê¸°íšŒ ì†ì‹¤ (FP):   {fp_opportunity_loss/1e8:.1f}ì–µì›\")\n",
    "print(f\"   ìˆœì´ìµ ê¸°ì—¬ (TN): {tn_revenue/1e8:.1f}ì–µì›\")\n",
    "print(f\"\\n   ìˆœ íš¨ê³¼:          {(tp_avoided_loss - fn_actual_loss - fp_opportunity_loss)/1e8:.1f}ì–µì›\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Section 2 ì™„ë£Œ\n",
    "\n",
    "**ì™„ë£Œ ì‚¬í•­:**\n",
    "- âœ… Bootstrap 95% CI (PR-AUC, F2-Score)\n",
    "- âœ… Validation vs Test ì¼ë°˜í™” ì„±ëŠ¥ ë¹„êµ\n",
    "- âœ… Confusion Matrix ìƒì„¸ ë¶„ì„\n",
    "- âœ… ì¬ë¬´ì  í•´ì„ (ì†ìµ ê´€ì )\n",
    "- âœ… FN ì›ì¸ ë¶„ì„ ë° FP ì™„í™” ë°©ì•ˆ\n",
    "\n",
    "**ë‹¤ìŒ ë‹¨ê³„:**\n",
    "- Section 3: SHAP ë¶„ì„ (Global Importance + False Negative ì¼€ì´ìŠ¤)\n",
    "- Section 4: Traffic Light ì‹œìŠ¤í…œ ê²€ì¦\n",
    "- Section 5: ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì‹œë®¬ë ˆì´ì…˜\n",
    "- Section 6: í•œê³„ ë° ê°œì„  ë°©í–¥\n",
    "- Section 7: ìµœì¢… ìš”ì•½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SHAP ë¶„ì„: ëª¨ë¸ í•´ì„\n",
    "\n",
    "### 3.1 ëª¨ë¸ ì¶”ì¶œ (Voting Ensemble ê³ ë ¤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP ë¶„ì„ìš© ëª¨ë¸ ì¶”ì¶œ\n",
    "if metadata['final_model_name'] == 'VotingEnsemble':\n",
    "    # Votingì˜ ê²½ìš° ì²« ë²ˆì§¸ estimator ì‚¬ìš©\n",
    "    model_for_shap = final_model.estimators_[0]\n",
    "    shap_model_name = type(model_for_shap).__name__\n",
    "    print(f\"âš ï¸  Voting Ensembleì´ë¯€ë¡œ ì²« ë²ˆì§¸ ëª¨ë¸({shap_model_name})ì˜ SHAP ë¶„ì„ ì‚¬ìš©\")\n",
    "else:\n",
    "    model_for_shap = final_model\n",
    "    shap_model_name = type(model_for_shap).__name__\n",
    "    print(f\"âœ… Single Model: {shap_model_name}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š SHAP ë¶„ì„ ëŒ€ìƒ ëª¨ë¸: {shap_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SHAP Values ê³„ì‚°\n",
    "\n",
    "**ì£¼ì˜**: Test Set ì „ì²´ë¥¼ ì‚¬ìš©í•˜ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ, ìƒ˜í”Œë§í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP ë¶„ì„ìš© ìƒ˜í”Œë§ (ì†ë„ë¥¼ ìœ„í•´)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "sample_size = min(500, len(X_test))\n",
    "sample_indices = np.random.choice(len(X_test), sample_size, replace=False)\n",
    "\n",
    "X_test_sample = X_test.iloc[sample_indices]\n",
    "y_test_sample = y_test.iloc[sample_indices]\n",
    "\n",
    "print(f\"ğŸ“Š SHAP ë¶„ì„ ìƒ˜í”Œ:\")\n",
    "print(f\"   - ìƒ˜í”Œ í¬ê¸°: {sample_size}\")\n",
    "print(f\"   - ìƒ˜í”Œ ë¶€ë„ìœ¨: {y_test_sample.mean():.2%}\")\n",
    "print(f\"\\nğŸ”„ SHAP Values ê³„ì‚° ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TreeExplainer (Tree ê¸°ë°˜ ëª¨ë¸ìš©)\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(model_for_shap)\n",
    "    shap_values = explainer.shap_values(X_test_sample)\n",
    "    \n",
    "    # Binary classificationì˜ ê²½ìš° class 1ë§Œ ì‚¬ìš©\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]\n",
    "    \n",
    "    print(f\"âœ… TreeExplainer ì‚¬ìš© ì™„ë£Œ\")\n",
    "    print(f\"   - SHAP values shape: {shap_values.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  TreeExplainer ì‹¤íŒ¨, KernelExplainer ì‹œë„: {e}\")\n",
    "    \n",
    "    # KernelExplainer (ëª¨ë“  ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥, ëŠë¦¼)\n",
    "    background = shap.sample(X_test_sample, 100)\n",
    "    explainer = shap.KernelExplainer(model_for_shap.predict_proba, background)\n",
    "    shap_values = explainer.shap_values(X_test_sample)\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]\n",
    "    \n",
    "    print(f\"âœ… KernelExplainer ì‚¬ìš© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Global Feature Importance (Bar Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Bar Plot (Global Importance)\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test_sample, \n",
    "                  plot_type=\"bar\", \n",
    "                  max_display=15,\n",
    "                  show=False)\n",
    "plt.title(f'SHAP Feature Importance (Top 15) - {shap_model_name}', fontsize=14, pad=20)\n",
    "plt.xlabel('í‰ê·  |SHAP value|', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Beeswarm Plot (íŠ¹ì„±ë³„ ì˜í–¥ ë°©í–¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Beeswarm Plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "shap.summary_plot(shap_values, X_test_sample, \n",
    "                  max_display=15,\n",
    "                  show=False)\n",
    "plt.title(f'SHAP Summary Plot (Beeswarm) - {shap_model_name}', fontsize=14, pad=20)\n",
    "plt.xlabel('SHAP value (ë¶€ë„ ìœ„í—˜ ì˜í–¥)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ í•´ì„ ê°€ì´ë“œ:\")\n",
    "print(\"   - Xì¶•: SHAP value (ì–‘ìˆ˜ = ë¶€ë„ ìœ„í—˜ ì¦ê°€, ìŒìˆ˜ = ë¶€ë„ ìœ„í—˜ ê°ì†Œ)\")\n",
    "print(\"   - ìƒ‰ìƒ: íŠ¹ì„± ê°’ (ë¹¨ê°• = ë†’ìŒ, íŒŒë‘ = ë‚®ìŒ)\")\n",
    "print(\"   - ì˜ˆ: ë¶€ì±„ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡(ë¹¨ê°•) ë¶€ë„ ìœ„í—˜ ì¦ê°€(ì–‘ì˜ SHAP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Top 10 íŠ¹ì„± ì¬ë¬´ í•´ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 íŠ¹ì„± ì¶”ì¶œ\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "feature_ranking = pd.DataFrame({\n",
    "    'feature': X_test.columns,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "top10_features = feature_ranking.head(10)\n",
    "\n",
    "print(\"ğŸ“Š Top 10 ì¤‘ìš” íŠ¹ì„± (SHAP ê¸°ë°˜)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'ìˆœìœ„':<5} {'íŠ¹ì„±ëª…':<40} {'ì¤‘ìš”ë„':<10}\")\n",
    "print(\"-\"*70)\n",
    "for idx, row in top10_features.iterrows():\n",
    "    rank = top10_features.index.get_loc(idx) + 1\n",
    "    print(f\"{rank:<5} {row['feature']:<40} {row['importance']:<10.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Top 10 íŠ¹ì„± ì¬ë¬´ í•´ì„ (ìˆ˜ë™ìœ¼ë¡œ ì‘ì„± ê¶Œì¥)\nprint(\"\\nğŸ’¼ Top 10 íŠ¹ì„± ì¬ë¬´ í•´ì„\")\nprint(\"=\"*70)\n\n# ì¼ë°˜ì ì¸ ì¬ë¬´ íŠ¹ì„± í•´ì„ í…œí”Œë¦¿ (ì‹¤ì œ íŠ¹ì„± ì´ë¦„ê³¼ ë§¤ì¹­ í•„ìš”)\n# âš ï¸ ì£¼ì˜: ì•„ë˜ëŠ” ì˜ˆì‹œì´ë©°, ì‹¤ì œ Top 10 íŠ¹ì„± ì´ë¦„ì— ë§ê²Œ ìˆ˜ì •í•´ì•¼ í•¨\ninterpretations = {\n    'ì‹ ìš©ë“±ê¸‰ì ìˆ˜': {\n        'meaning': 'ì‹ ìš©í‰ê°€ì‚¬ì˜ ì¢…í•© í‰ê°€',\n        'risk': 'ë‚®ì„ìˆ˜ë¡ ë¶€ë„ ìœ„í—˜ ì¦ê°€',\n        'warning': 'âš ï¸ Data Leakage ê°€ëŠ¥ì„± - ì‹ ìš©ë“±ê¸‰ì´ ì´ë¯¸ ë¶€ë„ ì •ë³´ ë°˜ì˜í–ˆì„ ìˆ˜ ìˆìŒ'\n    },\n    'ë¶€ì±„ë¹„ìœ¨': {\n        'meaning': 'ìê¸°ìë³¸ ëŒ€ë¹„ ë¶€ì±„ ë¹„ìœ¨',\n        'risk': '200% ì´ìƒ ì‹œ ì¬ë¬´ ì•ˆì •ì„± ìš°ë ¤',\n        'action': 'ê³ ë¶€ì±„ ê¸°ì—…ì€ ë‹´ë³´ ê°•í™” í•„ìˆ˜'\n    },\n    'ìœ ë™ë¹„ìœ¨': {\n        'meaning': 'ë‹¨ê¸° ì±„ë¬´ ìƒí™˜ ëŠ¥ë ¥',\n        'risk': '100% ë¯¸ë§Œ ì‹œ ìœ ë™ì„± ìœ„ê¸°',\n        'action': 'ìš´ì „ìë³¸ ëª¨ë‹ˆí„°ë§ ê°•í™”'\n    },\n    'ì´ìë³´ìƒë°°ìœ¨': {\n        'meaning': 'ì˜ì—…ì´ìµìœ¼ë¡œ ì´ì ì§€ê¸‰ ê°€ëŠ¥ ì—¬ë¶€',\n        'risk': '1 ë¯¸ë§Œ ì‹œ ì´ìë„ ëª» ê°šëŠ” ìƒíƒœ',\n        'action': 'ì¦‰ì‹œ ëŒ€ì¶œ ê±°ì ˆ'\n    },\n    'ROA': {\n        'meaning': 'ì´ìì‚° ëŒ€ë¹„ ìˆ˜ìµì„±',\n        'risk': 'ìŒìˆ˜ ì‹œ ì ì ê¸°ì—…',\n        'action': 'ìˆ˜ìµì„± ê°œì„  ê³„íš í™•ì¸'\n    }\n}\n\nfor idx, row in top10_features.iterrows():\n    rank = top10_features.index.get_loc(idx) + 1\n    feat_name = row['feature']\n    \n    print(f\"\\n{rank}. {feat_name} (SHAP Importance: {row['importance']:.4f})\")\n    \n    if feat_name in interpretations:\n        interp = interpretations[feat_name]\n        print(f\"   ì¬ë¬´ ì˜ë¯¸: {interp['meaning']}\")\n        print(f\"   ìœ„í—˜ ê¸°ì¤€: {interp['risk']}\")\n        if 'action' in interp:\n            print(f\"   ì‹¤ë¬´ ì•¡ì…˜: {interp['action']}\")\n        if 'warning' in interp:\n            print(f\"   {interp['warning']}\")\n    else:\n        print(f\"   ğŸ“– [Part 2 íŠ¹ì„±ê³µí•™ ë¬¸ì„œ ì°¸ì¡°]\")\n        print(f\"      â†’ docs/notebook_summaries/02_íŠ¹ì„±ê³µí•™/ ë””ë ‰í† ë¦¬\")\n        print(f\"      â†’ ê° ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì„± ì„¤ëª… í™•ì¸\")\n\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 False Negative ì¼€ì´ìŠ¤ ë¶„ì„ âš ï¸\n",
    "\n",
    "ëª¨ë¸ì´ ë†“ì¹œ ë¶€ë„ ê¸°ì—…(FN)ì„ ë¶„ì„í•˜ì—¬ ê°œì„  ë°©í–¥ì„ ì°¾ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Negative ì¼€ì´ìŠ¤ ì¶”ì¶œ\n",
    "fn_mask = (y_test == 1) & (y_test_pred == 0)\n",
    "fn_indices = np.where(fn_mask)[0]\n",
    "\n",
    "print(f\"ğŸ“Š False Negative ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ì „ì²´ FN ê±´ìˆ˜: {len(fn_indices)}\")\n",
    "print(f\"Type II Error: {len(fn_indices) / y_test.sum():.2%}\")\n",
    "print(\"\\nâš ï¸ ëª¨ë¸ì´ ë†“ì¹œ ë¶€ë„ ê¸°ì—… = ê°€ì¥ í° ë¦¬ìŠ¤í¬\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# FN ì¼€ì´ìŠ¤ ì¤‘ í™•ë¥ ì´ ë‚®ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ê°€ì¥ ì˜ëª» ì˜ˆì¸¡í•œ ì¼€ì´ìŠ¤)\n",
    "fn_probs = y_test_prob[fn_indices]\n",
    "fn_sorted_idx = np.argsort(fn_probs)[:10]  # ìƒìœ„ 10ê°œ\n",
    "\n",
    "print(f\"\\nğŸ“Œ ê°€ì¥ ì˜ëª» ì˜ˆì¸¡í•œ FN ì¼€ì´ìŠ¤ (ìƒìœ„ 10ê°œ):\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'ìˆœìœ„':<5} {'ì¸ë±ìŠ¤':<10} {'ì˜ˆì¸¡í™•ë¥ ':<12} {'ì‹¤ì œ':<10} {'íŠ¹ì´ì‚¬í•­'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for rank, idx in enumerate(fn_sorted_idx, 1):\n",
    "    global_idx = fn_indices[idx]\n",
    "    prob = fn_probs[idx]\n",
    "    print(f\"{rank:<5} {global_idx:<10} {prob:<12.4f} {'ë¶€ë„':<10} ë§¤ìš° ë‚®ì€ í™•ë¥ \")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FN ì¼€ì´ìŠ¤ ìƒì„¸ ë¶„ì„ (ìƒ˜í”Œ ì¼€ì´ìŠ¤)\n",
    "if len(fn_indices) > 0:\n",
    "    # ê°€ì¥ ë‚®ì€ í™•ë¥ ë¡œ ì˜ˆì¸¡í•œ FN ì¼€ì´ìŠ¤\n",
    "    worst_fn_idx = fn_indices[np.argmin(fn_probs)]\n",
    "    \n",
    "    print(f\"\\nğŸ” ìµœì•…ì˜ FN ì¼€ì´ìŠ¤ ìƒì„¸ ë¶„ì„ (Index: {worst_fn_idx})\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"ì‹¤ì œ: ë¶€ë„, ì˜ˆì¸¡ í™•ë¥ : {y_test_prob[worst_fn_idx]:.4f} (ì„ê³„ê°’: {metadata['selected_threshold']:.4f})\")\n",
    "    print(f\"\\nì£¼ìš” íŠ¹ì„± ê°’:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    case_features = X_test.iloc[worst_fn_idx]\n",
    "    \n",
    "    # Top 10 íŠ¹ì„±ë§Œ ì¶œë ¥\n",
    "    for feat in top10_features['feature'].head(10):\n",
    "        val = case_features[feat]\n",
    "        mean_val = X_test[feat].mean()\n",
    "        std_val = X_test[feat].std()\n",
    "        z_score = (val - mean_val) / (std_val + 1e-10)\n",
    "        \n",
    "        print(f\"   {feat:<40}: {val:>10.4f} (Z-score: {z_score:>6.2f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ’¡ í•´ì„:\")\n",
    "    print(\"   - Z-score > 2: ë§¤ìš° ë†’ìŒ (ìƒìœ„ 2.5%)\")\n",
    "    print(\"   - Z-score < -2: ë§¤ìš° ë‚®ìŒ (í•˜ìœ„ 2.5%)\")\n",
    "    print(\"   - ë¶€ë„ ê¸°ì—…ì¸ë°ë„ ì£¼ìš” ì§€í‘œê°€ í‰ê·  ìˆ˜ì¤€ì´ë©´ â†’ ë°ì´í„° ì™¸ ìš”ì¸ ì˜ì‹¬\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\nâœ… FNì´ ì—†ìŠµë‹ˆë‹¤ (ì™„ë²½í•œ Recall)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FN ì¼€ì´ìŠ¤ì˜ SHAP Force Plot (ìƒ˜í”Œ)\n",
    "if len(fn_indices) > 0 and worst_fn_idx in sample_indices:\n",
    "    sample_idx = np.where(sample_indices == worst_fn_idx)[0][0]\n",
    "    \n",
    "    print(\"\\nğŸ” SHAP Force Plot (ìµœì•…ì˜ FN ì¼€ì´ìŠ¤)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    shap.force_plot(\n",
    "        explainer.expected_value if not isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value[1],\n",
    "        shap_values[sample_idx],\n",
    "        X_test_sample.iloc[sample_idx],\n",
    "        matplotlib=True,\n",
    "        show=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Force Plot í•´ì„:\")\n",
    "    print(\"   - ë¹¨ê°•: ë¶€ë„ ìœ„í—˜ ì¦ê°€ ë°©í–¥\")\n",
    "    print(\"   - íŒŒë‘: ì •ìƒ ë°©í–¥ (ë¶€ë„ ìœ„í—˜ ê°ì†Œ)\")\n",
    "    print(\"   - ì´ ì¼€ì´ìŠ¤ëŠ” íŒŒë‘ì´ ìš°ì„¸ â†’ ëª¨ë¸ì´ ì •ìƒìœ¼ë¡œ íŒë‹¨í–ˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ë¶€ë„\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ FN ì¼€ì´ìŠ¤ê°€ ìƒ˜í”Œì— í¬í•¨ë˜ì§€ ì•Šì•„ Force Plot ìƒëµ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Section 3 ì™„ë£Œ\n",
    "\n",
    "**ì™„ë£Œ ì‚¬í•­:**\n",
    "- âœ… SHAP Values ê³„ì‚° (TreeExplainer)\n",
    "- âœ… Global Feature Importance (Bar Plot)\n",
    "- âœ… Beeswarm Plot (íŠ¹ì„±ë³„ ì˜í–¥ ë°©í–¥)\n",
    "- âœ… Top 10 íŠ¹ì„± ì¬ë¬´ í•´ì„\n",
    "- âœ… False Negative ì¼€ì´ìŠ¤ ë¶„ì„\n",
    "- âœ… SHAP Force Plot (ìµœì•…ì˜ FN ì¼€ì´ìŠ¤)\n",
    "\n",
    "**ë‹¤ìŒ ë‹¨ê³„:**\n",
    "- Section 4: Traffic Light ì‹œìŠ¤í…œ ê²€ì¦\n",
    "- Section 5: ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì‹œë®¬ë ˆì´ì…˜\n",
    "- Section 6: í•œê³„ ë° ê°œì„  ë°©í–¥ (ëŒ€í­ ê°•í™”)\n",
    "- Section 7: ìµœì¢… ìš”ì•½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Traffic Light ì‹œìŠ¤í…œ ê²€ì¦\n",
    "\n",
    "### 4.1 ìœ„í—˜ë„ ë¶„ë¥˜ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Light ë¶„ë¥˜ í•¨ìˆ˜\n",
    "def assign_traffic_light(prob, red_th, yellow_th):\n",
    "    \"\"\"í™•ë¥ ì— ë”°ë¼ Red/Yellow/Green ë¶„ë¥˜\"\"\"\n",
    "    if prob >= red_th:\n",
    "        return 'Red'\n",
    "    elif prob >= yellow_th:\n",
    "        return 'Yellow'\n",
    "    else:\n",
    "        return 'Green'\n",
    "\n",
    "# Test Setì— ì ìš©\n",
    "red_threshold = metadata['red_threshold']\n",
    "yellow_threshold = metadata['yellow_threshold']\n",
    "\n",
    "test_traffic_light = [assign_traffic_light(p, red_threshold, yellow_threshold) for p in y_test_prob]\n",
    "\n",
    "print(f\"ğŸš¦ Traffic Light ì„ê³„ê°’ (Validation Setì—ì„œ ê²°ì •)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸ”´ Red Threshold:    {red_threshold:.4f}  (Recall 80% ë³´ì¥ ëª©í‘œ)\")\n",
    "print(f\"ğŸŸ¡ Yellow Threshold: {yellow_threshold:.4f}  (Recall 95% ë³´ì¥ ëª©í‘œ)\")\n",
    "print(f\"ğŸŸ¢ Green:            < {yellow_threshold:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test Set ìœ„í—˜ë„ë³„ í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set ìœ„í—˜ë„ë³„ í†µê³„\n",
    "test_df = pd.DataFrame({\n",
    "    'actual': y_test.values,\n",
    "    'prob': y_test_prob,\n",
    "    'traffic_light': test_traffic_light\n",
    "})\n",
    "\n",
    "traffic_stats = test_df.groupby('traffic_light').agg({\n",
    "    'actual': ['count', 'sum', 'mean']\n",
    "}).round(4)\n",
    "\n",
    "traffic_stats.columns = ['ê¸°ì—… ìˆ˜', 'ì‹¤ì œ ë¶€ë„', 'ë¶€ë„ìœ¨']\n",
    "traffic_stats = traffic_stats.reindex(['Red', 'Yellow', 'Green'])\n",
    "\n",
    "print(\"\\nğŸ“Š Traffic Light ì‹œìŠ¤í…œ ì„±ëŠ¥ (Test Set)\")\n",
    "print(\"=\"*70)\n",
    "print(traffic_stats)\n",
    "print(\"=\"*70)\n",
    "\n",
    "# í¬ì°©ë¥  ê³„ì‚°\n",
    "total_bankrupts = y_test.sum()\n",
    "red_bankrupts = test_df[test_df['traffic_light'] == 'Red']['actual'].sum()\n",
    "red_yellow_bankrupts = test_df[test_df['traffic_light'].isin(['Red', 'Yellow'])]['actual'].sum()\n",
    "\n",
    "print(f\"\\nğŸ“Œ ë¦¬ìŠ¤í¬ í¬ì°©ë¥ :\")\n",
    "print(f\"   Redë§Œ:         {red_bankrupts}/{total_bankrupts} = {red_bankrupts/total_bankrupts:.2%}\")\n",
    "print(f\"   Red + Yellow:  {red_yellow_bankrupts}/{total_bankrupts} = {red_yellow_bankrupts/total_bankrupts:.2%}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Light ì‹œê°í™”\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('ìœ„í—˜ë„ë³„ ê¸°ì—… ìˆ˜', 'ìœ„í—˜ë„ë³„ ì‹¤ì œ ë¶€ë„ìœ¨'),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "colors = {'Red': '#e74c3c', 'Yellow': '#f39c12', 'Green': '#2ecc71'}\n",
    "categories = ['Red', 'Yellow', 'Green']\n",
    "\n",
    "# ê¸°ì—… ìˆ˜\n",
    "counts = [traffic_stats.loc[c, 'ê¸°ì—… ìˆ˜'] for c in categories]\n",
    "fig.add_trace(\n",
    "    go.Bar(x=categories, y=counts, \n",
    "           marker_color=[colors[c] for c in categories],\n",
    "           text=[f\"{int(v):,}\" for v in counts],\n",
    "           textposition='auto',\n",
    "           showlegend=False),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# ë¶€ë„ìœ¨\n",
    "bankruptcy_rates = [traffic_stats.loc[c, 'ë¶€ë„ìœ¨'] * 100 for c in categories]\n",
    "fig.add_trace(\n",
    "    go.Bar(x=categories, y=bankruptcy_rates,\n",
    "           marker_color=[colors[c] for c in categories],\n",
    "           text=[f\"{v:.2f}%\" for v in bankruptcy_rates],\n",
    "           textposition='auto',\n",
    "           showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Traffic Light ì‹œìŠ¤í…œ ì„±ëŠ¥ (Test Set)',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text='ê¸°ì—… ìˆ˜', row=1, col=1)\n",
    "fig.update_yaxes(title_text='ë¶€ë„ìœ¨ (%)', row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.3 Yellow Threshold ê²€ì¦: Recall 95% ë‹¬ì„± í™•ì¸ â­"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Yellow Threshold ì´ìƒ ì˜ˆì¸¡ì˜ ì‹¤ì œ Recall ê³„ì‚°\nprint(\"ğŸ¯ Yellow Threshold Recall 95% ê²€ì¦\")\nprint(\"=\"*70)\n\n# Yellow threshold ì´ìƒìœ¼ë¡œ ì˜ˆì¸¡ëœ ì¼€ì´ìŠ¤\nyellow_or_red_pred = (y_test_prob >= yellow_threshold).astype(int)\n\n# ì‹¤ì œ Recall ê³„ì‚°\nactual_recall = recall_score(y_test, yellow_or_red_pred)\n\nprint(f\"\\nëª©í‘œ: Recall >= 95%\")\nprint(f\"ì‹¤ì œ: Recall = {actual_recall:.2%}\")\nprint(f\"ì°¨ì´: {actual_recall - 0.95:.2%}\")\n\nif actual_recall >= 0.95:\n    print(f\"\\nâœ… Yellow Thresholdê°€ ëª©í‘œ Recall 95%ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!\")\n    print(f\"   â†’ Yellow + Red Zoneìœ¼ë¡œ ë¶„ë¥˜í•˜ë©´ ë¶€ë„ì˜ {actual_recall:.0%} í¬ì°©\")\nelif actual_recall >= 0.90:\n    print(f\"\\nâš ï¸ Yellow Thresholdê°€ Recall 90~95% ë²”ìœ„ì…ë‹ˆë‹¤.\")\n    print(f\"   â†’ ëª©í‘œì— ê·¼ì ‘í–ˆì§€ë§Œ ì¶”ê°€ ì¡°ì • ê³ ë ¤ ê°€ëŠ¥\")\nelse:\n    print(f\"\\nâŒ Yellow Thresholdê°€ Recall 95% ë¯¸ë‹¬ì…ë‹ˆë‹¤.\")\n    print(f\"   â†’ Threshold ì¬ì¡°ì • í•„ìš” (ë” ë‚®ì¶°ì•¼ í•¨)\")\n\nprint(\"=\"*70)\n\n# Red only Recallë„ ê³„ì‚°\nred_only_pred = (y_test_prob >= red_threshold).astype(int)\nred_recall = recall_score(y_test, red_only_pred)\n\nprint(f\"\\nğŸ“Š Thresholdë³„ Recall ë¹„êµ:\")\nprint(f\"   Redë§Œ (>= {red_threshold:.4f}):        Recall {red_recall:.2%}\")\nprint(f\"   Yellow+Red (>= {yellow_threshold:.4f}): Recall {actual_recall:.2%}\")\nprint(f\"   í–¥ìƒí­: {actual_recall - red_recall:.2%}p\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.4 ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ’¼ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ: Traffic Lightë³„ ì˜ì‚¬ê²°ì • ê·œì¹™\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "red_rate = traffic_stats.loc['Red', 'ë¶€ë„ìœ¨']\n",
    "yellow_rate = traffic_stats.loc['Yellow', 'ë¶€ë„ìœ¨']\n",
    "green_rate = traffic_stats.loc['Green', 'ë¶€ë„ìœ¨']\n",
    "\n",
    "print(f\"\\nğŸ”´ Red Zone (ê³ ìœ„í—˜) - ì‹¤ì œ ë¶€ë„ìœ¨: {red_rate:.2%}\")\n",
    "print(f\"   ì•¡ì…˜: ì¦‰ì‹œ ëŒ€ì¶œ ê±°ì ˆ\")\n",
    "print(f\"   ì˜ˆì™¸: ë‹´ë³´ê°€ ì¶©ë¶„í•œ ê²½ìš°ë§Œ ê²€í†  (ë‹´ë³´ë¹„ìœ¨ > 150%)\")\n",
    "print(f\"   ê·¼ê±°: ë¶€ë„ í™•ë¥ ì´ ë§¤ìš° ë†’ì•„ ì†ì‹¤ ìœ„í—˜ í¼\")\n",
    "\n",
    "print(f\"\\nğŸŸ¡ Yellow Zone (ì¤‘ìœ„í—˜) - ì‹¤ì œ ë¶€ë„ìœ¨: {yellow_rate:.2%}\")\n",
    "print(f\"   ì•¡ì…˜: ì¶”ê°€ ì‹¤ì‚¬ (Due Diligence) í•„ìˆ˜\")\n",
    "print(f\"   ì‹¤ì‚¬ í•­ëª©:\")\n",
    "print(f\"      â€¢ í˜„ì¥ ë°©ë¬¸ (ì¬ê³ , ì„¤ë¹„, ìš´ì˜ ì‹¤íƒœ í™•ì¸)\")\n",
    "print(f\"      â€¢ ê²½ì˜ì§„ ì¸í„°ë·° (ê²½ì˜ ê³„íš, í˜„ê¸ˆ íë¦„)\")\n",
    "print(f\"      â€¢ ì£¼ìš” ê±°ë˜ì²˜ í™•ì¸ (ë§¤ì¶œ ì•ˆì •ì„±)\")\n",
    "print(f\"      â€¢ ìµœê·¼ ë‰´ìŠ¤/ì†Œì†¡ ê²€ìƒ‰\")\n",
    "print(f\"   ìŠ¹ì¸ ì¡°ê±´: ë‹´ë³´ ë˜ëŠ” ë³´ì¦ì¸ í•„ìˆ˜, ê¸ˆë¦¬ ìƒí–¥ ì¡°ì •\")\n",
    "\n",
    "print(f\"\\nğŸŸ¢ Green Zone (ì €ìœ„í—˜) - ì‹¤ì œ ë¶€ë„ìœ¨: {green_rate:.2%}\")\n",
    "print(f\"   ì•¡ì…˜: ì¼ë°˜ í”„ë¡œì„¸ìŠ¤ë¡œ ì§„í–‰\")\n",
    "print(f\"   ì£¼ì˜: Greenì´ë¼ë„ ì •ê¸° ëª¨ë‹ˆí„°ë§ í•„ìš” (ë¶„ê¸°ë³„)\")\n",
    "print(f\"   í˜œíƒ: ìš°ëŒ€ ê¸ˆë¦¬ ê²€í†  ê°€ëŠ¥\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš ï¸ ì¤‘ìš”: Traffic LightëŠ” ì˜ì‚¬ê²°ì • ì§€ì› ë„êµ¬ì´ë©°, ìµœì¢… íŒë‹¨ì€ ì‹¬ì‚¬ì—­ì˜ ì „ë¬¸ì„± í•„ìš”\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì‹œë®¬ë ˆì´ì…˜\n",
    "\n",
    "### 5.1 ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ì‹œë‚˜ë¦¬ì˜¤ ê°€ì •\n# N_APPLICATIONS = 10000  # Section 1.5ì—ì„œ ì •ì˜ë¨\n# DEFAULT_RATE = 0.015  # Section 1.5ì—ì„œ ì •ì˜ë¨\nAVG_LOAN = AVG_LOAN_AMOUNT  # Section 1.5ì—ì„œ ì •ì˜í•œ ìƒìˆ˜ ì‚¬ìš©\n# DEFAULT_LOSS_RATE = 0.67  # Section 1.5ì—ì„œ ì •ì˜ë¨\n# INTEREST_RATE = 0.05  # Section 1.5ì—ì„œ ì •ì˜ë¨\n\nprint(\"ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì‹œë®¬ë ˆì´ì…˜\")\nprint(\"=\"*70)\nprint(f\"\\nğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ ê°€ì •:\")\nprint(f\"   - ì—°ê°„ ì‹¬ì‚¬ ê±´ìˆ˜:    {N_APPLICATIONS:,}\")\nprint(f\"   - ì˜ˆìƒ ë¶€ë„ìœ¨:       {DEFAULT_RATE:.2%}\")\nprint(f\"   - í‰ê·  ëŒ€ì¶œì•¡:       {AVG_LOAN:,}ì›\")\nprint(f\"   - ë¶€ë„ ì‹œ ì†ì‹¤ë¥ :    {DEFAULT_LOSS_RATE:.0%} (íšŒìˆ˜ìœ¨ {1-DEFAULT_LOSS_RATE:.0%})\")\nprint(f\"   - ì—° ì´ììœ¨:         {INTEREST_RATE:.1%}\")\nprint(\"=\"*70)\n\nexpected_defaults = int(N_APPLICATIONS * DEFAULT_RATE)\nprint(f\"\\nì˜ˆìƒ ë¶€ë„ ê±´ìˆ˜: {expected_defaults}ê±´\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Baseline (ëª¨ë¸ ë¯¸ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: ëª¨ë¸ ì—†ì´ ëª¨ë‘ ìŠ¹ì¸\n",
    "baseline_loss = expected_defaults * AVG_LOAN * DEFAULT_LOSS_RATE\n",
    "baseline_revenue = (N_APPLICATIONS - expected_defaults) * AVG_LOAN * INTEREST_RATE\n",
    "baseline_profit = baseline_revenue - baseline_loss\n",
    "\n",
    "print(\"\\nğŸ“Š Baseline (ëª¨ë¸ ë¯¸ì‚¬ìš© - ëª¨ë‘ ìŠ¹ì¸)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ì˜ˆìƒ ë¶€ë„ ê±´ìˆ˜:     {expected_defaults:,}ê±´\")\n",
    "print(f\"ë¶€ë„ ì†ì‹¤:          {baseline_loss/1e8:.1f}ì–µì›\")\n",
    "print(f\"ì´ì ìˆ˜ìµ:          {baseline_revenue/1e8:.1f}ì–µì›\")\n",
    "print(f\"ìˆœì´ìµ:             {baseline_profit/1e8:.1f}ì–µì›\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 With Model (Test Set ì„±ëŠ¥ ê¸°ë°˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set ì„±ëŠ¥ ë©”íŠ¸ë¦­\n",
    "recall = metadata['test_recall']\n",
    "precision = metadata['test_precision']\n",
    "\n",
    "# ëª¨ë¸ ì ìš© ì‹œ ì˜ˆìƒ ê²°ê³¼\n",
    "detected_defaults = int(expected_defaults * recall)\n",
    "missed_defaults = expected_defaults - detected_defaults\n",
    "\n",
    "# FP ê³„ì‚°: TP / Precision = TP + FP â†’ FP = TP / Precision - TP\n",
    "if precision > 0:\n",
    "    false_alarms = int(detected_defaults / precision - detected_defaults)\n",
    "else:\n",
    "    false_alarms = 0\n",
    "\n",
    "# ì†ìµ ê³„ì‚°\n",
    "model_loss = missed_defaults * AVG_LOAN * DEFAULT_LOSS_RATE\n",
    "opportunity_loss = false_alarms * AVG_LOAN * INTEREST_RATE\n",
    "approved = N_APPLICATIONS - detected_defaults - false_alarms\n",
    "model_revenue = approved * AVG_LOAN * INTEREST_RATE\n",
    "model_profit = model_revenue - model_loss\n",
    "\n",
    "print(\"\\nğŸ“Š With Model (Test Set ì„±ëŠ¥ ê¸°ë°˜)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ëª¨ë¸ ì„±ëŠ¥:\")\n",
    "print(f\"   - Recall:    {recall:.2%}\")\n",
    "print(f\"   - Precision: {precision:.2%}\")\n",
    "print(f\"\\nì˜ˆì¸¡ ê²°ê³¼:\")\n",
    "print(f\"   - íƒì§€ëœ ë¶€ë„ (TP):        {detected_defaults:,}ê±´\")\n",
    "print(f\"   - ë†“ì¹œ ë¶€ë„ (FN):          {missed_defaults:,}ê±´\")\n",
    "print(f\"   - ì˜¤íƒ (FP):               {false_alarms:,}ê±´\")\n",
    "print(f\"   - ìŠ¹ì¸ëœ ê¸°ì—…:             {approved:,}ê±´\")\n",
    "print(f\"\\nì†ìµ ê³„ì‚°:\")\n",
    "print(f\"   - ë¶€ë„ ì†ì‹¤ (FN):          {model_loss/1e8:.1f}ì–µì› âŒ\")\n",
    "print(f\"   - ê¸°íšŒ ì†ì‹¤ (FP):          {opportunity_loss/1e8:.1f}ì–µì› âš ï¸\")\n",
    "print(f\"   - ì´ì ìˆ˜ìµ (ìŠ¹ì¸ ê¸°ì—…):   {model_revenue/1e8:.1f}ì–µì› âœ…\")\n",
    "print(f\"   - ìˆœì´ìµ:                  {model_profit/1e8:.1f}ì–µì›\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 ê°œì„  íš¨ê³¼ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline vs Model ë¹„êµ\n",
    "improvement = model_profit - baseline_profit\n",
    "improvement_pct = (improvement / baseline_profit * 100) if baseline_profit != 0 else 0\n",
    "\n",
    "print(\"\\nğŸ“Š ê°œì„  íš¨ê³¼ ë¹„êµ\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'í•­ëª©':<30} {'Baseline':<20} {'With Model':<20} {'ê°œì„ '}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'ë¶€ë„ ì†ì‹¤':<30} {baseline_loss/1e8:<20.1f} {model_loss/1e8:<20.1f} {(baseline_loss-model_loss)/1e8:+.1f}ì–µì›\")\n",
    "print(f\"{'ê¸°íšŒ ì†ì‹¤':<30} {0:<20.1f} {opportunity_loss/1e8:<20.1f} {-opportunity_loss/1e8:+.1f}ì–µì›\")\n",
    "print(f\"{'ì´ì ìˆ˜ìµ':<30} {baseline_revenue/1e8:<20.1f} {model_revenue/1e8:<20.1f} {(model_revenue-baseline_revenue)/1e8:+.1f}ì–µì›\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'ìˆœì´ìµ':<30} {baseline_profit/1e8:<20.1f} {model_profit/1e8:<20.1f} {improvement/1e8:+.1f}ì–µì› ({improvement_pct:+.1f}%)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if improvement > 0:\n",
    "    print(f\"\\nâœ… ëª¨ë¸ ë„ì… ì‹œ ì—°ê°„ {improvement/1e8:.1f}ì–µì› ìˆœì´ìµ ì¦ê°€ ({improvement_pct:.1f}%)\")\n",
    "    print(f\"   - ë¶€ë„ ì†ì‹¤ ê°ì†Œ: {(baseline_loss - model_loss)/1e8:.1f}ì–µì›\")\n",
    "    print(f\"   - ê¸°íšŒ ì†ì‹¤ ë°œìƒ: {opportunity_loss/1e8:.1f}ì–µì›\")\n",
    "    print(f\"   â†’ ìˆœ íš¨ê³¼: {improvement/1e8:.1f}ì–µì› ê°œì„ \")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ í˜„ì¬ ì„±ëŠ¥ì—ì„œëŠ” ëª¨ë¸ ë„ì… ì‹œ {abs(improvement)/1e8:.1f}ì–µì› ì†ì‹¤\")\n",
    "    print(f\"   ì›ì¸: FPê°€ ë„ˆë¬´ ë§ì•„ ê¸°íšŒ ì†ì‹¤ì´ ë¶€ë„ ì†ì‹¤ ê°ì†Œë¥¼ ìƒì‡„\")\n",
    "    print(f\"   ê°œì„  ë°©ì•ˆ: Threshold ì¡°ì • ë˜ëŠ” Yellow Zone í™œìš© ê°•í™”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”: Baseline vs Model\n",
    "categories = ['Baseline', 'With Model']\n",
    "losses = [baseline_loss/1e8, (model_loss + opportunity_loss)/1e8]\n",
    "revenues = [baseline_revenue/1e8, model_revenue/1e8]\n",
    "profits = [baseline_profit/1e8, model_profit/1e8]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=categories,\n",
    "    y=[-l for l in losses],\n",
    "    name='ì†ì‹¤',\n",
    "    marker_color='#e74c3c',\n",
    "    text=[f\"-{l:.1f}ì–µ\" for l in losses],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=categories,\n",
    "    y=revenues,\n",
    "    name='ì´ì ìˆ˜ìµ',\n",
    "    marker_color='#2ecc71',\n",
    "    text=[f\"+{r:.1f}ì–µ\" for r in revenues],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=categories,\n",
    "    y=profits,\n",
    "    name='ìˆœì´ìµ',\n",
    "    mode='lines+markers+text',\n",
    "    marker=dict(size=15, color='#3498db'),\n",
    "    line=dict(width=3, color='#3498db'),\n",
    "    text=[f\"ìˆœì´ìµ: {p:.1f}ì–µ\" for p in profits],\n",
    "    textposition='top center'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì‹œë®¬ë ˆì´ì…˜ (ì—°ê°„ {N_APPLICATIONS:,}ê±´ ì‹¬ì‚¬ ê¸°ì¤€)',\n",
    "    barmode='relative',\n",
    "    yaxis_title='ê¸ˆì•¡ (ì–µì›)',\n",
    "    height=600,\n",
    "    legend=dict(x=0.7, y=1)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. í•œê³„ ë° ê°œì„  ë°©í–¥ (ëŒ€í­ ê°•í™”) âš ï¸\n",
    "\n",
    "### 6.1 ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"âš ï¸ í•œê³„ 1: ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ\")\nprint(\"=\"*70)\nprint(\"\\në¬¸ì œ:\")\nprint(\"   - 63.7% ê¸°ì—…ì´ í˜„ê¸ˆ = 0ìœ¼ë¡œ ê¸°ë¡\")\nprint(\"   - ì¬ê³ ìì‚°, ë§¤ì¶œì±„ê¶Œ ë“±ë„ ìœ ì‚¬í•œ ë¬¸ì œ\")\nprint(\"   - ì›ë³¸ ë°ì´í„° ì¶œì²˜: [í™•ì¸ í•„ìš”]\")\nprint(\"\\nì›ì¸ ì¶”ì •:\")\nprint(\"   1. ì¤‘ì†Œê¸°ì—… íšŒê³„ ì‹œìŠ¤í…œ ë¯¸ë¹„\")\nprint(\"   2. ì‹¤ì œ í˜„ê¸ˆ ë¶€ì¡± vs ê¸°ë¡ ëˆ„ë½ êµ¬ë¶„ ë¶ˆê°€\")\nprint(\"   3. ê°„í¸ ì¥ë¶€ ê¸°ì¥ (ë³µì‹ë¶€ê¸° ë¯¸ì ìš©)\")\nprint(\"   4. ì˜ì„¸ ê¸°ì—…ì˜ ê²½ìš° ì¬ë¬´ì œí‘œ ì‹ ë¢°ë„ ë‚®ìŒ\")\nprint(\"\\ní˜„ì¬ ëŒ€ì‘:\")\nprint(\"   - Binary feature 'í˜„ê¸ˆë³´ìœ ì—¬ë¶€' ì¶”ê°€\")\nprint(\"   - Robust í†µê³„ëŸ‰ ì‚¬ìš© (median, IQR)\")\nprint(\"   - Winsorizer ì‹¤í—˜ ì™„ë£Œ: ì„±ëŠ¥ ì°¨ì´ < 0.5%p, ë¯¸ì‚¬ìš© ê²°ì •\")\nprint(\"\\ní–¥í›„ ê°œì„ :\")\nprint(\"   1. ì›ë³¸ ë°ì´í„° ì¶œì²˜ í™•ì¸ ë° ê²€ì¦\")\nprint(\"   2. ì™¸ë¶€ ë°ì´í„° ê²°í•© (ê¸ˆìœµê°ë…ì›, êµ­ì„¸ì²­ ì‚¬ì—…ì ë°ì´í„°)\")\nprint(\"   3. ë°ì´í„° í’ˆì§ˆ ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ êµ¬ì¶•\")\nprint(\"   4. ë°ì´í„° ì‹ ë¢°ë„ë¥¼ ëª¨ë¸ ì…ë ¥ìœ¼ë¡œ í™œìš©\")\nprint(\"   5. ì™¸ê° ê¸°ì—…ê³¼ ë¹„ì™¸ê° ê¸°ì—… ë³„ë„ ëª¨ë¸ ê°œë°œ\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ì‹œê³„ì—´ ì •ë³´ ë¶€ì¡±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš ï¸ í•œê³„ 2: ì‹œê³„ì—´ ì •ë³´ ë¶€ì¡±\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\ní•œê³„:\")\n",
    "print(\"   - 2021ë…„ 8ì›” ë‹¨ì¼ ì‹œì  ìŠ¤ëƒ…ìƒ· ë°ì´í„°\")\n",
    "print(\"   - ì¬ë¬´ ì•…í™” ì†ë„, ì¶”ì„¸ íŒŒì•… ë¶ˆê°€\")\n",
    "print(\"   - 'ê°‘ìê¸°' ë¶€ë„ë‚œ ê¸°ì—… íƒì§€ ì–´ë ¤ì›€\")\n",
    "print(\"\\nImpact:\")\n",
    "print(f\"   - ê¸‰ê²©íˆ ì•…í™”ë˜ëŠ” ê¸°ì—… ë†“ì¹  ìˆ˜ ìˆìŒ\")\n",
    "print(f\"   - Type II Error {metadata['test_type_ii_error']:.2%}ì— ê¸°ì—¬í•˜ëŠ” ì£¼ìš” ìš”ì¸\")\n",
    "print(f\"   - ê³„ì ˆì„± íš¨ê³¼ ë°˜ì˜ ë¶ˆê°€\")\n",
    "print(f\"   - ê²½ê¸° ì‚¬ì´í´ ì˜í–¥ íŒŒì•… ë¶ˆê°€\")\n",
    "print(\"\\ní–¥í›„ ê°œì„ :\")\n",
    "print(\"   1. ë¶„ê¸°ë³„ ë°ì´í„° í™•ë³´ (ìµœì†Œ 2ë…„ì¹˜)\")\n",
    "print(\"   2. ë³€í™”ìœ¨ íŠ¹ì„± ì¶”ê°€:\")\n",
    "print(\"      â€¢ ë§¤ì¶œ ì¦ê°€ìœ¨ (YoY, QoQ)\")\n",
    "print(\"      â€¢ ë¶€ì±„ ì¦ê°€ìœ¨\")\n",
    "print(\"      â€¢ ìš´ì „ìë³¸ ë³€í™”ìœ¨\")\n",
    "print(\"      â€¢ ì‹ ìš©ë“±ê¸‰ ë³€í™” ì¶”ì´\")\n",
    "print(\"   3. LSTM/Transformer ê¸°ë°˜ ì‹œê³„ì—´ ëª¨ë¸ ê²€í† \")\n",
    "print(\"   4. ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ (ì¬ë¬´ ì•…í™” ê°€ì†ë„ íƒì§€)\")\n",
    "print(\"   5. Rolling window ê¸°ë°˜ ë™ì  ëª¨ë¸ ì¬í•™ìŠµ\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 ëª¨ë¸ ì„±ëŠ¥ í•œê³„ (Type II Error ë¶„ì„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš ï¸ í•œê³„ 3: ëª¨ë¸ ì„±ëŠ¥ í•œê³„ (ê°€ì¥ ì‹¬ê°)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\ní˜„ì¬ ì„±ëŠ¥ (Test Set):\")\n",
    "print(f\"   - PR-AUC:        {metadata['test_pr_auc']:.4f} (95% CI: [{pr_auc_ci_low:.4f}, {pr_auc_ci_high:.4f}])\")\n",
    "print(f\"   - F2-Score:      {metadata['test_f2']:.4f}\")\n",
    "print(f\"   - Recall:        {metadata['test_recall']:.2%}\")\n",
    "print(f\"   - Precision:     {metadata['test_precision']:.2%}\")\n",
    "print(f\"   - Type II Error: {metadata['test_type_ii_error']:.2%} âŒâŒâŒ\")\n",
    "print(\"\\nğŸ“Œ í•µì‹¬ ë¬¸ì œ:\")\n",
    "print(f\"   ë¶€ë„ ê¸°ì—…ì˜ {metadata['test_type_ii_error']:.0%}ë¥¼ ë†“ì¹¨ (False Negative)\")\n",
    "print(f\"   â†’ ì—°ê°„ ì•½ {missed_defaults}ê±´ì˜ ë¶€ë„ë¥¼ ì‚¬ì „ ì°¨ë‹¨í•˜ì§€ ëª»í•¨\")\n",
    "print(f\"   â†’ ì˜ˆìƒ ì‹¤ì œ ì†ì‹¤: {model_loss/1e8:.1f}ì–µì›\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 ì›ì¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ” Type II Error ì›ì¸ ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nì›ì¸ 1: ë°ì´í„°ì— ì—†ëŠ” ì •ë³´\")\n",
    "print(\"   - ì†Œì†¡ ì§„í–‰ ìƒí™© (ë²•ì› ë°ì´í„°)\")\n",
    "print(\"   - ê²½ì˜ì§„ êµì²´/ë¹„ë¦¬ (ë‰´ìŠ¤, ê¸ˆìœµë‹¹êµ­ ì œì¬)\")\n",
    "print(\"   - ì£¼ìš” ê±°ë˜ì²˜ ë¶€ë„ (ì—°ì‡„ ë¶€ë„)\")\n",
    "print(\"   - ì—…ê³„ í™˜ê²½ ë³€í™” (ì‚°ì—… íŠ¸ë Œë“œ, ê·œì œ)\")\n",
    "print(\"   - ë…¸ì‚¬ ë¶„ê·œ (íŒŒì—… ë“±)\")\n",
    "print(\"   - ìì—°ì¬í•´/íŒ¬ë°ë¯¹ ì˜í–¥\")\n",
    "print(\"\\nì›ì¸ 2: ê·¹ë„ ë¶ˆê· í˜• (1:66)\")\n",
    "print(\"   - ì†Œìˆ˜ í´ë˜ìŠ¤(ë¶€ë„) í•™ìŠµ ì–´ë ¤ì›€\")\n",
    "print(\"   - SMOTEë¡œ ì¼ë¶€ ì™„í™”í–ˆìœ¼ë‚˜ ê·¼ë³¸ í•œê³„\")\n",
    "print(\"   - Class Weight ì¡°ì •ë„ ì‹œë„í–ˆìœ¼ë‚˜ ê³¼ì í•© ë°œìƒ\")\n",
    "print(\"   - ë¶€ë„ ì¼€ì´ìŠ¤ê°€ ë„ˆë¬´ ì ì–´ íŒ¨í„´ í•™ìŠµ ë¶ˆì¶©ë¶„\")\n",
    "print(\"\\nì›ì¸ 3: ì•™ìƒë¸” íš¨ê³¼ ì œí•œì \")\n",
    "print(\"   - ëª¨ë“  Tree ê¸°ë°˜ ëª¨ë¸ ì˜ˆì¸¡ ìœ ì‚¬ (ìƒê´€ > 0.95)\")\n",
    "print(\"   - ë‹¤ì–‘ì„± ì²´í¬ë¡œ ê°œì„  ì‹œë„í–ˆìœ¼ë‚˜ í•œê³„\")\n",
    "print(\"   - Meta-learner ê³¼ì í•© ë°œìƒ (Voting ì„ íƒ ì•ˆ í•¨)\")\n",
    "print(\"\\nì›ì¸ 4: íŠ¹ì´ ì¼€ì´ìŠ¤ (Outlier Bankruptcies)\")\n",
    "print(\"   - ì¬ë¬´ì œí‘œìƒ ê±´ì „í•´ ë³´ì´ì§€ë§Œ ìˆ¨ê²¨ì§„ ë¦¬ìŠ¤í¬\")\n",
    "print(\"   - íšŒê³„ ë¶„ì‹ ê°€ëŠ¥ì„± (íƒì§€ ì–´ë ¤ì›€)\")\n",
    "print(\"   - íŠ¹ìˆ˜ ì—…ì¢… ë¦¬ìŠ¤í¬ (ì¼ë°˜í™” ì–´ë ¤ì›€)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 ê°œì„  ë°©ì•ˆ (ë‹¨ê¸°/ì¤‘ê¸°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ’¡ ê°œì„  ë°©ì•ˆ\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ”¹ ë‹¨ê¸° (3ê°œì›”):\")\n",
    "print(\"   1. ì™¸ë¶€ ë°ì´í„° í†µí•©:\")\n",
    "print(\"      â€¢ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (ë¶€ì •ì  ê¸°ì‚¬ íƒì§€)\")\n",
    "print(\"      â€¢ ì†Œì†¡ ì´ë ¥ ë°ì´í„° (ë²•ì› API)\")\n",
    "print(\"      â€¢ ê²½ì˜ì§„ ì´ë ¥ ë°ì´í„° (ê³¼ê±° ë¶€ë„ ê¸°ì—… ì—°ë£¨ ì—¬ë¶€)\")\n",
    "print(\"      â€¢ SNS/ì˜¨ë¼ì¸ ë¦¬ë·° ê°ì„± ë¶„ì„\")\n",
    "print(\"\\n   2. ì•™ìƒë¸” ë‹¤ì–‘ì„± ì¦ëŒ€:\")\n",
    "print(\"      â€¢ Neural Network ì¶”ê°€ (TabNet, FT-Transformer)\")\n",
    "print(\"      â€¢ Linear Model + Tree Model ì¡°í•©\")\n",
    "print(\"      â€¢ Stacking Meta-learnerë¥¼ NNìœ¼ë¡œ ë³€ê²½\")\n",
    "print(\"\\n   3. Cost-sensitive Learning ê°•í™”:\")\n",
    "print(\"      â€¢ Focal Loss ì ìš© (ì–´ë ¤ìš´ ìƒ˜í”Œ ì§‘ì¤‘)\")\n",
    "print(\"      â€¢ FN ë¹„ìš©ì„ ë” ë†’ê²Œ ì„¤ì • (í˜„ì¬ 5ë°° â†’ 10ë°°)\")\n",
    "print(\"      â€¢ Custom Loss Function (FN penalty ì¦ê°€)\")\n",
    "print(\"\\nğŸ”¹ ì¤‘ê¸° (6ê°œì›”):\")\n",
    "print(\"   4. ì‹œê³„ì—´ ëª¨ë¸ ë„ì…:\")\n",
    "print(\"      â€¢ ë¶„ê¸°ë³„ ë°ì´í„° í™•ë³´\")\n",
    "print(\"      â€¢ LSTM/GRU ê¸°ë°˜ ì‹œí€€ìŠ¤ ëª¨ë¸\")\n",
    "print(\"      â€¢ ë³€í™”ìœ¨ íŠ¹ì„± ìë™ ìƒì„±\")\n",
    "print(\"      â€¢ Temporal Attention Mechanism\")\n",
    "print(\"\\n   5. Semi-supervised Learning:\")\n",
    "print(\"      â€¢ ë¶€ë„ ì§ì „ ê¸°ì—… ë ˆì´ë¸” í™œìš© (Label Spreading)\")\n",
    "print(\"      â€¢ Pseudo-labeling (ê³ í™•ë¥  ì˜ˆì¸¡ í™œìš©)\")\n",
    "print(\"      â€¢ Self-training\")\n",
    "print(\"\\n   6. Anomaly Detection í†µí•©:\")\n",
    "print(\"      â€¢ Isolation Forest (ì´ìƒ íŒ¨í„´ íƒì§€)\")\n",
    "print(\"      â€¢ Autoencoder (ì •ìƒ íŒ¨í„´ í•™ìŠµ â†’ ì´ìƒ íƒì§€)\")\n",
    "print(\"      â€¢ One-Class SVM\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 ì¼ë°˜í™” ê°€ëŠ¥ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš ï¸ í•œê³„ 4: ì¼ë°˜í™” ê°€ëŠ¥ì„± (ì‹œê°„ì /ê³µê°„ì )\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\ní•œê³„:\")\n",
    "print(\"   - 2021ë…„ ë°ì´í„° â†’ COVID-19 íŒ¬ë°ë¯¹ ì˜í–¥\")\n",
    "print(\"   - ì •ë¶€ ì§€ì›ê¸ˆìœ¼ë¡œ ìƒì¡´í•œ í•œê³„ ê¸°ì—… í¬í•¨ ê°€ëŠ¥\")\n",
    "print(\"   - ê¸ˆë¦¬ ìƒìŠ¹ê¸° vs í•˜ë½ê¸° ì˜í–¥ ë¯¸ë°˜ì˜\")\n",
    "print(\"   - ë‹¨ì¼ êµ­ê°€(í•œêµ­) ë°ì´í„°ë§Œ ì‚¬ìš©\")\n",
    "print(\"\\nìš°ë ¤:\")\n",
    "print(\"   - 2022-2023ë…„ì—ëŠ” ì´ë“¤ ê¸°ì—…ì´ ë¶€ë„ë‚  ê°€ëŠ¥ì„±\")\n",
    "print(\"   - ëª¨ë¸ì´ ì´ë¥¼ ë°˜ì˜í•˜ì§€ ëª»í•¨\")\n",
    "print(\"   - ê²½ì œ í™˜ê²½ ë³€í™” ì‹œ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥\")\n",
    "print(\"   - íƒ€êµ­ ì ìš© ì‹œ í•œêµ­ íŠ¹í™” íŠ¹ì„± ì¡°ì • í•„ìš”\")\n",
    "print(\"\\nê²€ì¦ ë°©ì•ˆ:\")\n",
    "print(\"   1. ì‹œê°„ì  ê²€ì¦ (Temporal Validation):\")\n",
    "print(\"      â€¢ 2022-2023 ë°ì´í„°ë¡œ ì¬í‰ê°€\")\n",
    "print(\"      â€¢ ì„±ëŠ¥ ìœ ì§€ ì—¬ë¶€ í™•ì¸\")\n",
    "print(\"      â€¢ Model Drift íƒì§€\")\n",
    "print(\"\\n   2. ê³µê°„ì  ê²€ì¦ (Spatial Validation):\")\n",
    "print(\"      â€¢ ë‹¤ë¥¸ êµ­ê°€ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"      â€¢ í•œêµ­ íŠ¹í™” íŠ¹ì„±ë§Œ ì œì™¸í•˜ê³  ì ìš©\")\n",
    "print(\"      â€¢ Transfer Learning ê°€ëŠ¥ì„± ê²€í† \")\n",
    "print(\"\\n   3. ê²½ì œ ì‚¬ì´í´ ê³ ë ¤:\")\n",
    "print(\"      â€¢ ê²½ê¸° ì§€í‘œ (GDP, ê¸ˆë¦¬, í™˜ìœ¨) ì¶”ê°€\")\n",
    "print(\"      â€¢ ì‹œê¸°ë³„ ëª¨ë¸ ì¬í•™ìŠµ ì „ëµ\")\n",
    "print(\"      â€¢ ê²½ì œ ìƒí™©ë³„ Dynamic Threshold\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 í•´ì„ ê°€ëŠ¥ì„± vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ’¡ í•œê³„ 5: í•´ì„ ê°€ëŠ¥ì„± vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\ní˜„ì¬ ì„ íƒ:\")\n",
    "print(\"   - ë„ë©”ì¸ íŠ¹ì„± ê¸°ë°˜ â†’ í•´ì„ ê°€ëŠ¥ì„± ìš°ì„ \")\n",
    "print(f\"   - Tree ê¸°ë°˜ ëª¨ë¸ ({metadata['final_model_name']}) â†’ SHAPìœ¼ë¡œ ì„¤ëª… ìš©ì´\")\n",
    "print(\"   - Pipeline êµ¬ì¡° â†’ ì¬í˜„ ê°€ëŠ¥ì„± ë†’ìŒ\")\n",
    "print(\"\\nTrade-off:\")\n",
    "print(\"   - Deep Learning ì‚¬ìš© ì‹œ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥ (ì˜ˆìƒ PR-AUC +0.02~0.03)\")\n",
    "print(\"   - í•˜ì§€ë§Œ ì„¤ëª… ì–´ë ¤ì›€ â†’ ì‹¤ë¬´ ì ìš© ì œí•œ\")\n",
    "print(\"   - Black-box ëª¨ë¸ì€ ê·œì œ ì´ìŠˆ ë°œìƒ ê°€ëŠ¥\")\n",
    "print(\"\\nê²°ì • ê·¼ê±°:\")\n",
    "print(\"   âœ… ê¸ˆìœµê¶Œ ì‹¤ë¬´ì—ì„œëŠ” ì„¤ëª… ê°€ëŠ¥ì„±ì´ í•„ìˆ˜\")\n",
    "print(\"      â€¢ ê·œì œ ìš”êµ¬ì‚¬í•­ (Basel III, AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸)\")\n",
    "print(\"      â€¢ ì‹¬ì‚¬ì—­ì´ 'ì™œ ê±°ì ˆí–ˆëŠ”ê°€?' ê³ ê°ì—ê²Œ ì„¤ëª…í•´ì•¼ í•¨\")\n",
    "print(\"      â€¢ ë‚´ë¶€ ê°ì‚¬ ë° ì™¸ë¶€ ê²€ì‚¬ ëŒ€ë¹„\")\n",
    "print(\"      â€¢ ë²•ì  ë¶„ìŸ ì‹œ ê·¼ê±° ì œì‹œ í•„ìš”\")\n",
    "print(\"\\n   âœ… ì‚¬ìš©ì ì‹ ë¢° í™•ë³´\")\n",
    "print(\"      â€¢ SHAPìœ¼ë¡œ ëª¨ë“  ì˜ˆì¸¡ ê·¼ê±° ì œì‹œ ê°€ëŠ¥\")\n",
    "print(\"      â€¢ ë„ë©”ì¸ ì „ë¬¸ê°€ê°€ ê²€ì¦ ê°€ëŠ¥í•œ ë¡œì§\")\n",
    "print(\"      â€¢ ì´ìƒ ì¼€ì´ìŠ¤ ë°œê²¬ ì‹œ ì›ì¸ íŒŒì•… ìš©ì´\")\n",
    "print(\"\\ní–¥í›„ ë°©í–¥:\")\n",
    "print(\"   - í•´ì„ ê°€ëŠ¥í•œ DL ëª¨ë¸ íƒìƒ‰ (TabNet, NODE, SAINT)\")\n",
    "print(\"   - Hybrid ì ‘ê·¼: DLë¡œ íŠ¹ì„± ì¶”ì¶œ + Treeë¡œ ë¶„ë¥˜\")\n",
    "print(\"   - ëª¨ë¸ ë…ë¦½ì  í•´ì„ ê¸°ë²• (LIME, Anchors) ì¶”ê°€ ì ìš©\")\n",
    "print(\"   - Counterfactual Explanation (ë°˜ì‚¬ì‹¤ì  ì„¤ëª…)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 ê·¸ëŸ¼ì—ë„ ê°€ì¹˜ ìˆëŠ” ì´ìœ  âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâœ… ê·¸ëŸ¼ì—ë„ ê°€ì¹˜ ìˆëŠ” ì´ìœ \")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n1. ë„ë©”ì¸ ë…¼ë¦¬ ëª…í™• âœ…\")\n",
    "print(\"   - ëª¨ë“  íŠ¹ì„±ì´ ì¬ë¬´ ì´ë¡  ê¸°ë°˜ (Altman, Beaver, Beneish)\")\n",
    "print(\"   - ê° íŠ¹ì„±ì˜ ì˜ë¯¸ë¥¼ ëª…í™•íˆ ì„¤ëª… ê°€ëŠ¥\")\n",
    "print(\"   - ì‹¤ë¬´ ì‹¬ì‚¬ì—­ì´ ë°”ë¡œ ì´í•´í•˜ê³  í™œìš© ê°€ëŠ¥\")\n",
    "print(\"   - ê·œì œ ë‹¹êµ­ ì„¤ëª… ìš©ì´\")\n",
    "print(\"\\n2. ì¬í˜„ ê°€ëŠ¥ ë° í™•ì¥ ê°€ëŠ¥ âœ…\")\n",
    "print(\"   - ë‹¤ë¥¸ ì—°ë„ ë°ì´í„°ì— ì¦‰ì‹œ ì ìš© ê°€ëŠ¥ (Pipeline ì¬ì‚¬ìš©)\")\n",
    "print(\"   - ë‹¤ë¥¸ êµ­ê°€ ì‹œì¥ì—ë„ í™•ì¥ ê°€ëŠ¥ (í•œêµ­ íŠ¹í™” íŠ¹ì„±ë§Œ ì œì™¸)\")\n",
    "print(\"   - ì „ì²´ íŒŒì´í”„ë¼ì¸ ìë™í™” ì™„ë£Œ\")\n",
    "print(\"   - Gitìœ¼ë¡œ ë²„ì „ ê´€ë¦¬ â†’ ì‹¤í—˜ ì¬í˜„ ë³´ì¥\")\n",
    "print(\"\\n3. í•´ì„ ê°€ëŠ¥í•œ AI âœ…\")\n",
    "print(\"   - SHAPìœ¼ë¡œ ëª¨ë“  ì˜ˆì¸¡ ê·¼ê±° ì œì‹œ\")\n",
    "print(\"   - Global + Local Explanation ì œê³µ\")\n",
    "print(\"   - ê·œì œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (AI ìœ¤ë¦¬)\")\n",
    "print(\"   - ì‚¬ìš©ì ì‹ ë¢° í™•ë³´\")\n",
    "print(\"\\n4. ì‹¤ìš©ì  ì„±ëŠ¥ í–¥ìƒ âœ…\")\n",
    "print(f\"   - Test PR-AUC: {metadata['test_pr_auc']:.4f} (95% CI: [{pr_auc_ci_low:.4f}, {pr_auc_ci_high:.4f}])\")\n",
    "print(f\"   - Recall: {metadata['test_recall']:.2%} (ë¶€ë„ì˜ {metadata['test_recall']:.0%} íƒì§€)\")\n",
    "if improvement > 0:\n",
    "    print(f\"   - ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜: ì—°ê°„ {improvement/1e8:.1f}ì–µì› ìˆœì´ìµ ì¦ê°€\")\n",
    "print(\"   - Traffic Light ì‹œìŠ¤í…œìœ¼ë¡œ ì˜ì‚¬ê²°ì • ê°„ì†Œí™”\")\n",
    "print(\"\\n5. í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ âœ…\")\n",
    "print(\"   - ì™¸ë¶€ ë°ì´í„° ì¶”ê°€ ìš©ì´ (Pipeline êµ¬ì¡°)\")\n",
    "print(\"   - ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ ê°€ëŠ¥ (Pipeline êµì²´ë§Œ)\")\n",
    "print(\"   - ì§€ì†ì  ê°œì„  ê°€ëŠ¥ (A/B í…ŒìŠ¤íŠ¸, Champion-Challenger)\")\n",
    "print(\"   - ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶• ìš©ì´\")\n",
    "print(\"\\n6. ê²¬ê³ í•œ ë°©ë²•ë¡  (Part 3 v2 ê°œì„ íŒ) âœ…\")\n",
    "print(\"   - Data Leakage ì™„ë²½ ë°©ì§€: 3-Way Split + Validation ê¸°ë°˜ ê²°ì •\")\n",
    "print(\"   - Pipeline êµ¬ì¡°: ë°°í¬ ì‹œ ì „ì²˜ë¦¬ ì˜¤ë¥˜ ë°©ì§€\")\n",
    "print(\"   - CV ê¸°ë°˜ Threshold: ë‹¨ì¼ split í¸í–¥ ë°©ì§€\")\n",
    "print(\"   - ì•™ìƒë¸” ë‹¤ì–‘ì„± ì²´í¬: ëª¨ë¸ ì„ íƒì˜ í•©ë¦¬ì„± í™•ë³´\")\n",
    "print(\"   - í†µê³„ì  ì—„ê²©ì„±: Bootstrap CI, Wilcoxon test ë“±\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ìµœì¢… ìš”ì•½ ë° ê²°ë¡ \n",
    "\n",
    "### 7.1 í”„ë¡œì íŠ¸ ì„±ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ í”„ë¡œì íŠ¸ ìµœì¢… ì„±ê³¼\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“Š ë‹¬ì„±í•œ ê²ƒ âœ…\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\n1. ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ íŠ¹ì„± ê³µí•™\")\n",
    "print(\"   âœ… 75ê°œ ì¬ë¬´ ì´ë¡  ê¸°ë°˜ íŠ¹ì„± ìƒì„± (Part 2)\")\n",
    "print(\"   âœ… í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ ì™„ë£Œ\")\n",
    "print(\"   âœ… 27ê°œ ìµœì¢… ì„ íƒ (VIF, IV, Correlation ê¸°ì¤€)\")\n",
    "\n",
    "print(\"\\n2. ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬\")\n",
    "print(\"   âœ… SMOTE + Tomek Links / Class Weight ëŒ€ì¡° ì‹¤í—˜\")\n",
    "print(\"   âœ… 1:66 ë¶ˆê· í˜• ë¹„ìœ¨ ì™„í™”\")\n",
    "print(\"   âœ… ë°ì´í„° ê¸°ë°˜ ì „ëµ ì„ íƒ\")\n",
    "\n",
    "print(\"\\n3. ê²¬ê³ í•œ ëª¨ë¸ë§ í”„ë¡œì„¸ìŠ¤ (Part 3 v2 ê°œì„ íŒ)\")\n",
    "print(\"   âœ… 3-Way Splitìœ¼ë¡œ Data Leakage ì™„ë²½ ë°©ì§€\")\n",
    "print(\"   âœ… Pipeline êµ¬ì¡°ë¡œ ë°°í¬ ì•ˆì •ì„± í™•ë³´\")\n",
    "print(\"   âœ… AutoML (n_iter=100~200) ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰\")\n",
    "print(\"   âœ… CV ê¸°ë°˜ robust threshold ì„ ì •\")\n",
    "print(\"   âœ… ì•™ìƒë¸” ë‹¤ì–‘ì„± ì²´í¬ (Wilcoxon test)\")\n",
    "\n",
    "print(f\"\\n4. Test Set ìµœì¢… ì„±ëŠ¥\")\n",
    "print(f\"   âœ… PR-AUC:        {metadata['test_pr_auc']:.4f} (95% CI: [{pr_auc_ci_low:.4f}, {pr_auc_ci_high:.4f}])\")\n",
    "print(f\"   âœ… F2-Score:      {metadata['test_f2']:.4f}\")\n",
    "print(f\"   âœ… Recall:        {metadata['test_recall']:.2%}\")\n",
    "print(f\"   âœ… Precision:     {metadata['test_precision']:.2%}\")\n",
    "\n",
    "print(\"\\n5. í•´ì„ ê°€ëŠ¥í•œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ\")\n",
    "print(\"   âœ… SHAP Global/Local Explanation\")\n",
    "print(\"   âœ… Traffic Light ì˜ì‚¬ê²°ì • ì§€ì›\")\n",
    "print(\"   âœ… ëª¨ë“  íŠ¹ì„±ì˜ ì¬ë¬´ì  ì˜ë¯¸ ëª…í™•\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 ì£¼ìš” í•œê³„ ë° ê°œì„  ë°©í–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš ï¸ ì£¼ìš” í•œê³„\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"\\n1. Type II Error {metadata['test_type_ii_error']:.2%} (ë¶€ë„ ê¸°ì—… ë†“ì¹¨)\")\n",
    "print(\"   ì›ì¸: ë°ì´í„° ì™¸ ì •ë³´ ë¶€ì¡±, ê·¹ë„ ë¶ˆê· í˜•\")\n",
    "print(\"   ê°œì„ : ì™¸ë¶€ ë°ì´í„°, ì‹œê³„ì—´ ëª¨ë¸, Cost-sensitive Learning\")\n",
    "\n",
    "print(\"\\n2. ì‹œê³„ì—´ ë°ì´í„° ë¶€ì¬\")\n",
    "print(\"   ìŠ¤ëƒ…ìƒ· ë°ì´í„° â†’ ì•…í™” ì†ë„ íŒŒì•… ë¶ˆê°€\")\n",
    "print(\"   ê°œì„ : ë¶„ê¸°ë³„ ë°ì´í„° í™•ë³´, LSTM/Transformer ë„ì…\")\n",
    "\n",
    "print(\"\\n3. ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ\")\n",
    "print(\"   63.7% ê¸°ì—…ì´ í˜„ê¸ˆ=0 ê¸°ë¡\")\n",
    "print(\"   ê°œì„ : ì™¸ë¶€ ë°ì´í„° ê²°í•©, í’ˆì§ˆ ê²€ì¦, ì™¸ê°/ë¹„ì™¸ê° ë³„ë„ ëª¨ë¸\")\n",
    "\n",
    "print(\"\\n4. ì¼ë°˜í™” ê°€ëŠ¥ì„± (2021 COVID-19 ì˜í–¥)\")\n",
    "print(\"   ê°œì„ : 2022-2023 ë°ì´í„°ë¡œ ì‹œê°„ì  ê²€ì¦, ê²½ê¸° ì§€í‘œ ì¶”ê°€\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 í–¥í›„ ë¡œë“œë§µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ›£ï¸ í–¥í›„ ë¡œë“œë§µ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“… Phase 1: ë°ì´í„° í™•ì¥ (3ê°œì›”)\")\n",
    "print(\"   - 2022-2023 ë°ì´í„° í™•ë³´\")\n",
    "print(\"   - ì™¸ë¶€ ë°ì´í„° í†µí•© (ë‰´ìŠ¤, ì†Œì†¡, ê²½ì˜ì§„ ì´ë ¥)\")\n",
    "print(\"   - ì‹œê³„ì—´ ë³€í™”ìœ¨ íŠ¹ì„± ì¶”ê°€\")\n",
    "\n",
    "print(\"\\nğŸ“… Phase 2: ëª¨ë¸ ê°œì„  (6ê°œì›”)\")\n",
    "print(\"   - ì‹œê³„ì—´ ëª¨ë¸ ë„ì… (LSTM/Transformer)\")\n",
    "print(\"   - ì•™ìƒë¸” ë‹¤ì–‘ì„± ì¦ëŒ€ (TabNet, NN ì¶”ê°€)\")\n",
    "print(\"   - Cost-sensitive Learning ê°•í™” (Focal Loss)\")\n",
    "print(\"   - Anomaly Detection í†µí•©\")\n",
    "\n",
    "print(\"\\nğŸ“… Phase 3: ì‹¤ë¬´ ë°°í¬ (9ê°œì›”)\")\n",
    "print(\"   - ì‹¤ì‹œê°„ ì˜ˆì¸¡ API ê°œë°œ\")\n",
    "print(\"   - ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶• (Model Drift íƒì§€)\")\n",
    "print(\"   - A/B í…ŒìŠ¤íŠ¸ (Champion-Challenger)\")\n",
    "print(\"   - ì„±ëŠ¥ ì¶”ì  ëŒ€ì‹œë³´ë“œ\")\n",
    "\n",
    "print(\"\\nğŸ“… Phase 4: ì§€ì† ê°œì„  (12ê°œì›”~)\")\n",
    "print(\"   - ì›”ë³„ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸\")\n",
    "print(\"   - í”¼ë“œë°± ë£¨í”„ (ì‹¤ì œ ë¶€ë„ vs ì˜ˆì¸¡)\")\n",
    "print(\"   - ëª¨ë¸ ë“œë¦¬í”„íŠ¸ ëŒ€ì‘\")\n",
    "print(\"   - ê²½ì œ ìƒí™©ë³„ Dynamic Threshold\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 ìµœì¢… ë©”ì‹œì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ’¡ ìµœì¢… ë©”ì‹œì§€\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\në³¸ í”„ë¡œì íŠ¸ëŠ” í•œêµ­ ê¸°ì—… ë¶€ë„ ì˜ˆì¸¡ì´ë¼ëŠ” ì–´ë ¤ìš´ ë¬¸ì œì— ëŒ€í•´\")\n",
    "print(\"ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ AI ì ‘ê·¼ë²•ì˜ ê°€ëŠ¥ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"\\nType II Error {metadata['test_type_ii_error']:.2%}ë¼ëŠ” ëª…í™•í•œ í•œê³„ê°€ ìˆì§€ë§Œ,\")\n",
    "print(\"ì´ëŠ” ë°ì´í„°ì™€ ë°©ë²•ë¡ ì˜ ê·¼ë³¸ì  ì œì•½ì—ì„œ ë¹„ë¡¯ëœ ê²ƒì´ë©°,\")\n",
    "print(\"ì†”ì§í•˜ê²Œ ì¸ì •í•˜ê³  êµ¬ì²´ì ì¸ ê°œì„  ë°©í–¥ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\në¬´ì—‡ë³´ë‹¤ ì¤‘ìš”í•œ ê²ƒì€:\")\n",
    "print(\"   1. ëª¨ë“  íŠ¹ì„±ê³¼ ì˜ˆì¸¡ì´ ì¬ë¬´ì ìœ¼ë¡œ ì„¤ëª… ê°€ëŠ¥\")\n",
    "print(\"   2. ì‹¤ë¬´ì—ì„œ ì¦‰ì‹œ í™œìš© ê°€ëŠ¥í•œ Traffic Light ì‹œìŠ¤í…œ\")\n",
    "print(\"   3. ë°ì´í„° ëˆ„ì¶œ ì—†ëŠ” ê²¬ê³ í•œ ê²€ì¦ ë°©ë²•ë¡ \")\n",
    "print(\"   4. ì§€ì†ì ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥í•œ í™•ì¥ì„± ìˆëŠ” í”„ë ˆì„ì›Œí¬\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(f\"\\nğŸ“ˆ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜:\")\n",
    "    print(f\"   ì—°ê°„ ì•½ {improvement/1e8:.1f}ì–µì›ì˜ ìˆœì´ìµ ì¦ê°€ íš¨ê³¼\")\n",
    "    print(f\"   (ì—°ê°„ {N_APPLICATIONS:,}ê±´ ì‹¬ì‚¬ ê¸°ì¤€)\")\n",
    "\n",
    "print(\"\\nğŸš€ ì´ í”„ë¡œì íŠ¸ëŠ” ì™„ì„±ì´ ì•„ë‹Œ ì‹œì‘ì…ë‹ˆë‹¤.\")\n",
    "print(\"   ì™¸ë¶€ ë°ì´í„° í†µí•©, ì‹œê³„ì—´ ëª¨ë¸, ì•™ìƒë¸” ë‹¤ì–‘ì„± ì¦ëŒ€ ë“±\")\n",
    "print(\"   ëª…í™•í•œ ë¡œë“œë§µì„ í†µí•´ ì§€ì†ì ìœ¼ë¡œ ì„±ëŠ¥ì„ ê°œì„ í•´ ë‚˜ê°ˆ ê²ƒì…ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ Part 1~4 ì „ì²´ ì—¬ì •ì„ í•¨ê»˜í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Part 4 ì™„ë£Œ\n",
    "\n",
    "**ì „ì²´ ì™„ë£Œ ì‚¬í•­:**\n",
    "\n",
    "### Section 1: Opening + Setup\n",
    "- âœ… Part 3 v2 ë©”íƒ€ë°ì´í„° ë¡œë”©\n",
    "- âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ë¡œë”©\n",
    "- âœ… Test ë°ì´í„° ë¡œë”© ë° ì˜ˆì¸¡\n",
    "\n",
    "### Section 2: Test Set ì„±ëŠ¥ í‰ê°€\n",
    "- âœ… Bootstrap 95% CI (PR-AUC, F2-Score)\n",
    "- âœ… Validation vs Test ì¼ë°˜í™” ì„±ëŠ¥ ë¹„êµ\n",
    "- âœ… Confusion Matrix ìƒì„¸ ë¶„ì„\n",
    "- âœ… ì¬ë¬´ì  í•´ì„ (TP/FN/FP/TN)\n",
    "\n",
    "### Section 3: SHAP ë¶„ì„\n",
    "- âœ… SHAP Values ê³„ì‚°\n",
    "- âœ… Global Feature Importance\n",
    "- âœ… Beeswarm Plot\n",
    "- âœ… Top 10 íŠ¹ì„± ì¬ë¬´ í•´ì„\n",
    "- âœ… False Negative ì¼€ì´ìŠ¤ ë¶„ì„\n",
    "\n",
    "### Section 4: Traffic Light ì‹œìŠ¤í…œ\n",
    "- âœ… ìœ„í—˜ë„ë³„ í†µê³„ (Red/Yellow/Green)\n",
    "- âœ… ì‹¤ì œ ë¶€ë„ìœ¨ ê²€ì¦\n",
    "- âœ… ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ\n",
    "\n",
    "### Section 5: ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜\n",
    "- âœ… Baseline vs Model ë¹„êµ\n",
    "- âœ… ì†ìµ ì‹œë®¬ë ˆì´ì…˜\n",
    "- âœ… ê°œì„  íš¨ê³¼ ì •ëŸ‰í™”\n",
    "\n",
    "### Section 6: í•œê³„ ë° ê°œì„  ë°©í–¥\n",
    "- âœ… ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ë¶„ì„\n",
    "- âœ… ì‹œê³„ì—´ ì •ë³´ ë¶€ì¡± ë¶„ì„\n",
    "- âœ… Type II Error ì›ì¸ ë¶„ì„ (ëŒ€í­ ê°•í™”)\n",
    "- âœ… ì¼ë°˜í™” ê°€ëŠ¥ì„± ê²€í† \n",
    "- âœ… í•´ì„ ê°€ëŠ¥ì„± vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„\n",
    "- âœ… ê·¸ëŸ¼ì—ë„ ê°€ì¹˜ ìˆëŠ” ì´ìœ \n",
    "\n",
    "### Section 7: ìµœì¢… ìš”ì•½\n",
    "- âœ… í”„ë¡œì íŠ¸ ì„±ê³¼ ìš”ì•½\n",
    "- âœ… ì£¼ìš” í•œê³„ ì •ë¦¬\n",
    "- âœ… í–¥í›„ ë¡œë“œë§µ (Phase 1-4)\n",
    "- âœ… ìµœì¢… ë©”ì‹œì§€\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **Part 3 v2 ë…¸íŠ¸ë¶ ì‹¤í–‰**\n",
    "   ```bash\n",
    "   jupyter notebook notebooks/ë°œí‘œ_Part3_ëª¨ë¸ë§_ë°_ìµœì í™”_v2.ipynb\n",
    "   ```\n",
    "\n",
    "2. **Part 4 ë…¸íŠ¸ë¶ ì‹¤í–‰**\n",
    "   ```bash\n",
    "   jupyter notebook notebooks/ë°œí‘œ_Part4_ê²°ê³¼_ë°_ë¹„ì¦ˆë‹ˆìŠ¤_ê°€ì¹˜_v2.ipynb\n",
    "   ```\n",
    "\n",
    "3. **ê²°ê³¼ ê²€í†  ë° ë°œí‘œ ì¤€ë¹„**\n",
    "\n",
    "---\n",
    "\n",
    "**ëª©í‘œ ì ìˆ˜: 87ì  ì´ìƒ (Aë“±ê¸‰)**\n",
    "\n",
    "- ì„¤ëª… ê°€ëŠ¥ì„± (25ì ): âœ… SHAP + ì¬ë¬´ í•´ì„ + FN ì›ì¸ ë¶„ì„\n",
    "- ìŠ¤í† ë¦¬í…”ë§ (20ì ): âœ… Part 3 ìš”ì•½ â†’ ì„±ëŠ¥ â†’ í•œê³„ â†’ ë¯¸ë˜\n",
    "- ì‹œê°í™”+í•´ì„ (20ì ): âœ… Bootstrap CI + Confusion Matrix + SHAP\n",
    "- ë„ë©”ì¸ ì „ë¬¸ì„± (15ì ): âœ… ì¬ë¬´ í•´ì„ + ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜\n",
    "- í†µê³„ì  ì—„ê²©ì„± (10ì ): âœ… Bootstrap CI + Validation vs Test\n",
    "- ì¬í˜„ ê°€ëŠ¥ì„± (5ì ): âœ… Pipeline + Metadata\n",
    "- í•œê³„ ì¸ì • (5ì ): âœ… ì†”ì§í•œ í•œê³„ + ì›ì¸ + ê°œì„ ì•ˆ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}