#!/usr/bin/env python3
"""
íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ëª©í‘œ:
1. ëª¨ë“  íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
2. ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜ì™€ ë‹¤ë¥¸ íŠ¹ì„±ë“¤ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
3. ë†’ì€ ìƒê´€ê´€ê³„ (> 0.8) íŠ¹ì„± ìŒ ì°¾ê¸°
4. VIF (Variance Inflation Factor) ê³„ì‚°
5. ì‹œê°í™”
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, spearmanr
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
if platform.system() == 'Darwin':
    plt.rc('font', family='AppleGothic')
elif platform.system() == 'Windows':
    plt.rc('font', family='Malgun Gothic')
else:
    plt.rc('font', family='NanumGothic')
plt.rc('axes', unicode_minus=False)

print('='*80)
print('ğŸ“Š íŠ¹ì„± ìƒê´€ê´€ê³„ ë¶„ì„')
print('='*80)

# ë°ì´í„° ë¡œë”©
df = pd.read_csv('data/features/domain_based_features_ì™„ì „íŒ.csv', encoding='utf-8')
TARGET_COL = 'ëª¨í˜•ê°œë°œìš©Performance(í–¥í›„1ë…„ë‚´ë¶€ë„ì—¬ë¶€)'
X = df.drop(columns=[TARGET_COL])
y = df[TARGET_COL]

print(f'ë°ì´í„° shape: {df.shape}')
print(f'íŠ¹ì„± ê°œìˆ˜: {X.shape[1]}')

# ============================================================================
# 1. ì „ì²´ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤
# ============================================================================

print('\n' + '='*80)
print('1ï¸âƒ£ ì „ì²´ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ (Pearson)')
print('='*80)

corr_matrix = X.corr(method='pearson')

print(f'\nìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ shape: {corr_matrix.shape}')
print(f'\nìƒê´€ê´€ê³„ í†µê³„:')
print(f'  í‰ê·  (ì ˆëŒ€ê°’): {corr_matrix.abs().mean().mean():.4f}')
print(f'  ì¤‘ì•™ê°’: {corr_matrix.median().median():.4f}')
print(f'  ìµœëŒ€ê°’: {corr_matrix.abs().max().max():.4f}')

# ============================================================================
# 2. ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„
# ============================================================================

print('\n' + '='*80)
print('2ï¸âƒ£ ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜ì™€ ë‹¤ë¥¸ íŠ¹ì„±ë“¤ì˜ ìƒê´€ê´€ê³„')
print('='*80)

DISTRUST_COL = 'ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜'
if DISTRUST_COL in corr_matrix.columns:
    distrust_corr = corr_matrix[DISTRUST_COL].drop(DISTRUST_COL).sort_values(ascending=False, key=abs)

    print(f'\nìƒìœ„ 10ê°œ (ì ˆëŒ€ê°’ ê¸°ì¤€):')
    print('-'*80)
    print(f'{"íŠ¹ì„±":<30s} {"ìƒê´€ê³„ìˆ˜":>12s} {"ì ˆëŒ€ê°’":>12s}')
    print('-'*80)
    for feat, corr in distrust_corr.head(10).items():
        print(f'{feat:<30s} {corr:12.6f} {abs(corr):12.6f}')

    print(f'\ní•˜ìœ„ 10ê°œ (ì ˆëŒ€ê°’ ê¸°ì¤€):')
    print('-'*80)
    for feat, corr in distrust_corr.tail(10).items():
        print(f'{feat:<30s} {corr:12.6f} {abs(corr):12.6f}')

    # ë§¤ìš° ë†’ì€ ìƒê´€ê´€ê³„ (> 0.9)
    very_high = distrust_corr[distrust_corr.abs() > 0.9]
    if len(very_high) > 0:
        print(f'\nâš ï¸ ë§¤ìš° ë†’ì€ ìƒê´€ê´€ê³„ (> 0.9): {len(very_high)}ê°œ')
        for feat, corr in very_high.items():
            print(f'  {feat}: {corr:.6f}')
else:
    print(f'âš ï¸ {DISTRUST_COL} ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')

# ============================================================================
# 3. ë†’ì€ ìƒê´€ê´€ê³„ ìŒ ì°¾ê¸°
# ============================================================================

print('\n' + '='*80)
print('3ï¸âƒ£ ë†’ì€ ìƒê´€ê´€ê³„ íŠ¹ì„± ìŒ (|r| > 0.8)')
print('='*80)

high_corr_pairs = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        corr_val = corr_matrix.iloc[i, j]
        if abs(corr_val) > 0.8:
            high_corr_pairs.append({
                'Feature 1': corr_matrix.columns[i],
                'Feature 2': corr_matrix.columns[j],
                'Correlation': corr_val,
                'Abs_Corr': abs(corr_val)
            })

if high_corr_pairs:
    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('Abs_Corr', ascending=False)
    print(f'\nì°¾ì€ ìŒ: {len(high_corr_df)}ê°œ')
    print('\n' + high_corr_df.to_string(index=False))

    # íŒŒì¼ ì €ì¥
    high_corr_df.to_csv('data/processed/high_correlation_pairs.csv', index=False, encoding='utf-8-sig')
    print(f'\nâœ… ì €ì¥: data/processed/high_correlation_pairs.csv')
else:
    print('\nìƒê´€ê´€ê³„ > 0.8ì¸ ìŒì´ ì—†ìŠµë‹ˆë‹¤')

# ============================================================================
# 4. VIF (Variance Inflation Factor) ê³„ì‚°
# ============================================================================

print('\n' + '='*80)
print('4ï¸âƒ£ VIF (ë‹¤ì¤‘ê³µì„ ì„±) ë¶„ì„')
print('='*80)

try:
    from statsmodels.stats.outliers_influence import variance_inflation_factor

    # ë¬´í•œëŒ€/ê²°ì¸¡ì¹˜ ì œê±°
    X_clean = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())

    print('\nVIF ê³„ì‚° ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)')

    vif_data = []
    for i, col in enumerate(X_clean.columns):
        try:
            vif = variance_inflation_factor(X_clean.values, i)
            vif_data.append({'Feature': col, 'VIF': vif})
            if (i + 1) % 5 == 0:
                print(f'  ì§„í–‰: {i+1}/{len(X_clean.columns)}')
        except Exception as e:
            print(f'  {col} ê³„ì‚° ì‹¤íŒ¨: {e}')
            vif_data.append({'Feature': col, 'VIF': np.nan})

    vif_df = pd.DataFrame(vif_data).sort_values('VIF', ascending=False)

    print(f'\nVIF ê²°ê³¼ (ìƒìœ„ 20ê°œ):')
    print('-'*80)
    print(vif_df.head(20).to_string(index=False))

    # VIF > 10ì¸ íŠ¹ì„±
    high_vif = vif_df[vif_df['VIF'] > 10]
    print(f'\nâš ï¸ VIF > 10 (ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œ): {len(high_vif)}ê°œ')
    for _, row in high_vif.head(10).iterrows():
        print(f'  {row["Feature"]}: {row["VIF"]:.2e}')

    # ì €ì¥
    vif_df.to_csv('data/processed/vif_analysis.csv', index=False, encoding='utf-8-sig')
    print(f'\nâœ… ì €ì¥: data/processed/vif_analysis.csv')

except ImportError:
    print('\nâš ï¸ statsmodels íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤')
    print('   ì„¤ì¹˜: pip install statsmodels')

# ============================================================================
# 5. ì‹œê°í™”
# ============================================================================

print('\n' + '='*80)
print('5ï¸âƒ£ ì‹œê°í™”')
print('='*80)

# 5.1 ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ (ì „ì²´)
fig, axes = plt.subplots(2, 2, figsize=(20, 20))

# ì „ì²´ íˆíŠ¸ë§µ
sns.heatmap(corr_matrix, cmap='RdBu_r', center=0, vmin=-1, vmax=1,
            cbar_kws={'shrink': 0.8}, ax=axes[0, 0], square=True)
axes[0, 0].set_title('ì „ì²´ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤', fontsize=16, pad=20)

# ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜ ê´€ë ¨ (ìˆëŠ” ê²½ìš°)
if DISTRUST_COL in X.columns:
    distrust_idx = X.columns.get_loc(DISTRUST_COL)
    distrust_row = corr_matrix.iloc[distrust_idx, :].values.reshape(1, -1)

    sns.heatmap(distrust_row, cmap='RdBu_r', center=0, vmin=-1, vmax=1,
                xticklabels=X.columns, yticklabels=[DISTRUST_COL],
                cbar_kws={'shrink': 0.8}, ax=axes[0, 1])
    axes[0, 1].set_title(f'{DISTRUST_COL}ì™€ì˜ ìƒê´€ê´€ê³„', fontsize=16, pad=20)
    axes[0, 1].tick_params(axis='x', rotation=90)

# ìƒìœ„ 10ê°œ íŠ¹ì„± ê°„ íˆíŠ¸ë§µ
if DISTRUST_COL in X.columns:
    top10_features = [DISTRUST_COL] + distrust_corr.head(9).index.tolist()
    top10_corr = corr_matrix.loc[top10_features, top10_features]

    sns.heatmap(top10_corr, annot=True, fmt='.3f', cmap='RdBu_r', center=0,
                vmin=-1, vmax=1, cbar_kws={'shrink': 0.8}, ax=axes[1, 0], square=True)
    axes[1, 0].set_title('ìƒìœ„ 10ê°œ íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ (ì„¸ë¶€)', fontsize=16, pad=20)
    axes[1, 0].tick_params(axis='x', labelrotation=45)
    axes[1, 0].tick_params(axis='y', labelrotation=0)

# ìƒê´€ê´€ê³„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
corr_values = corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)]
axes[1, 1].hist(corr_values, bins=50, edgecolor='black', alpha=0.7)
axes[1, 1].axvline(0, color='red', linestyle='--', linewidth=2)
axes[1, 1].axvline(0.8, color='orange', linestyle='--', linewidth=2, label='|r| = 0.8')
axes[1, 1].axvline(-0.8, color='orange', linestyle='--', linewidth=2)
axes[1, 1].set_title('ìƒê´€ê³„ìˆ˜ ë¶„í¬', fontsize=16, pad=20)
axes[1, 1].set_xlabel('ìƒê´€ê³„ìˆ˜', fontsize=12)
axes[1, 1].set_ylabel('ë¹ˆë„', fontsize=12)
axes[1, 1].legend()
axes[1, 1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('data/processed/correlation_analysis.png', dpi=300, bbox_inches='tight')
print('\nâœ… ì €ì¥: data/processed/correlation_analysis.png')

# 5.2 ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜ ìƒê´€ê´€ê³„ ë°” ì°¨íŠ¸
if DISTRUST_COL in X.columns:
    fig, ax = plt.subplots(figsize=(12, 8))

    top15 = distrust_corr.head(15)
    colors = ['red' if x > 0 else 'blue' for x in top15.values]

    ax.barh(range(len(top15)), top15.values, color=colors, alpha=0.7, edgecolor='black')
    ax.set_yticks(range(len(top15)))
    ax.set_yticklabels(top15.index)
    ax.set_xlabel('ìƒê´€ê³„ìˆ˜', fontsize=12)
    ax.set_title(f'{DISTRUST_COL}ì™€ì˜ ìƒê´€ê´€ê³„ (ìƒìœ„ 15ê°œ)', fontsize=16, pad=20)
    ax.axvline(0, color='black', linestyle='-', linewidth=1)
    ax.grid(axis='x', alpha=0.3)

    # ê°’ í‘œì‹œ
    for i, v in enumerate(top15.values):
        ax.text(v, i, f' {v:.3f}', va='center', ha='left' if v > 0 else 'right', fontsize=10)

    plt.tight_layout()
    plt.savefig('data/processed/distrust_correlation_bar.png', dpi=300, bbox_inches='tight')
    print('âœ… ì €ì¥: data/processed/distrust_correlation_bar.png')

# ============================================================================
# 6. ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
# ============================================================================

print('\n' + '='*80)
print('6ï¸âƒ£ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±')
print('='*80)

summary = []
summary.append('# íŠ¹ì„± ìƒê´€ê´€ê³„ ë¶„ì„ ë³´ê³ ì„œ\n')
summary.append(f'ìƒì„± ì¼ì‹œ: {pd.Timestamp.now()}\n\n')

summary.append('## 1. ë°ì´í„° ì •ë³´\n')
summary.append(f'- íŠ¹ì„± ê°œìˆ˜: {X.shape[1]}\n')
summary.append(f'- ìƒ˜í”Œ ê°œìˆ˜: {X.shape[0]}\n\n')

summary.append('## 2. ì „ì²´ ìƒê´€ê´€ê³„ í†µê³„\n')
summary.append(f'- í‰ê·  (ì ˆëŒ€ê°’): {corr_matrix.abs().mean().mean():.4f}\n')
summary.append(f'- ì¤‘ì•™ê°’: {corr_matrix.median().median():.4f}\n')
summary.append(f'- ìµœëŒ€ê°’: {corr_matrix.abs().max().max():.4f}\n\n')

if DISTRUST_COL in X.columns:
    summary.append(f'## 3. {DISTRUST_COL}ì™€ì˜ ìƒê´€ê´€ê³„\n\n')
    summary.append('### ìƒìœ„ 10ê°œ (ì ˆëŒ€ê°’ ê¸°ì¤€)\n\n')
    for feat, corr in distrust_corr.head(10).items():
        summary.append(f'- {feat}: {corr:.6f}\n')

    very_high = distrust_corr[distrust_corr.abs() > 0.9]
    if len(very_high) > 0:
        summary.append(f'\n### âš ï¸ ë§¤ìš° ë†’ì€ ìƒê´€ê´€ê³„ (> 0.9): {len(very_high)}ê°œ\n\n')
        for feat, corr in very_high.items():
            summary.append(f'- {feat}: {corr:.6f}\n')

if high_corr_pairs:
    summary.append(f'\n## 4. ë†’ì€ ìƒê´€ê´€ê³„ ìŒ (|r| > 0.8): {len(high_corr_df)}ê°œ\n\n')
    for _, row in high_corr_df.head(20).iterrows():
        summary.append(f'- {row["Feature 1"]} â†” {row["Feature 2"]}: {row["Correlation"]:.6f}\n')

summary.append('\n## 5. ê²°ë¡ \n\n')
if DISTRUST_COL in X.columns and len(very_high) > 0:
    summary.append(f'âš ï¸ **ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜ëŠ” {len(very_high)}ê°œ íŠ¹ì„±ê³¼ ë§¤ìš° ë†’ì€ ìƒê´€ê´€ê³„(> 0.9)ë¥¼ ê°€ì§**\n\n')
    summary.append('ì´ëŠ” ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œë¥¼ ì•¼ê¸°í•˜ë©°, L1 ì •ê·œí™”ê°€ ë‹¤ë¥¸ íŠ¹ì„±ì„ ì–µì œí•œ ì£¼ìš” ì›ì¸ì…ë‹ˆë‹¤.\n\n')
    summary.append('**ê¶Œì¥ì‚¬í•­:**\n')
    summary.append('1. ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜ ì œì™¸ í›„ ëª¨ë¸ ì¬í•™ìŠµ\n')
    summary.append('2. ë˜ëŠ” L2 ì •ê·œí™” + StandardScaler ì‚¬ìš©\n')
    summary.append('3. ë˜ëŠ” VIF > 10ì¸ íŠ¹ì„±ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì œê±°\n')

with open('data/processed/correlation_summary.md', 'w', encoding='utf-8') as f:
    f.writelines(summary)

print('\nâœ… ì €ì¥: data/processed/correlation_summary.md')

print('\n' + '='*80)
print('âœ… ìƒê´€ê´€ê³„ ë¶„ì„ ì™„ë£Œ!')
print('='*80)
