# ë°œí‘œìš© Part 3: ëª¨ë¸ë§ ë° ìµœì í™” ë…¸íŠ¸ë¶ ìƒì„± í”„ë¡¬í”„íŠ¸

ë‹¹ì‹ ì€ í•œêµ­ ê¸°ì—… ë¶€ë„ ì˜ˆì¸¡ í”„ë¡œì íŠ¸ì˜ ì‹œë‹ˆì–´ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì…ë‹ˆë‹¤. Part 2ì—ì„œ ìƒì„±í•œ ë„ë©”ì¸ ê¸°ë°˜ íŠ¹ì„±ì„ í™œìš©í•˜ì—¬ **ë°œí‘œìš© Part 3: ëª¨ë¸ë§ ë° ìµœì í™”** ë…¸íŠ¸ë¶ì„ ìƒì„±í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸

### í”„ë¡œì íŠ¸ ê°œìš”
- **ëª©í‘œ**: í•œêµ­ ê¸°ì—… ë¶€ë„ ìœ„í—˜ì„ 3ê°œì›”~1ë…„ ì „ì— ì˜ˆì¸¡í•˜ëŠ” AI ëª¨ë¸ ê°œë°œ
- **ë°ì´í„°**: 50,105ê°œ ê¸°ì—…, ë¶€ë„ìœ¨ 1.51% (ì‹¬ê°í•œ ë¶ˆê· í˜•)
- **í•µì‹¬ ê³¼ì œ**: ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬, ë„ë©”ì¸ ì§€ì‹ ë°˜ì˜, í•´ì„ ê°€ëŠ¥ì„±

### Part 1-2 ì™„ë£Œ ì‚¬í•­

**Part 1: ë¬¸ì œ ì •ì˜ ë° íƒìƒ‰ì  ë¶„ì„**
- ìœ ë™ì„±ì´ ê°€ì¥ ê°•ë ¥í•œ ì˜ˆì¸¡ ë³€ìˆ˜ ë°œê²¬ (ìœ ë™ë¹„ìœ¨, ë‹¹ì¢Œë¹„ìœ¨, í˜„ê¸ˆë¹„ìœ¨)
- ì—…ì¢…ë³„ ë¶€ë„ìœ¨ 2ë°° ì°¨ì´ (ê±´ì„¤ì—… 2.8% vs ê¸ˆìœµì—… 0.9%)
- ì™¸ê° ì—¬ë¶€ê°€ ë¶€ë„ìœ¨ì— ì˜í–¥

**Part 2: ë„ë©”ì¸ íŠ¹ì„± ê³µí•™ ì™„ë£Œ (ì‹¤ì œ ì¶œë ¥ ê²°ê³¼)**
- **ìƒì„±ëœ íŠ¹ì„±**: 52ê°œ (ìœ ë™ì„± 10ê°œ, ì§€ê¸‰ë¶ˆëŠ¥ 11ê°œ, ì¬ë¬´ì¡°ì‘ 15ê°œ, ì´í•´ê´€ê³„ì 10ê°œ, í•œêµ­ì‹œì¥ 6ê°œ)
- **Feature Validation**: 49ê°œ íŠ¹ì„± ê²€ì¦ ì™„ë£Œ (Mann-Whitney U test, Cliff's Delta, AUC)
- **VIF ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„**: 19ê°œ ê³ VIF íŠ¹ì„± ë°œê²¬ â†’ 14ê°œ ì œê±°, 5ê°œ ê²½ê³ ì™€ í•¨ê»˜ ìœ ì§€
- **IV ê¸°ë°˜ íŠ¹ì„± ì„ íƒ**: IV > 0.02 ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
- **ìµœì¢… ì„ íƒëœ íŠ¹ì„±**: 27ê°œ íŠ¹ì„± (ë‹¤ì¤‘ê³µì„ ì„± ì œê±° + ì˜ˆì¸¡ë ¥ ê²€ì¦ ì™„ë£Œ)
- **ì¶œë ¥ íŒŒì¼**: `data/features/domain_based_features_ì™„ì „íŒ.csv`

**Part 2 í•µì‹¬ ë°œê²¬**:
- Beneish M-Score ì™„ì „ êµ¬í˜„ (15ê°œ ì¬ë¬´ì¡°ì‘ íƒì§€ íŠ¹ì„±)
- ìœ ë™ì„± íŠ¹ì„±ì´ ê°€ì¥ ë†’ì€ AUC (í˜„ê¸ˆì†Œì§„ì¼ìˆ˜, ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥)
- ì´í•´ê´€ê³„ì í–‰ë™ íŠ¹ì„±(ì—°ì²´, ì‹ ìš©ë“±ê¸‰)ì´ ê°•í•œ ì˜ˆì¸¡ë ¥

---

## ğŸ¯ Part 3 ë…¸íŠ¸ë¶ ìƒì„± ìš”êµ¬ì‚¬í•­

### ğŸ“‚ ì…ë ¥ ë°ì´í„°
- **íŒŒì¼ ê²½ë¡œ**: `../data/features/domain_based_features_ì™„ì „íŒ.csv`
- **ë°ì´í„° êµ¬ì¡°**:
  - íƒ€ê²Ÿ: `ëª¨í˜•ê°œë°œìš©Performance(í–¥í›„1ë…„ë‚´ë¶€ë„ì—¬ë¶€)` (0: ì •ìƒ, 1: ë¶€ë„)
  - íŠ¹ì„±: 27ê°œ ë„ë©”ì¸ ê¸°ë°˜ íŠ¹ì„± (Part 2ì—ì„œ ì„ íƒë¨)
  - í¬ê¸°: 50,105 rows

### ğŸ› ï¸ í•„ìˆ˜ êµ¬í˜„ ë‹¨ê³„

#### 1ï¸âƒ£ í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë”©
```python
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
- pandas, numpy, matplotlib, seaborn, plotly
- scikit-learn (train_test_split, RandomizedSearchCV, StratifiedKFold)
- imblearn (ImbPipeline, SMOTE, BorderlineSMOTE, RandomUnderSampler, SMOTETomek)
- lightgbm, xgboost, catboost
- BalancedRandomForestClassifier, VotingClassifier

# í•œê¸€ í°íŠ¸ ì„¤ì • (macOS: AppleGothic, Windows: Malgun Gothic, Linux: NanumGothic)
# UTF-8 ì¸ì½”ë”© í™•ì¸
```

**ë°ì´í„° ë¡œë”© í›„ í™•ì¸ì‚¬í•­**:
- ë°ì´í„° shape ì¶œë ¥
- ë¶€ë„ìœ¨ í™•ì¸ (ì•½ 1.51% ì˜ˆìƒ)
- ê²°ì¸¡ì¹˜ í™•ì¸
- Train/Test split (80:20, stratify=y, random_state=42)

---

#### 2ï¸âƒ£ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

**ImbPipeline 6ë‹¨ê³„ êµ¬ì¡°** (ë°˜ë“œì‹œ ì´ ìˆœì„œëŒ€ë¡œ):

```python
from imblearn.pipeline import Pipeline as ImbPipeline

pipeline = ImbPipeline([
    ('inf_handler', InfiniteHandler()),         # 1. ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬
    ('winsorizer', Winsorizer(0.01, 0.99)),    # 2. ì´ìƒì¹˜ ì œì–´ (1%~99% ë¶„ìœ„ìˆ˜)
    ('log_transformer', LogTransformer()),      # 3. ë¡œê·¸ ë³€í™˜ (ì–‘ìˆ˜ë§Œ)
    ('imputer', IterativeImputer(max_iter=10)), # 4. ê²°ì¸¡ì¹˜ ë³´ê°„
    ('scaler', RobustScaler()),                 # 5. ìŠ¤ì¼€ì¼ë§
    ('resampler', 'passthrough'),               # 6. ë¦¬ìƒ˜í”Œë§ (í›„ë³´êµ°ì—ì„œ ì„ íƒ)
    ('classifier', LogisticRegression())        # 7. ë¶„ë¥˜ê¸°
])
```

**ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ì •ì˜ í•„ìš”**:
- `InfiniteHandler`: np.inf, -np.inf â†’ np.nan
- `Winsorizer`: 1%~99% ë¶„ìœ„ìˆ˜ë¡œ í´ë¦¬í•‘
- `LogTransformer`: ì–‘ìˆ˜ ì»¬ëŸ¼ì—ë§Œ np.log1p ì ìš©

---

#### 3ï¸âƒ£ ë¦¬ìƒ˜í”Œë§ ì „ëµ (5ê°€ì§€)

**ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•  ë¦¬ìƒ˜í”Œë§ ì „ëµ**:

```python
resampler_list = [
    'passthrough',                                      # 1. ë¦¬ìƒ˜í”Œë§ ì—†ìŒ (ë² ì´ìŠ¤ë¼ì¸)
    SMOTE(sampling_strategy=0.2, random_state=42),     # 2. SMOTE (ë¶€ë„ ê¸°ì—… 20%ê¹Œì§€ ì¦ê°•)
    BorderlineSMOTE(sampling_strategy=0.2, random_state=42),  # 3. ê²½ê³„ì„  ìƒ˜í”Œ ì¤‘ì‹¬
    RandomUnderSampler(sampling_strategy=0.3, random_state=42), # 4. ì–¸ë”ìƒ˜í”Œë§
    SMOTETomek(sampling_strategy=0.2, random_state=42) # 5. SMOTE + Tomek Links (ì¶”ê°€ ìš”ì²­)
]
```

**ë¦¬ìƒ˜í”Œë§ ë¹„ìœ¨ ê·¼ê±°**:
- `sampling_strategy=0.2`: ë¶€ë„ìœ¨ 1.5% â†’ 20%ë¡œ ì¦ê°• (ê³¼ìƒì„± ë°©ì§€)
- `sampling_strategy=0.3`: ì–¸ë”ìƒ˜í”Œë§ì€ 30%ê¹Œì§€ë§Œ (ë°ì´í„° ì†ì‹¤ ìµœì†Œí™”)

---

#### 4ï¸âƒ£ AutoML: RandomizedSearchCV

**5ê°œ ëª¨ë¸ Ã— í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ**:

```python
param_grid = [
    # 1. LightGBM (ìë™ ë¶ˆê· í˜• ì²˜ë¦¬)
    {
        'resampler': resampler_list,
        'classifier': [lgb.LGBMClassifier(random_state=42, verbose=-1)],
        'classifier__n_estimators': [300, 500, 1000],
        'classifier__learning_rate': [0.01, 0.02, 0.05],
        'classifier__num_leaves': [31, 63, 127],
        'classifier__max_depth': [-1, 10, 20],
        'classifier__subsample': [0.7, 0.9],
        'classifier__reg_alpha': [0.1, 0.5],
        'classifier__reg_lambda': [0.1, 0.5],
        'classifier__is_unbalance': [True]
    },

    # 2. XGBoost
    {
        'resampler': resampler_list,
        'classifier': [xgb.XGBClassifier(random_state=42, eval_metric='logloss')],
        'classifier__n_estimators': [300, 500],
        'classifier__max_depth': [4, 6, 8],
        'classifier__learning_rate': [0.01, 0.05],
        'classifier__gamma': [0, 0.1, 0.5],
        'classifier__subsample': [0.7, 0.9],
        'classifier__reg_alpha': [0.1, 1.0],
        'classifier__scale_pos_weight': [1, 8, 66]  # sqrt_ratio, scale_ratio
    },

    # 3. CatBoost
    {
        'resampler': resampler_list,
        'classifier': [CatBoostClassifier(random_state=42, verbose=0)],
        'classifier__iterations': [500, 1000],
        'classifier__learning_rate': [0.01, 0.03, 0.1],
        'classifier__depth': [4, 6, 8],
        'classifier__l2_leaf_reg': [3, 5, 9],
        'classifier__auto_class_weights': ['Balanced', 'SqrtBalanced']
    },

    # 4. BalancedRandomForest
    {
        'resampler': resampler_list,
        'classifier': [BalancedRandomForestClassifier(random_state=42, n_jobs=-1)],
        'classifier__n_estimators': [300, 500],
        'classifier__max_depth': [10, 20, None],
        'classifier__max_features': ['sqrt', 'log2']
    },

    # 5. LogisticRegression (ë² ì´ìŠ¤ë¼ì¸)
    {
        'resampler': resampler_list,
        'classifier': [LogisticRegression(random_state=42, max_iter=1000)],
        'classifier__C': [0.1, 1.0, 10.0],
        'classifier__class_weight': ['balanced', None]
    }
]
```

**RandomizedSearchCV ì„¤ì •**:

```python
search = RandomizedSearchCV(
    estimator=pipeline,
    param_distributions=param_grid,
    n_iter=100,                          # 100íšŒ ëœë¤ ìƒ˜í”Œë§
    scoring='average_precision',         # PR-AUC ìµœì í™”
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    n_jobs=-1,
    verbose=1,
    random_state=42
)
```

**ì‹¤í–‰ í›„ ì¶œë ¥**:
- ìµœì  ëª¨ë¸ ì´ë¦„ (ì˜ˆ: XGBClassifier, LGBMClassifier ë“±)
- ìµœì  ë¦¬ìƒ˜í”Œë§ ì „ëµ
- ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°
- CV PR-AUC ì ìˆ˜
- ì†Œìš” ì‹œê°„

---

#### 5ï¸âƒ£ Weighted Voting ì•™ìƒë¸”

**Top 3 ëª¨ë¸ ê¸°ë°˜ ì•™ìƒë¸” êµ¬ì¶•**:

```python
# 1. AutoML ê²°ê³¼ì—ì„œ ìƒìœ„ 3ê°œ ì¶”ì¶œ
results_df = pd.DataFrame(search.cv_results_)
top3 = results_df.sort_values('mean_test_score', ascending=False).head(3)

# 2. VotingClassifier êµ¬ì„±
voting_clf = VotingClassifier(
    estimators=[
        ('Top1_ModelName', pipeline_1),
        ('Top2_ModelName', pipeline_2),
        ('Top3_ModelName', pipeline_3)
    ],
    voting='soft',                      # í™•ë¥  í‰ê· 
    weights=[score1, score2, score3],   # CV PR-AUC ê¸°ë°˜ ê°€ì¤‘ì¹˜
    n_jobs=-1
)
```

**ì¶œë ¥**:
- Top 3 ëª¨ë¸ ì´ë¦„ ë° CV ì ìˆ˜ (í‘œ í˜•ì‹)
- ê°€ì¤‘ì¹˜ ê³„ì‚° ë°©ì‹ ì„¤ëª…

---

#### 6ï¸âƒ£ ìµœì¢… ëª¨ë¸ ì„ ì • (Test Set í‰ê°€)

**ì„±ëŠ¥ ë¹„êµ**:

```python
def evaluate_model(model, X_test, y_test):
    y_prob = model.predict_proba(X_test)[:, 1]
    return {
        'PR-AUC': average_precision_score(y_test, y_prob),
        'ROC-AUC': roc_auc_score(y_test, y_prob),
        'F1-Score': f1_score(y_test, (y_prob >= 0.5).astype(int))
    }

# Single Best vs Weighted Voting ë¹„êµ
results = pd.DataFrame([
    evaluate_model(best_single_model, X_test, y_test),
    evaluate_model(voting_clf, X_test, y_test)
], index=['Single Best', 'Weighted Voting'])
```

**ìµœì¢… ëª¨ë¸ ì„ ì • ë¡œì§**:
- PR-AUCê°€ ë†’ì€ ìª½ ì„ íƒ
- ë‹¨, ì•™ìƒë¸”ì´ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ 0.5% ì´ìƒ ìš°ìˆ˜í•´ì•¼ ì„ íƒ (ë³µì¡ë„ ê³ ë ¤)
- ìœ ì§€ë³´ìˆ˜ ìš©ì´ì„±ë„ ê³ ë ¤

---

#### 7ï¸âƒ£ Traffic Light ì‹œìŠ¤í…œ (ë¶€ë„ ìœ„í—˜ 3ë“±ê¸‰ ë¶„ë¥˜)

**ì„ê³„ê°’ ê²°ì • ë°©ë²•** (ëª¨ë¸ ê²°ê³¼ ê¸°ë°˜ ìµœì í™”):

**Step 1: F1-Score ê¸°ë°˜ ìµœì  ì„ê³„ê°’ íƒìƒ‰**
```python
from sklearn.metrics import precision_recall_curve, f1_score

# PR Curveì—ì„œ ëª¨ë“  ì„ê³„ê°’ í…ŒìŠ¤íŠ¸
precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)

# F1-Score ê³„ì‚°
f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)
optimal_threshold = thresholds[np.argmax(f1_scores)]

print(f"F1-Score ìµœì  ì„ê³„ê°’: {optimal_threshold:.4f}")
```

**Step 2: ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ ë°˜ì˜**
```python
# ëª©í‘œ: Recall >= 60% ë³´ì¥ (ë¶€ë„ ê¸°ì—…ì˜ 60% ì´ìƒ íƒì§€)
target_recall = 0.6

# Recall >= 60%ë¥¼ ë§Œì¡±í•˜ëŠ” ìµœëŒ€ Precision ì„ê³„ê°’ ì°¾ê¸°
idx = np.where(recalls >= target_recall)[0]
if len(idx) > 0:
    business_threshold = thresholds[idx[np.argmax(precisions[idx])]]
    print(f"Recall 60% ë³´ì¥ ì„ê³„ê°’: {business_threshold:.4f}")
```

**Step 3: Traffic Light ì„ê³„ê°’ ì„¤ì •**
```python
# Red ì„ê³„ê°’: ë¹„ì¦ˆë‹ˆìŠ¤ ì„ê³„ê°’ ë˜ëŠ” ìƒìœ„ 5% ë°±ë¶„ìœ„ìˆ˜
red_threshold = max(business_threshold, np.percentile(y_prob, 95))

# Yellow ì„ê³„ê°’: Redì˜ 40% ìˆ˜ì¤€ ë˜ëŠ” ìƒìœ„ 15% ë°±ë¶„ìœ„ìˆ˜
yellow_threshold = max(red_threshold * 0.4, np.percentile(y_prob, 85))

print(f"\nìµœì¢… ì„ê³„ê°’:")
print(f"  Yellow (ì£¼ì˜): >= {yellow_threshold:.4f}")
print(f"  Red (ìœ„í—˜):    >= {red_threshold:.4f}")

# ë¶„ë¥˜ í•¨ìˆ˜
def traffic_light_classification(y_prob, yellow_th, red_th):
    conditions = [
        (y_prob >= red_th),      # Red
        (y_prob >= yellow_th)    # Yellow
    ]
    choices = ['Red (ìœ„í—˜)', 'Yellow (ì£¼ì˜)']
    return np.select(conditions, choices, default='Green (ì•ˆì „)')

grades = traffic_light_classification(y_prob_test, yellow_threshold, red_threshold)
```

**ì°¸ê³  ì„ê³„ê°’ (04 ë…¸íŠ¸ë¶ ê²°ê³¼)**:
- Yellow: 0.02 (2%), Red: 0.05 (5%)
- í•˜ì§€ë§Œ ëª¨ë¸ ì„±ëŠ¥ì— ë”°ë¼ ì¡°ì • í•„ìš” (ìœ„ ë¡œì§ ì‚¬ìš©)

**ì¶œë ¥í•´ì•¼ í•  í†µê³„**:

| ë“±ê¸‰ | ê¸°ì—… ìˆ˜ (ë¹„ìœ¨) | ì‹¤ì œ ë¶€ë„ ìˆ˜ | ì •ë°€ë„ (Precision) | ë¶€ë„ í¬ì°©ë¥  (Recall ê¸°ì—¬) |
|------|---------------|--------------|-------------------|------------------------|
| ğŸ”´ Red (ìœ„í—˜) | ??? (??%) | ??? | ??% | ??% |
| ğŸŸ¡ Yellow (ì£¼ì˜) | ??? (??%) | ??? | ??% | ??% |
| ğŸŸ¢ Green (ì•ˆì „) | ??? (??%) | ??? | ??% | ??% |
| **í•©ê³„** | 10,021 (100%) | ??? | - | **ë¦¬ìŠ¤í¬ ë°©ì–´ìœ¨: ??%** |

**ë¦¬ìŠ¤í¬ ë°©ì–´ìœ¨**: (Red + Yellowì—ì„œ í¬ì°©í•œ ë¶€ë„ ìˆ˜) / ì „ì²´ ë¶€ë„ ìˆ˜ Ã— 100

**ì„ê³„ê°’ ê²°ì • ê¸°ì¤€**:
- âœ… F1-Score ìµœì í™”
- âœ… Recall >= 60% ë³´ì¥ (ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬)
- âœ… ìƒìœ„ 5~15% ê¸°ì—…ì„ ì§‘ì¤‘ ê´€ë¦¬ ëŒ€ìƒìœ¼ë¡œ ì„ ì •

---

#### 8ï¸âƒ£ ì‹œê°í™” (í•„ìˆ˜ í¬í•¨)

**1. Feature Importance (Top 15)**
- Plotly ê°€ë¡œ ë°” ì°¨íŠ¸
- ì¤‘ìš”ë„ ì ìˆ˜ì™€ íŠ¹ì„±ëª… í‘œì‹œ

**2. PR-AUC Curve**
- Precision-Recall ê³¡ì„ 
- í˜„ì¬ Red ì„ê³„ê°’ ìœ„ì¹˜ ë¹¨ê°„ ì  í‘œì‹œ (ë™ì  ì„ê³„ê°’ ì‚¬ìš©)
- Yellow ì„ê³„ê°’ ìœ„ì¹˜ ë…¸ë€ ì  í‘œì‹œ
- AUC ê°’ ì œëª©ì— í‘œì‹œ

**3. Confusion Matrix (Red ì„ê³„ê°’ ê¸°ì¤€)**
- Plotly Heatmap
- TN, FP, FN, TP ëª…í™•íˆ í‘œê¸°
- ì œëª©ì— ì‚¬ìš©ëœ ì„ê³„ê°’ í‘œì‹œ

**4. ì˜ˆì¸¡ í™•ë¥  ë¶„í¬**
- ì •ìƒ ê¸°ì—…(ì´ˆë¡ìƒ‰) vs ë¶€ë„ ê¸°ì—…(ë¹¨ê°„ìƒ‰) íˆìŠ¤í† ê·¸ë¨
- ë¡œê·¸ ìŠ¤ì¼€ì¼ ì‚¬ìš© (ë¶ˆê· í˜• ë°ì´í„°)

**5. Traffic Light ì‹œê°í™”**
- ë„ë„› ì°¨íŠ¸: ë“±ê¸‰ë³„ ê¸°ì—… ë¹„ì¤‘
- ë§‰ëŒ€ ì°¨íŠ¸: ë“±ê¸‰ë³„ ì‹¤ì œ ë¶€ë„ìœ¨

**6. Cumulative Gains Curve**
- ìƒìœ„ N% ì‹¬ì‚¬ ì‹œ ë¶€ë„ í¬ì°© ë¹„ìœ¨
- ëœë¤ ê¸°ì¤€ì„ ê³¼ ë¹„êµ

---

#### 9ï¸âƒ£ ëª¨ë¸ ì €ì¥ (Part 4 SHAP ë¶„ì„ ëŒ€ë¹„)

**ì¤‘ìš”**: Part 4ì—ì„œ SHAP ë¶„ì„ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ, SHAPì´ ì˜ ì‘ë™í•˜ë„ë¡ ëª¨ë¸ì„ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.

```python
import joblib
import os

save_dir = '../data/processed/'
os.makedirs(save_dir, exist_ok=True)

# 1. ìµœì¢… ëª¨ë¸ (ì „ì²´ íŒŒì´í”„ë¼ì¸ í¬í•¨)
joblib.dump(final_model, os.path.join(save_dir, 'ë°œí‘œ_Part3_ìµœì¢…ëª¨ë¸.pkl'))
print(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì €ì¥: ë°œí‘œ_Part3_ìµœì¢…ëª¨ë¸.pkl")

# 2. ë¶„ë¥˜ê¸°ë§Œ (SHAP ë¶„ì„ìš©) â­ ì¤‘ìš”!
if hasattr(final_model, 'named_steps'):
    classifier_only = final_model.named_steps['classifier']
else:
    classifier_only = final_model

joblib.dump(classifier_only, os.path.join(save_dir, 'ë°œí‘œ_Part3_ë¶„ë¥˜ê¸°.pkl'))
print(f"âœ… ë¶„ë¥˜ê¸°ë§Œ ì €ì¥: ë°œí‘œ_Part3_ë¶„ë¥˜ê¸°.pkl (SHAPìš©)")

# 3. ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ (SHAP ë¶„ì„ìš©) â­ ì¤‘ìš”!
# SHAPì€ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ í•„ìš”í•˜ë¯€ë¡œ Train/Test ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ í›„ ì €ì¥
from sklearn.pipeline import Pipeline

# ì „ì²˜ë¦¬ë§Œ ìˆ˜í–‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸ ìƒì„±
preprocessing_only = Pipeline([
    ('inf_handler', final_model.named_steps['inf_handler']),
    ('winsorizer', final_model.named_steps['winsorizer']),
    ('log_transformer', final_model.named_steps['log_transformer']),
    ('imputer', final_model.named_steps['imputer']),
    ('scaler', final_model.named_steps['scaler'])
])

# ì „ì²˜ë¦¬ ì ìš©
X_train_processed = preprocessing_only.transform(X_train)
X_test_processed = preprocessing_only.transform(X_test)

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ (ì»¬ëŸ¼ëª… ìœ ì§€)
X_train_processed_df = pd.DataFrame(X_train_processed, columns=X_train.columns)
X_test_processed_df = pd.DataFrame(X_test_processed, columns=X_test.columns)

# ì €ì¥
X_train_processed_df.to_csv(os.path.join(save_dir, 'ë°œí‘œ_Part3_X_train_processed.csv'),
                             index=False, encoding='utf-8-sig')
X_test_processed_df.to_csv(os.path.join(save_dir, 'ë°œí‘œ_Part3_X_test_processed.csv'),
                            index=False, encoding='utf-8-sig')
y_train.to_csv(os.path.join(save_dir, 'ë°œí‘œ_Part3_y_train.csv'),
               index=False, encoding='utf-8-sig', header=['target'])
y_test.to_csv(os.path.join(save_dir, 'ë°œí‘œ_Part3_y_test.csv'),
              index=False, encoding='utf-8-sig', header=['target'])

print(f"âœ… ì „ì²˜ë¦¬ëœ Train/Test ë°ì´í„° ì €ì¥ (SHAP ë¶„ì„ìš©)")

# 4. ì„ê³„ê°’ ì €ì¥ (Traffic Light ì‹œìŠ¤í…œìš©)
thresholds = {
    'yellow_threshold': yellow_threshold,
    'red_threshold': red_threshold,
    'optimal_f1_threshold': optimal_threshold
}
joblib.dump(thresholds, os.path.join(save_dir, 'ë°œí‘œ_Part3_ì„ê³„ê°’.pkl'))
print(f"âœ… Traffic Light ì„ê³„ê°’ ì €ì¥")

print("\n" + "="*60)
print("Part 4 SHAP ë¶„ì„ì„ ìœ„í•œ í•„ìˆ˜ íŒŒì¼:")
print("  1. ë°œí‘œ_Part3_ë¶„ë¥˜ê¸°.pkl - SHAP explainer ìƒì„±ìš©")
print("  2. ë°œí‘œ_Part3_X_train_processed.csv - Background ë°ì´í„°")
print("  3. ë°œí‘œ_Part3_X_test_processed.csv - ì„¤ëª… ëŒ€ìƒ ë°ì´í„°")
print("="*60)
```

**ì €ì¥ë˜ëŠ” íŒŒì¼ ëª©ë¡**:
1. `ë°œí‘œ_Part3_ìµœì¢…ëª¨ë¸.pkl`: ì „ì²´ íŒŒì´í”„ë¼ì¸ (ë°°í¬ìš©)
2. `ë°œí‘œ_Part3_ë¶„ë¥˜ê¸°.pkl`: ë¶„ë¥˜ê¸°ë§Œ (SHAP ë¶„ì„ìš©) â­
3. `ë°œí‘œ_Part3_X_train_processed.csv`: ì „ì²˜ë¦¬ëœ í•™ìŠµ ë°ì´í„° (SHAP background) â­
4. `ë°œí‘œ_Part3_X_test_processed.csv`: ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° (SHAP ì„¤ëª… ëŒ€ìƒ) â­
5. `ë°œí‘œ_Part3_y_train.csv`: í•™ìŠµ íƒ€ê²Ÿ
6. `ë°œí‘œ_Part3_y_test.csv`: í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ
7. `ë°œí‘œ_Part3_ì„ê³„ê°’.pkl`: Traffic Light ì„ê³„ê°’

---

## ğŸ“Š ë…¸íŠ¸ë¶ êµ¬ì¡° (ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜)

```markdown
# ğŸ“— ë°œí‘œìš© Part 3: ëª¨ë¸ë§ ë° ìµœì í™”

## ğŸ¯ Part 3 ëª©í‘œ ë° ì´ì „ Part ìš”ì•½

### Part 1-2 ì£¼ìš” ë°œê²¬
- [Part 1-2 ìš”ì•½ 3-5ì¤„]

### Part 3 ëª©í‘œ
1. ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ (5ê°€ì§€ ë¦¬ìƒ˜í”Œë§ ì „ëµ)
2. AutoMLë¡œ ìµœì  ëª¨ë¸ íƒìƒ‰ (100íšŒ ëœë¤ ìƒ˜í”Œë§)
3. Weighted Voting ì•™ìƒë¸”
4. ë¹„ì¦ˆë‹ˆìŠ¤ ì ìš©: Traffic Light ì‹œìŠ¤í…œ

---

## 0. í™˜ê²½ ì„¤ì •
[ë¼ì´ë¸ŒëŸ¬ë¦¬ import, í•œê¸€ í°íŠ¸ ì„¤ì •]

## 1. ë°ì´í„° ë¡œë”© ë° ë¶„í• 
[Part 2 ì¶œë ¥ íŒŒì¼ ë¡œë”©, Train/Test split]

## 2. ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ì •ì˜
[InfiniteHandler, Winsorizer, LogTransformer]

## 3. ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ ì „ëµ
[ImbPipeline êµ¬ì¡°, 5ê°€ì§€ ë¦¬ìƒ˜í”Œë§ ì „ëµ ì„¤ëª…]

## 4. AutoML: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
[RandomizedSearchCV ì‹¤í–‰, ê²°ê³¼ ì¶œë ¥]

## 5. Weighted Voting ì•™ìƒë¸”
[Top 3 ëª¨ë¸ ì¶”ì¶œ, VotingClassifier êµ¬ì„±]

## 6. ìµœì¢… ëª¨ë¸ ì„ ì •
[Single Best vs Voting ë¹„êµ, ìŠ¹ì ì„ íƒ]

## 7. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
[PR-AUC, ROC-AUC, Confusion Matrix]

## 8. Feature Importance ë¶„ì„
[ì¤‘ìš”ë„ Top 15 ì‹œê°í™”]

## 9. Traffic Light ì‹œìŠ¤í…œ
[3ë“±ê¸‰ ë¶„ë¥˜, í†µê³„ ì¶œë ¥, ì‹œê°í™”]

## 10. ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„
[Cumulative Gains, íš¨ìœ¨ì„± ë¶„ì„]

## 11. ëª¨ë¸ ì €ì¥ ë° ë‹¤ìŒ ë‹¨ê³„
[pkl íŒŒì¼ ì €ì¥, Part 4 ì˜ˆê³ ]
```

---

## âœ… í’ˆì§ˆ ê¸°ì¤€ (ë°˜ë“œì‹œ ì¤€ìˆ˜)

### ì½”ë“œ í’ˆì§ˆ
- [ ] ëª¨ë“  ì…€ì´ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ ê°€ëŠ¥ (top-to-bottom)
- [ ] í•˜ë“œì½”ë”© ê¸ˆì§€ (ê²½ë¡œ, ì„ê³„ê°’ ë“± ë³€ìˆ˜í™”)
- [ ] í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ (ê¹¨ì§ ì—†ìŒ)
- [ ] UTF-8 ì¸ì½”ë”© í™•ì¸

### ë°ì´í„° ì²˜ë¦¬
- [ ] ì‹œê³„ì—´ ì˜ì¡´ì  ë¡œì§ ì‚¬ìš© ì•ˆ í•¨ (íš¡ë‹¨ë©´ ë°ì´í„°)
- [ ] Train/Test split ì „ì— ë¦¬ìƒ˜í”Œë§ í•˜ì§€ ì•ŠìŒ (Leakage ë°©ì§€)
- [ ] Stratified splitìœ¼ë¡œ ë¶€ë„ìœ¨ ìœ ì§€

### ëª¨ë¸ë§
- [ ] 5ê°€ì§€ ë¦¬ìƒ˜í”Œë§ ì „ëµ ëª¨ë‘ í¬í•¨ (SMOTETomek í¬í•¨)
- [ ] 5ê°œ ëª¨ë¸ ëª¨ë‘ í…ŒìŠ¤íŠ¸
- [ ] PR-AUCë¥¼ ì£¼ìš” ë©”íŠ¸ë¦­ìœ¼ë¡œ ì‚¬ìš©
- [ ] Weighted Voting ì•™ìƒë¸” êµ¬í˜„

### ì‹œê°í™”
- [ ] Plotly ì‚¬ìš© (ì¸í„°ë™í‹°ë¸Œ)
- [ ] í•œê¸€ ê¹¨ì§ ì—†ìŒ
- [ ] 6ê°€ì§€ í•µì‹¬ ì‹œê°í™” ëª¨ë‘ í¬í•¨

### ì¶œë ¥
- [ ] Traffic Light í†µê³„ í‘œ ì™„ì„±
- [ ] ë¦¬ìŠ¤í¬ ë°©ì–´ìœ¨ ê³„ì‚° ë° ì¶œë ¥
- [ ] ìµœì¢… ëª¨ë¸ pkl íŒŒì¼ ì €ì¥
- [ ] SHAP ë¶„ì„ìš© íŒŒì¼ ì €ì¥ (ë¶„ë¥˜ê¸°.pkl, X_train/test_processed.csv)

---

## ğŸš« ì£¼ì˜ì‚¬í•­ (ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ)

1. **Optuna ì‚¬ìš© ê¸ˆì§€** â†’ RandomizedSearchCVë§Œ ì‚¬ìš©
2. **Stacking ì•™ìƒë¸” ê¸ˆì§€** â†’ Weighted Votingë§Œ ì‚¬ìš©
3. **ì‹œê³„ì—´ ë¡œì§ ê¸ˆì§€** â†’ ì‹œê°„ ìˆœì„œ ì˜ì¡´ ì½”ë“œ ì‘ì„± ì•ˆ í•¨
4. **Train/Test ì „ì— ë¦¬ìƒ˜í”Œë§ ê¸ˆì§€** â†’ íŒŒì´í”„ë¼ì¸ ë‚´ì—ì„œë§Œ ë¦¬ìƒ˜í”Œë§
5. **Category dtype ìˆ˜ì¹˜ ê³„ì‚° ê¸ˆì§€** â†’ ë¨¼ì € .cat.codesë¡œ ë³€í™˜
6. **ROC-AUC ì£¼ìš” ë©”íŠ¸ë¦­ ì‚¬ìš© ê¸ˆì§€** â†’ PR-AUCê°€ í•µì‹¬
7. **SHAP ë¶„ì„ìš© íŒŒì¼ ëˆ„ë½ ê¸ˆì§€** â†’ ì „ì²˜ë¦¬ëœ ë°ì´í„°ì™€ ë¶„ë¥˜ê¸° ë°˜ë“œì‹œ ì €ì¥

---

## ğŸ“Œ ì°¸ê³  ìë£Œ

### ê¸°ì¡´ ë…¸íŠ¸ë¶
- `notebooks/04_ë¶ˆê· í˜•_ë¶„ë¥˜_ëª¨ë¸ë§_final.ipynb`: ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ (ì°¸ê³ ë§Œ, ë³µì‚¬ ê¸ˆì§€)
- `notebooks/ë°œí‘œ_Part2_ë„ë©”ì¸_íŠ¹ì„±_ê³µí•™_ì™„ì „íŒ.ipynb`: Part 2 ì¶œë ¥ ê²°ê³¼

### ë¬¸ì„œ
- `CLAUDE.md`: í”„ë¡œì íŠ¸ ì „ì²´ ê°€ì´ë“œ
- `docs/notebook_summaries/`: ë…¸íŠ¸ë¶ ìš”ì•½ ë¬¸ì„œ

### ì…ë ¥ íŒŒì¼
- `data/features/domain_based_features_ì™„ì „íŒ.csv`: 27ê°œ íŠ¹ì„± (Part 2 ì¶œë ¥)
- `data/features/feature_metadata_ì™„ì „íŒ.csv`: íŠ¹ì„± ë©”íƒ€ë°ì´í„°

---

## ğŸ¯ ìµœì¢… ëª©í‘œ

**ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ë”°ë¼ ìƒì„±ëœ ë…¸íŠ¸ë¶ì€**:
1. âœ… Part 2 ê²°ê³¼ë¥¼ ì •í™•íˆ ë¡œë”©í•˜ê³  í™œìš©
2. âœ… 5ê°€ì§€ ë¦¬ìƒ˜í”Œë§ ì „ëµ ëª¨ë‘ í…ŒìŠ¤íŠ¸ (SMOTETomek í¬í•¨)
3. âœ… 5ê°œ ëª¨ë¸ Ã— 100íšŒ ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ìµœì  ëª¨ë¸ íƒìƒ‰
4. âœ… Weighted Voting ì•™ìƒë¸” êµ¬ì¶• ë° ë¹„êµ
5. âœ… Traffic Light ì‹œìŠ¤í…œìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì…ì¦
6. âœ… ë°œí‘œìš©ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ì™„ì„±ë„ (ì‹œê°í™”, ì„¤ëª… í¬í•¨)
7. âœ… ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ (ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ ì‹œ ì—ëŸ¬ ì—†ìŒ)

**íŒŒì¼ëª…**: `notebooks/ë°œí‘œ_Part3_ëª¨ë¸ë§_ë°_ìµœì í™”.ipynb`

**ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„**: 20~40ë¶„ (100íšŒ ëœë¤ ìƒ˜í”Œë§ ê¸°ì¤€)

---

ì´ì œ ìœ„ ìš”êµ¬ì‚¬í•­ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” Jupyter Notebookì„ ìƒì„±í•´ì£¼ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ì€ ì´ëª¨ì§€ì™€ í•¨ê»˜ ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ê³ , ê° ë‹¨ê³„ë§ˆë‹¤ ì¶©ë¶„í•œ ì„¤ëª…ì„ í¬í•¨í•˜ì„¸ìš”. ì½”ë“œëŠ” ì£¼ì„ì„ ë‹¬ì•„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•˜ê³ , ì¶œë ¥ ê²°ê³¼ëŠ” ë°œí‘œì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê¹”ë”í•˜ê²Œ í¬ë§·íŒ…í•˜ì„¸ìš”.
