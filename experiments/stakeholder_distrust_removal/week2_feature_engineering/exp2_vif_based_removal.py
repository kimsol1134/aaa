"""
Week 2 ì‹¤í—˜ 2: VIF ê¸°ë°˜ íŠ¹ì„± ì œê±°
ëª©ì : ë‹¤ì¤‘ê³µì„ ì„±ì´ ë†’ì€ íŠ¹ì„± ì œê±°í•˜ì—¬ ëª¨ë¸ ì•ˆì •ì„± í–¥ìƒ
"""

import sys
sys.path.append('/home/user/aaa/experiments/stakeholder_distrust_removal/scripts')

import pandas as pd
import numpy as np
from catboost import CatBoostClassifier
from statsmodels.stats.outliers_influence import variance_inflation_factor
import warnings
warnings.filterwarnings('ignore')

from common_utils import (
    load_data, split_data, remove_feature_from_data,
    create_pipeline, evaluate_model, save_results, RANDOM_STATE
)


def calculate_vif_all_features(X, sample_ratio=0.2):
    """
    ëª¨ë“  íŠ¹ì„±ì˜ VIF ê³„ì‚°

    Args:
        X: íŠ¹ì„± ë°ì´í„°í”„ë ˆì„
        sample_ratio: ìƒ˜í”Œë§ ë¹„ìœ¨ (ê³„ì‚° ì†ë„ í–¥ìƒ)

    Returns:
        VIF ë°ì´í„°í”„ë ˆì„
    """
    print(f"VIF ê³„ì‚° ì¤‘ (ìƒ˜í”Œë§ {sample_ratio*100:.0f}%)...")

    # ìƒ˜í”Œë§
    sample_size = int(len(X) * sample_ratio)
    X_sample = X.sample(n=sample_size, random_state=RANDOM_STATE)

    # ì „ì²˜ë¦¬
    X_clean = X_sample.fillna(0).replace([np.inf, -np.inf], 0)

    # VIF ê³„ì‚°
    vif_data = []
    for i, feature in enumerate(X_clean.columns):
        try:
            vif = variance_inflation_factor(X_clean.values, i)
            if np.isinf(vif) or np.isnan(vif):
                vif = 999
        except:
            vif = 999

        vif_data.append({
            'feature': feature,
            'VIF': vif,
            'status': 'ğŸ”´ ì œê±° ê³ ë ¤' if vif > 10 else ('ğŸŸ¡ ì£¼ì˜' if vif > 5 else 'âœ… ì–‘í˜¸')
        })

        if (i + 1) % 10 == 0:
            print(f"  ì§„í–‰: {i+1}/{len(X_clean.columns)} íŠ¹ì„±")

    return pd.DataFrame(vif_data).sort_values('VIF', ascending=False)


def remove_high_vif_features(X, vif_threshold=10):
    """
    VIFê°€ ë†’ì€ íŠ¹ì„± ì œê±°

    Args:
        X: íŠ¹ì„± ë°ì´í„°í”„ë ˆì„
        vif_threshold: VIF ì„ê³„ê°’

    Returns:
        X_reduced: VIF ê¸°ë°˜ ì œê±°ëœ ë°ì´í„°í”„ë ˆì„
        removed_features: ì œê±°ëœ íŠ¹ì„± ë¦¬ìŠ¤íŠ¸
    """
    # VIF ê³„ì‚°
    vif_df = calculate_vif_all_features(X)

    # VIF > thresholdì¸ íŠ¹ì„±
    high_vif_features = vif_df[vif_df['VIF'] > vif_threshold]['feature'].tolist()

    print(f"\nğŸ“Š VIF > {vif_threshold} íŠ¹ì„±: {len(high_vif_features)}ê°œ")
    if high_vif_features:
        print(vif_df[vif_df['VIF'] > vif_threshold][['feature', 'VIF', 'status']].to_string(index=False))

    # ì œê±°
    X_reduced = X.drop(columns=high_vif_features)

    print(f"\nâœ… íŠ¹ì„± ì œê±°: {X.shape[1]} â†’ {X_reduced.shape[1]} ({len(high_vif_features)}ê°œ ì œê±°)")

    return X_reduced, high_vif_features, vif_df


def run_vif_based_removal_experiment():
    """
    VIF ê¸°ë°˜ íŠ¹ì„± ì œê±° ì‹¤í—˜

    ë¹„êµ ëŒ€ìƒ:
    1. Baseline: VIF ì œê±° ì•ˆ í•¨
    2. VIF > 10 ì œê±°
    3. VIF > 5 ì œê±° (ë” ë³´ìˆ˜ì )
    4. ê³ ìƒê´€ ìŒ ì œê±° (|r| > 0.9)
    """
    print("=" * 80)
    print("Week 2 ì‹¤í—˜ 2: VIF ê¸°ë°˜ íŠ¹ì„± ì œê±°")
    print("=" * 80)

    # ë°ì´í„° ë¡œë”©
    X, y = load_data()
    X_removed = remove_feature_from_data(X, 'ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜')

    # ë°ì´í„° ë¶„í• 
    X_train_base, X_val_base, X_test_base, y_train, y_val, y_test = split_data(X_removed, y)

    # ì‹¤í—˜ 1: Baseline (VIF ì œê±° ì•ˆ í•¨)
    print(f"\n{'='*80}")
    print(f"ì‹¤í—˜ 1: Baseline (VIF ì œê±° ì•ˆ í•¨)")
    print(f"{'='*80}")

    model = CatBoostClassifier(
        iterations=100, depth=5, learning_rate=0.05,
        random_state=RANDOM_STATE, verbose=0, eval_metric='Precision'
    )
    pipe = create_pipeline(model, wins=False, resamp='smote', resamp_ratio=0.2)

    print(f"í•™ìŠµ ì¤‘...")
    pipe.fit(X_train_base, y_train)

    baseline_result = evaluate_model(
        pipe, X_val_base, y_val, X_test_base, y_test,
        model_name='Baseline'
    )
    baseline_result['n_features'] = X_train_base.shape[1]

    # ì‹¤í—˜ 2: VIF > 10 ì œê±°
    print(f"\n{'='*80}")
    print(f"ì‹¤í—˜ 2: VIF > 10 ì œê±°")
    print(f"{'='*80}")

    X_train_vif10, removed_vif10, vif_df = remove_high_vif_features(X_train_base, vif_threshold=10)
    X_val_vif10 = X_val_base.drop(columns=removed_vif10)
    X_test_vif10 = X_test_base.drop(columns=removed_vif10)

    model = CatBoostClassifier(
        iterations=100, depth=5, learning_rate=0.05,
        random_state=RANDOM_STATE, verbose=0, eval_metric='Precision'
    )
    pipe = create_pipeline(model, wins=False, resamp='smote', resamp_ratio=0.2)

    print(f"\ní•™ìŠµ ì¤‘...")
    pipe.fit(X_train_vif10, y_train)

    vif10_result = evaluate_model(
        pipe, X_val_vif10, y_val, X_test_vif10, y_test,
        model_name='VIF > 10 ì œê±°'
    )
    vif10_result['n_features'] = X_train_vif10.shape[1]
    vif10_result['removed_features'] = ', '.join(removed_vif10)

    # ì‹¤í—˜ 3: VIF > 5 ì œê±°
    print(f"\n{'='*80}")
    print(f"ì‹¤í—˜ 3: VIF > 5 ì œê±°")
    print(f"{'='*80}")

    X_train_vif5, removed_vif5, _ = remove_high_vif_features(X_train_base, vif_threshold=5)
    X_val_vif5 = X_val_base.drop(columns=removed_vif5)
    X_test_vif5 = X_test_base.drop(columns=removed_vif5)

    model = CatBoostClassifier(
        iterations=100, depth=5, learning_rate=0.05,
        random_state=RANDOM_STATE, verbose=0, eval_metric='Precision'
    )
    pipe = create_pipeline(model, wins=False, resamp='smote', resamp_ratio=0.2)

    print(f"\ní•™ìŠµ ì¤‘...")
    pipe.fit(X_train_vif5, y_train)

    vif5_result = evaluate_model(
        pipe, X_val_vif5, y_val, X_test_vif5, y_test,
        model_name='VIF > 5 ì œê±°'
    )
    vif5_result['n_features'] = X_train_vif5.shape[1]

    # ì‹¤í—˜ 4: ê³ ìƒê´€ ìŒ ì œê±°
    print(f"\n{'='*80}")
    print(f"ì‹¤í—˜ 4: ê³ ìƒê´€ ìŒ ì œê±° (|r| > 0.9)")
    print(f"{'='*80}")

    # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
    corr_matrix = X_train_base.fillna(0).replace([np.inf, -np.inf], 0).corr()

    # ê³ ìƒê´€ ìŒ ì°¾ê¸°
    high_corr_pairs = []
    removed_by_corr = set()

    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            if abs(corr_matrix.iloc[i, j]) > 0.9:
                feat1 = corr_matrix.columns[i]
                feat2 = corr_matrix.columns[j]
                high_corr_pairs.append((feat1, feat2, corr_matrix.iloc[i, j]))

                # VIFê°€ ë” ë†’ì€ ê²ƒ ì œê±°
                if feat1 in vif_df['feature'].values and feat2 in vif_df['feature'].values:
                    vif1 = vif_df[vif_df['feature'] == feat1]['VIF'].values[0]
                    vif2 = vif_df[vif_df['feature'] == feat2]['VIF'].values[0]

                    if vif1 > vif2:
                        removed_by_corr.add(feat1)
                    else:
                        removed_by_corr.add(feat2)

    removed_by_corr = list(removed_by_corr)

    print(f"ê³ ìƒê´€ ìŒ: {len(high_corr_pairs)}ê°œ")
    print(f"ì œê±°í•  íŠ¹ì„±: {len(removed_by_corr)}ê°œ")
    if removed_by_corr:
        print(f"  {', '.join(removed_by_corr)}")

    X_train_corr = X_train_base.drop(columns=removed_by_corr)
    X_val_corr = X_val_base.drop(columns=removed_by_corr)
    X_test_corr = X_test_base.drop(columns=removed_by_corr)

    model = CatBoostClassifier(
        iterations=100, depth=5, learning_rate=0.05,
        random_state=RANDOM_STATE, verbose=0, eval_metric='Precision'
    )
    pipe = create_pipeline(model, wins=False, resamp='smote', resamp_ratio=0.2)

    print(f"\ní•™ìŠµ ì¤‘...")
    pipe.fit(X_train_corr, y_train)

    corr_result = evaluate_model(
        pipe, X_val_corr, y_val, X_test_corr, y_test,
        model_name='ê³ ìƒê´€ ìŒ ì œê±°'
    )
    corr_result['n_features'] = X_train_corr.shape[1]

    # ê²°ê³¼ ë¹„êµ
    results_df = pd.DataFrame([baseline_result, vif10_result, vif5_result, corr_result])

    print("\n" + "=" * 80)
    print("ğŸ“Š ìµœì¢… ë¹„êµ ê²°ê³¼")
    print("=" * 80)
    print(results_df[['model_name', 'n_features', 'val_pr_auc', 'test_pr_auc',
                       'val_test_gap', 'test_recall']].to_string(index=False))

    # ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ” ë¶„ì„")
    print("=" * 80)

    best_model = results_df.sort_values('test_pr_auc', ascending=False).iloc[0]
    best_gap = results_df.sort_values('val_test_gap').iloc[0]

    print(f"\nìµœê³  Test PR-AUC:")
    print(f"  {best_model['model_name']}")
    print(f"  Test PR-AUC:  {best_model['test_pr_auc']:.4f}")
    print(f"  íŠ¹ì„± ìˆ˜:      {best_model['n_features']}ê°œ")

    print(f"\nìµœì†Œ Val-Test Gap:")
    print(f"  {best_gap['model_name']}")
    print(f"  Val-Test Gap: {best_gap['val_test_gap']:.1f}%")
    print(f"  Test PR-AUC:  {best_gap['test_pr_auc']:.4f}")

    # VIF ë°ì´í„°í”„ë ˆì„ ì €ì¥
    save_results(vif_df, 'week2', 'vif_analysis')
    save_results(results_df, 'week2', 'vif_based_removal')

    return results_df, vif_df


if __name__ == '__main__':
    results, vif_df = run_vif_based_removal_experiment()
    print("\nâœ… Week 2 ì‹¤í—˜ 2 ì™„ë£Œ")
